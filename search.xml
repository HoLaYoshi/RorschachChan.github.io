<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[苹果手机无信用卡注册区美国apple store的办法]]></title>
    <url>%2F2018%2F05%2F30%2F%E8%8B%B9%E6%9E%9C%E6%89%8B%E6%9C%BA%E6%97%A0%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%B3%A8%E5%86%8C%E5%8C%BA%E7%BE%8E%E5%9B%BDapple-store%E7%9A%84%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这次去霓虹国在心斋桥Apple体验店买了一个256G的iphone X，由于政府政策的原因，中国区的apple store有很多应用是没有的，于是乎我就打算注册一个美国版的账号，从而登录美国版的apple store去下载那些“你懂得”的app。 首先先登录https://www.apple.com/ ，在网页最下面先确定国家是United States，然后点击Manage Your Apple ID，如图： 在https://appleid.apple.com/#!&amp;page=signin页面里，点击Create your Apple ID建立一个新的apple账号，名称正常写，国家还是United States不要动，生日如实填写，但是如果是未成年人的话，有些成人的app是不可以被下载的。然后就是写好自己的登陆问题，这个问题已经要记住，每次登陆都要输入，忘记的话就麻烦了。注册账号这里其他部分我就不多说了。 账号注册完毕之后，就直接在苹果网站上登录，登录之后，就会看到账号的详细信息，在Payment &amp; Shipping的地方点击Add Payment Method…，如图： 这里有一个PAYMENT METHOD的地方，要填写none，如果你用apple手机上登录这个账号的话，这里是不能选none的，无论是Dr.还是Mr.都没有none这个选项，所以说一定要在网页登录账号。然后就是需要你填写一些用户地址、邮编等信息，由于是账号注册时候选择的是美国，那么也需要填写美国的地址，可以在http://www.haoweichi.com/Index/random里生成一个身份信息填写。如图： 下面那个SHIPPING ADDRESS就是账单邮寄的地址，想填就填，不想填就放那。填写好了之后点击save，但是目前这个账号还是不能通过的，如果你在apple手机登录了这个账号然后登录apple store的话，会有一个提示：该账号没有被使用过，请填写细节。 这里如果你还手机上操作填写细节，发现你刚刚在电脑上填写的地址和邮编已经同步到手机的账号了，但是支付卡那一栏还是没有none，也就是说依旧要一个信用卡。此时请在电脑上下载itunes，然后在电脑的itunes里登录这个美国区账号，由于电脑itunes里的支付渠道依旧可以选择none，所以我们可以在这里绕一个弯，使用itunes这个渠道来完成这个美国区账号的彻底注册。 在itunes把整个账号完整过程都注册完毕之后，再登录到手机端，就可以在美国的apple store里尽情的下载app了！]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>apple</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超赞的京都大阪五日游]]></title>
    <url>%2F2018%2F05%2F25%2F%E8%B6%85%E8%B5%9E%E7%9A%84%E4%BA%AC%E9%83%BD%E5%A4%A7%E9%98%AA%E4%BA%94%E6%97%A5%E6%B8%B8%2F</url>
    <content type="text"><![CDATA[说来惭愧，活了30年了这是我第一次出国旅行，借着公司有一次旅游的机会就跟女朋友一起到京都和大阪玩5天。 搞定了签证，在网上买好了USJ的快速通行票，又预定了随身WIFI，简单在穷游、知乎和马蜂窝上做了做自由行的攻略，18号晚上6点半从杭州萧山机场出发，两个小时后到达关西机场。之前在《miss pilot》里看到过ANA的航空，这一次亲自乘坐感觉还是不错，飞机场有吃有玩还有葡萄酒喝。 到关西机场之后，又按指纹又照相的通过了一连串的海关检查，就跟公司其他小伙伴兵分两路，他们去奈良看鹿，我跟女票直接去京都。凭借女票的三脚猫日语功力和她已经来过大阪的经验，我俩先办理了地铁卡，购买了一日游行卡，然后坐上了从大阪出发到京都。 从大阪到京都大约花了一个半小时左右，抵达京都已经是晚上11点了。路上下着细细小雨，再加上两人拖着箱子有点肚饿，就在路边的seven-eleven里简单买了一点水和东西，买东西之余发现在超市里有成人书籍出售。从便利店出来顺着google地图找之前在爱彼迎上预订的民宿，那是一个公寓型民宿，凭借店主之前在邮件里写的密码，我们从信箱里拿到房间钥匙。 日本的庙京都是一个充满寺庙和神社的地方，京都的旅行就是“从这个庙出来，到下一个庙去”，而清水寺正是京都众多庙里人气很旺的景点之一，日本的庙和神社有一个习惯，入寺前先用竹勺洗手，如果要入室参拜的话还要脱鞋。在京都穿和服是一个很常见的事情，而且我觉得一群人穿和服是一个蛮cool的风景，不过女票没有租，但是在寺里买了很多的御守。 昨晚到京都太晚，无法注意天空，到了白天才发现京都的天真的很蓝，看见远方的山轻而易举。从清水寺出来下一站是八坂神社，巧的是遇到了一对新婚夫妇在这里结婚拍照，不得不说日本新郎传统的黑和服加扇子的形象还是很帅的。 日本的玩水族馆一直都是我非常喜欢的地方，而大阪海游馆也是这一次游玩里安排的一个重要环节，但是比较让我失望的是它的海底隧道很短，大约也就杭州水族馆的一半长度。我俩没有看到喂食节目，而且海游馆也没有海豹顶球，海豚跳舞这样的节目。不过海游馆的鱼种类还是很多的，有些品种还可以亲手去摸一摸它们。出了海游馆就是一个蛮大的摩天轮，用一日通票的话可以免费上去坐一圈。 大阪的USJ是我们这次日本之行的最后一站也是最高潮的部分，去年圣诞节我跟女票在上海的迪士尼度过的。从迪士尼回来就一直碎碎念大阪的环球影城，我俩还特意挑选了一个工作日去玩就是为了尽可能的少排队，但是那天依旧很多很多人，真的超火爆。 环球影城的运营模式跟迪士尼差不多，通过IP分主题区，可以购物也有花车游行。但是整个乐园的玩法相对单一—-都是过山车：哈利波特是过山车、蜘蛛侠是过山车、小黄人是原地晃晃过山车、侏罗纪公园是水上过山车，至于翼龙飞行和好莱坞美梦更是超刺激的过山车… 这一次环球影城的特殊项目有四个：怪物猎人、美少女战士（看动画片）、柯南（密室逃脱）和最终幻想。我跟女票还有公司同事都选择了柯南，虽然通篇日语对白，不过还是能猜出来一个大概剧情，所以一个半小时玩下来感觉就像看了一遍柯南的剧场版，里面的解密就不剧透了，机关真的很难，想要在一个小时内完全逃脱几乎是一个不可能的任务。 上面把正经的娱乐说完了，下面来说一点不正经的娱乐。我和女票在大阪住在日本桥地铁站附近，那里距离道顿堀走路也就10分钟的路程，而道顿堀附近有一个街叫宗右卫门町，那里就是大阪有名的牛郎街，一路走过去各种牛郎宣传大海报和在路边搭讪的小哥，甚至那附近的小吃店里还有牛郎哥的宣传单。除了铺天盖地的牛郎哥哥外还有站街的妹妹，大多数都是黄发浓妆，但是仔细看脸都不算太好看的。这些人会跟过往的单身男女搭讪，邀请他们去店里坐坐喝点酒说说话，至于有没有更进一步的皮肉关系，那就不好说了。而且据说他们是不做不懂日语人的生意的，所以如果他们真的纠缠你了，就直接说我是外国人就好。 日本的购物到了日本，买东西是必然的。不过当地的大商场关门很早，基本晚上八点半左右就开始关门。在伏见稻荷大社甚至有的商铺五点半就打烊了，我很好奇，商场这么早关门，那日本人晚上的娱乐是什么呢？他们除了去居酒屋喝酒和广场溜达再加上回家看电视难道就没有其他的娱乐了吗？ 不过，各大药妆店的营业时间很晚，甚至唐吉坷德是24小时营业。这种地方里充满了大陆人、香港人、台湾人、韩国人还有泰国人，在人群和背包中穿梭，拎着篮子买买买，买到5000就可以退税。我女票这次买了很多的卸妆水乳液面膜眼霜口红还有零食，作为一个在旁边无事可做的男人，深深地觉得陪女人逛街是一个很遭罪的事情。 日本的吃我是看过《深夜食堂》和《孤独的美食家》的，所以对日本的食物有一点好感，而且在杭州吃到日本料理也不是一个难事。不过这次到了日本，连续吃了五天当地的饭，发现日本的菜其实很单一。 日本普通的餐就是“米饭+猪肉\牛肉\鸡肉+沙拉+味增汤”，日本的米饭是很好吃的，但是他们的肉做法基本就是炸，炒是很少的。如果不是米饭的话就是炒面、拉面、寿司或者是煎饺。期间我跟女票吃了一次烤肉，里面有“最强牛里脊和牛肠”给我留下了很深的印象。此外在海游馆还吃到了我梦寐已久的大阪烧，插播一句话，吃大阪烧的时候还看到足球运动员郑大世，我女票一眼就认出他来了… 日本的消费能力不低，五天下来，基本上每一顿饭都大约花费了3000多日元，在吉野家吃算比较便宜的，2000不到就能搞定。在烤肉店要了套餐，每人是5000日元。这次在日本，觉得最好吃的是牛里脊，然后就是烤蟹壳。 说完了吃再说说喝，大阪和京都随处可见自动售卖机，售卖机里面基本就是五样饮品—水、绿茶、优酸乳、可乐和咖啡，价钱还都差不多。日本的水果很贵，一个不到6斤重的西瓜就要2200日元左右，橘子大约五块钱一个，但是他们的酒却相比较便宜。在日本我可没少喝梅子酒、气泡果酒和啤酒。 日本的电视我俩住的民宿有一个小电视，里面有12个频道，其中三个是购物频道…我想可能日本的免费电视就这么点，大多数都是收费频道。这九个电视台白天有新闻，有韩剧，有街头采访；晚上有芭蕾舞片段、有综艺节目、还有打着圣光的肉番！说到综艺节目，里面有一个片段就是把秃头用毛巾擦的锃亮，然后用遥控板去对着秃头摁键，结果信号经过秃头的折射，竟然能顺利的操纵电视。再后来叫来两个秃头，尝试多次折射，依旧可以准确遥控电视…就这么一个环节把我之前从来不看日本综艺节目的同事笑翻了，回国后就开始恶补这种日本综艺。 游玩的tips1.日本路边的垃圾箱很少，据说是因为他们没有边走路边吃喝东西的习惯，所以随处带一个塑料袋来装垃圾；2.USJ的快速通行证只有日语区的页面才有，请准备好visa和master卡；3.办理的地铁充值卡不要扔，下一次再来日本，直接储值依旧可以使用；4.到了USJ别上来先买东西，要先排队玩，东西可以放到最后出院的时候再买；5.不会日语在一般情况下没问题，但是如果看不懂车站的话，就难免要问路了，这样会比较头疼，准备一个google翻译。6.champion在日本的地摊也有卖，人民币大约100多，所以淘宝上那些200左右的champion完全不需要考虑… 这次的遗憾这次玩的蛮爽的，但是大阪仅仅只有三天只能玩一个皮毛，比如本次出游的遗憾如下： 1.据说大阪有一个棒球场，20日元一个球，然后通过发球机器发射，游客可以轮棒尝试一下本垒打的快感，但是由于时间太紧没有打上棒球…2.没有去游戏机厅，以前常在漫画里看到日本有那种弹子机，如果赢的多，可以用塑料筐装满小弹子去换钱，这种游戏机厅在大阪的商场很常见，而且门口都有大广告，上面写“新品到店，欢迎畅玩”；3.在龟梨和也和山下智久主演的《我命中注定的人》里，龟梨和也手工雕刻了一个王将的木牌，这次到了大阪逛了很多店，都没有发现这款木雕，不仅没有这个木雕，连战国时期各大将的头盔纺织品也没有看到，这一点很遗憾；4.USJ里的变形金刚和终结者2都暂时停业，不过我后来在B战上看了视频，还是过山车… 等下一次如果有机会能去东京的话，就尝试把上面几个弥补上，再顺便去一趟秋叶原。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>日本</tag>
        <tag>旅游</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab+Jenkins搭建持续集成系统]]></title>
    <url>%2F2018%2F05%2F25%2FGitlab-Jenkins%E6%90%AD%E5%BB%BA%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[前言gitlab是一个应用很广泛的版本控制工具，他也有自带的持续集成工具—gitlab cli，但是这个工具不如jenkins那么好用。本文的目的要把gitlab和jenkins进行结合，当我们更新了代码并且把代码push到gitlab的时候，gitlab会把代码的变化通知到jenkins，然后jenkins就会自动构建project。 说一下实验环境：Jenkins所在服务器IP：121.41.37.251（10.168.173.181），版本是2.124(查看jenkins的版本语句java -jar /usr/lib/jenkins/jenkins.war --version);Gitlab所在服务器IP：114.55.224.158（10.25.85.175），使用容器安装，版本是10.7.3; jenkins添加gitlab插件通过浏览器登陆jenkins界面，然后在系统管理里面选择管理插件，如图： 然后在可选择插件里搜索gitlab hook插件，但是没想到我这个版本提示，目前的1.4.2版本的gitlab hook目前存在安全隐患，如图： 具体的安全隐患细节是这样的： 这个风险请自己把握，然后我选择了继续安装，如图： 安装完了gitlab hook插件后，还要安装GitLab Plugin和Gitlab Authentication plugin这两个插件，方法跟上面的一样。 创建测试工程在jenkins上建立一个新的任务，比如叫”jicheng-test”，这是一个自由风格的软件项目： 然后在源码管理里面选择git，然后输入gitlab里面仓库的地址，比如我在gitlab上新建了一个仓库叫jenkinstest，那么就复制这个仓库的地址填到jenkins的Repositories里，如图： 还要在Credentials这里面写上gitlab的用户和密码，然后保存即可： 配置 GitLab 用户浏览器切换到gitlab界面，在用户头像点击，User settings —&gt; Access Tokens，这里的Personal Access Tokens写入一个账号，这个账号是用来让Jenkins和GitLab API交互。这个用户将需要是全局的管理员或添加进每个组／工程，并作为成员。需要开发者权限来报告构建状态。如图： 输入账号和账号有效时期之后，会生成一个Private token，如图： 拷贝它，稍后在配置Jenkins服务器时会用到。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用yum安装软件爆No such file or directory]]></title>
    <url>%2F2018%2F05%2F17%2F%E4%BD%BF%E7%94%A8yum%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E7%88%86No-such-file-or-directory%2F</url>
    <content type="text"><![CDATA[今天开发反馈说yum install redis报错-bash: /usr/bin/yum: /usr/bin/python: bad interpreter: No such file or directory，于是我就登上服务器，使用python一看，反馈-bash: python: command not found，原来这个机器的python被人改动了，用whereis python查了一下，原来python的地址被人改成了/usr/bin/python2.7，于是就手动更改了一下/usr/bin/yum，把#!/usr/bin/python改成了#!/usr/bin/python2.7。但是使用yum install -y redis发现虽然可以连接到库但是会报No such file or directory，如图： 原来光改了/usr/bin/yum还没用，还要改/usr/libexec/urlgrabber-ext-down这个文件，同样也是把python改成/usr/bin/python2.7说明python的路径才可以。 改了上面两个文件之后，又加上了yum clean all和yum makecache，清除一下缓存，一切恢复了正常。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix去监控docker容器]]></title>
    <url>%2F2018%2F05%2F17%2F%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7docker%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言现在容器技术越来越普遍，那么搭建了容器肯定要监控起来，监控方法有两种，一种是做一个zabbix-agent容器去监控容器，还有一个是升级原有的zabbix-agent，这里说第一种。 这里先交代一下环境：zabbix-server的ip是10.244.48.42，要监控的机器ip是10.244.34.79，这个机器里面装了一个容器在运行gitlab，如图： 事前检查两台服务器是否互通，而且10050和10051端口是否standby。还要在zabbix-server端做好auto-discovery，等等等等准备工作。 使用Zabbix Agent Docker进行监控在10.244.34.79这个机器上先安装zabbix-agent容器： 12345678910docker run \ --name=dockbix \ #这个是容器的名称 --net=host \ #容器可以直接访问主机上所有的网络信息 --privileged \ #容器内的root拥有真正的root权限 -v /:/rootfs \ #这个是对应宿主机的映射盘 -v /var/run:/var/run \ --restart unless-stopped \ #不管退出状态码是什么始终重启容器，不过当daemon启动时，如果容器之前已经为停止状态，不要尝试启动它。 -e &quot;ZA_Server=10.244.48.42&quot; \ #这里就填写zabbix-server的ip地址 -e &quot;ZA_ServerActive=10.244.48.42&quot; \ -d hub.c.163.com/canghai809/dockbix-agent-xxl-limited:latest #这里使用了网易蜂巢镜像 但是反馈给我docker: invalid restart policy unless-stopped.这样的错误信息，原来这个gitlab这台服务器的docker版本较老，而unless-stopped这个是在1.9.0版本才加入的，所以对于旧版的docker环境需要改成always。 更改docker run的命令之后重新执行效果如下： 可见容器启动成功，docker logs -f 容器ID号看一下日志是否正常。如果正常的话，应该在zabbix-server端是可以看到这个10.244.34.79已经被添加到控制台里了，如图： 导入监控docker的模版在zabbix server上导入监控docker的模版，一共2个模版,下载后解压。模版下载地址: https://dl.cactifans.com/zabbix/Zabbix-Template-App-Docker.tar.gz 。 我使用主动模式，因此导入Zabbix-Template-App-Docker-active.xml这个模版，如图： 此时可以去zabbix-server这个机器上验证一下是否监控成功，在zabbix-server上执行zabbix_get -s 10.244.34.79 -k docker.discovery，效果如下： 可见已经成功获取到了那两个容器的名称，这就代表zabbix-server已经监控到位了。 验证数据首先现在10.244.34.79里执行docker stats 容器1的ID 容器2的ID...，看一下当前运行的所有容器的状态，如下： 与zabbix-server的latest data做一下对比，由于被监控机的docker版本较老，docker stats结果不是那么的精准，不过用来监控参考还是OK的…如果docker是最新版的，那么监控值是很准的。 剩下的就是慢慢添加triggers了… 补充一句，zabbix-agent 3.2的rpm安装方法： 1234rpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm yum -y install zabbix-agent zabbix-senderservice zabbix-agent startchkconfig zabbix-agent on 参考资料https://github.com/monitoringartist/zabbix-docker-monitoring （墙裂推荐！）https://blog.codeship.com/ensuring-containers-are-always-running-with-dockers-restart-policy/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab的配置备份]]></title>
    <url>%2F2018%2F05%2F16%2FGitlab%E9%85%8D%E7%BD%AE%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[我这个gitlab是容器安装的，直接使用最新的gitlab镜像，gitlab版本是10.7.3。 要备份数据的话，就要进入容器里，执行gitlab-rake gitlab:backup:create，效果如下： 执行完毕之后，在/var/opt/gitlab/backups文件夹里就会生成一个备份文件，我这里生成的文件叫：1526454102_2018_05_16_10.7.3_gitlab_backup.tar，这个就是备份的文件。 如果要还原的话，命令如下： 1234567891011# 先关闭连接数据库的进程sudo gitlab-ctl stop# 通过指定时间戳来执行restore操作，这个操作会复写gitlab的数据库sudo gitlab-rake gitlab:backup:restore BACKUP=1526454102 #BACKUP后面的是备份文件开头的那串数字# 再次启动gitlabsudo gitlab-ctl start# 通过下面命令检查gitlabsudo gitlab-rake gitlab:check SANITIZE=true 注意！利用backup机制进行备份的话，对gitlab的版本是要求严格一致的。例如用8.6版的gitlab生成的备份文件，拿到8.7版的gitlab上进行恢复，是会报错的。 如果要设置这个备份文件的生命周期和备份文件存储的位置，编辑/etc/gitlab/gitlab.rb，修改如下的地方： 1234gitlab_rails[&apos;backup_path&apos;] = &quot;/var/opt/gitlab/backups&quot; #这里改新路径gitlab_rails[&apos;backup_archive_permissions&apos;] = 0644 #这里可以设定文件的权限# limit backup lifetime to 7 days - 604800 secondsgitlab_rails[&apos;backup_keep_time&apos;] = 604800 #文件存储时间一周 然后重启一下gitlab即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab的简单应用]]></title>
    <url>%2F2018%2F05%2F16%2FGitlab%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%94%A8%2F</url>
    <content type="text"><![CDATA[gitlab跟svn的区别我就不多说了，这里直接说具体应用。 建立一个project先登陆到gitlab的网页，我这里使用了root用户，选择create a project，然后就是填写project的名称以及它所属的用户，这里由于只有root用户，所以这个叫jjfjj的project就是root自己的，如果建立了一个组的话，那么这里就填写那个组，如下： 下面这个Visibility Level ，就是权限等级，它分三种： Private：私有的，只有你自己或者组内的成员能访问 Internal：所有登录的用户 Public：公开的，所有人都可以访问 这个东西和project的名称都是可以后期更改的。 然后就是create project，就创建了这个jjfjj。如图: 将本地代码上传建立好了gitlab，就要把开发的代码传进去，我在另外一个机器里，创建一个目录code，这个目录就是专门用来放置代码的，假设现在里面有一个文件叫testcode.py，如图： 具体操作如下： 如果在两个不同的文件夹里执行上面的过程，会传输到两个不同的project里。说明一下上面几个命令的意思：git init：初始化git仓库git add .：添加整个目录里的所有文件到仓库git rm --cached 某个文件名：将某个文件从gitlab上撤除，如果想当前文件夹恢复成一个普通的文件夹，那就把文件夹路径下的.git文件删除掉即可git commit -m &#39;这里是要写的注释&#39;：提交代码到仓库git remote add origin +gitlab的地址(上上图里红色框的内容)：链接到gitlab服务器git push origin master：push代码到服务器git remote -v：查看当前文件夹的目标project 此时刷新一下gitlab的project页面，就看到刚刚的那个testcode.py已经传上来了。如图： 如果代码有所更改或者出现Everything up-to-date，那么就按顺序执行git add .，git commit -m &#39;这里是要写的注释&#39;，git push origin master即可。 免密码push代码在上面的git push origin master的时候需要输入gitlab的用户密码，如要需要免密码push，有两种方法。 第一种方法是ssh，请看 https://blog.whsir.com/post-1749.html/comment-page-1#comment-3425 。 第二种方法还是用http的方式传送，但是将密码写进配置文件里：执行git config --global credential.helper store，然后cat ~/.gitconfig，就会看到如下结果： 12345[user] email = chen_shuo@dahuatech.com name = root[credential] helper = store 重新去执行git add .，git commit -m &#39;这里是要写的注释&#39;，git push origin master，就不再需要输入密码了。 从gitlab上垃取代码在要部署的机器上找到要部署的文件夹，我这里用/gitlab为例，操作如下： 12345678910[root@pass-mixnumbus-001 /GITLAB] # git init #将这个文件夹进行初始化 Initialized empty Git repository in /GITLAB/.git/ #提示现在已经安装了.git文件[root@pass-mixnumbus-001 /GITLAB(master)] # git remote add origin http://114.55.224.158/root/JJFJJ.git #确定库[root@pass-mixnumbus-001 /GITLAB(master)] # git pull origin master #制定要把master分支的代码全拉取到这个文件夹里Username for 'http://114.55.224.158': root #输入账号和密码Password for 'http://root@114.55.224.158': From http://114.55.224.158/root/JJFJJ * branch master -&gt; FETCH_HEAD[root@pass-mixnumbus-001 /GITLAB(master)] # ls #看一下效果admin.py looksql.py models.py syncECS.py testsyncECS.py 再与gitlab界面的代码比较一下，果然都过来了！如图： 在gitlab上建立分支gitlab上有很多个分支，主要的分支是master，它也是默认的分支，但是实际工作中是需要其他的开发去新建一些测试的分支，到时候可以先把这些测试的分支拿来部署，如果有问题就回滚回master分支。 分支相关的语句如下： 123456git branch #查看本地分支git branch -r #查看远程分支git branch -a #查看所有分支git branch develop #本地创建新的分支，此时刷新gitlab的页面的话就会有这个叫develop的分支建立了git checkout develop #切换到新的develop分支git checkout -b develop #上面两步可以合成一个命令，这个的意思就是：创建+切换分支 这个时候在代码机上新增或者改变文件，然后执行git add .，git commit -m &#39;这里是要写的注释&#39;，git push origin develop，就把新增的变化上传到了develop分支，如图： 1234567891011[root@iZ23pg8sy5bZ ~/GITLAB(develop)] # git push origin developCounting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 325 bytes | 0 bytes/s, done.Total 3 (delta 1), reused 0 (delta 0)remote: remote: To create a merge request for develop, visit:remote: http://114.55.224.158/root/JJFJJ/merge_requests/new?merge_request%5Bsource_branch%5D=developremote: To http://114.55.224.158/root/JJFJJ.git fc8d456..8a97b58 develop -&gt; develop 而在部署的机器上，直接执行git pull origin develop，输入账号密码之后，就会把develop分支的内容全部垃取下来了。 如果不想要这个develop分支了，就git branch -d develop，如果要删除远程的分支，就是git push origin :develop，注意这个冒号。 参考资料https://blog.cnbluebox.com/blog/2014/04/15/gitlabde-shi-yong/https://zhang759740844.github.io/2016/08/27/git%E6%8A%80%E5%B7%A7/https://www.restran.net/2016/02/23/git-and-gitlab-guide/https://www.jianshu.com/p/f54053afecf2]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab的汉化过程]]></title>
    <url>%2F2018%2F05%2F15%2FGitlab%E7%9A%84%E6%B1%89%E5%8C%96%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[gitlab的容器安装方法部署前的第一句话，gitlab是不支持32位系统的！ gitlab用容器部署的话非常的简单，首先docker pull gitlab/gitlab-ce:latest下载镜像，然后docker run --detach --hostname 本机外网IP --publish 443:443 --publish 80:80 --publish 2222:22 --name gitlab --restart always gitlab/gitlab-ce:latest建立一个容器，如图： 然后在浏览器的地址栏里输入服务器的外网IP地址，就到了一个更换密码的页面，这个密码就是root的密码，如图： 设定密码之后，就可以通过root账号登陆gitlab了，如图： 至于“使用ldsp方式登录”、“配置域名”和“关闭注册功能”请移步去看：https://rorschachchan.github.io/2018/05/10/在已经运行的docker容器里面使用中文/ 。 gitlab的汉化方法汉化之前，要确定gitlab的版本，先docker exec -it 容器ID env LANG=C.UTF-8 /bin/bash登陆到容器里，执行cat /opt/gitlab/embedded/service/gitlab-rails/VERSION，由于当时镜像是最新的，所以gitlab的版本是10.7.3。 还是在容器里，执行git clone https://gitlab.com/xhang/gitlab.git，克隆获取汉化版本库(这里要感谢辛苦的汉化工作者，向你们致敬！)，默认是获取最新的。如果需要下载老版本的汉化包，则要加上老版本的分支，如：git clone https://gitlab.com/xhang/gitlab.git -b v10.2.5-zh。 然后gitlab-ctl stop先停止gitlab服务，cd gitlab/进入到刚刚下载的那个git包里，执行如下代码： 123456root@10 gitlab]# git fetchroot@10 gitlab]# git diff v10.7.3 v10.7.3-zh &gt; ../10.7.3-zh.diffroot@10 gitlab]# cd ..root@10 ~]# patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; 10.7.3-zh.diffroot@10 ~]# #如果提示没有patch，请执行apt-get update &amp;&amp; apt-get install patchroot@10 ~]# gitlab-ctl start 重新返回到浏览器里，就能看到汉化后的gitlab了，大功告成！ 参考资料https://xuanwo.org/2016/04/13/gitlab-install-intro/https://www.jianshu.com/p/6606aed59a56http://adairjun.github.io/2016/12/20/gitlab/https://github.com/marbleqi/gitlab-ce-zh/blob/v10.5.1-zh-patch/Nginx.md]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析django里models.py、views.py与网页之间的爱恨纠葛]]></title>
    <url>%2F2018%2F05%2F14%2F%E6%B5%85%E6%9E%90django%E9%87%8Cmodels-py%E3%80%81views-py%E3%80%81page%E4%B9%8B%E9%97%B4%E7%9A%84%E7%BA%A0%E8%91%9B%2F</url>
    <content type="text"><![CDATA[环境：django 2.0 + python 3.6 + pycharm 2018 django建立一个app之后就会有models.py、views.py、admin.py这几个文件，他们三个分别的用途如下： models.py主要是用来设置数据在数据库的存储格式（比如默认值，字段类型和字段长度等等）; admin.py是用来设置在/admin/后台里面的显示样式; views.py是用来设置在前台网页里的显示样式； urls.py是用来编辑域名规则； admin.py是后台配置的文件，所以对前台网页来说，它不重要，而真正与前端网页相关的就是三个部分：models.py、views.py和对应的网页。 举个例子，假设有一个models.py，内容如下： 1234567from django.db import models from django.contrib.auth.models import User class BlogType(models.Model): type_name = models.CharField(max_length=15) #规定type_name是一个最大为15字节的charfield def __str__(self): return &apos;&lt;BlogType:%s&gt;&apos; % self.type_name 然后随便加入一些内容，如图： 而在views.py里，要求在前端网页里如此的显示： 1234567from django.shortcuts import render_to_response,get_object_or_404 from .models import Blog,BlogType #这里引用了models.py里的那两个class def blog_list(request): context = &#123;&#125; context[&apos;blog_types&apos;] = BlogType.objects.all() return render_to_response(&apos;pageblog/blog_list.html&apos;,context) 在views.py里规定，如果有访问域名是/blog_list/的网页，就返回pageblog/blog_list.html这个页面，而这个blog_list.html只是一个框架，里面的内容是context。context本身是一个字典，里面的里面的key对应的value是用ojbects这个函数获得的，objects.all()就是获取全部的意思。用来填充blog_list.html的context里面有blogs和blog_types两个key。 那么现在就可以在blog_list.html里使用blog_types这个key了，如下： 1234&lt;!-- 前面略 --&gt; &lt;h4&gt;博客分类&lt;/h4&gt; &lt;h3&gt; &#123;&#123; blog_types&#125;&#125; &lt;/h3&gt; &lt;!-- 后面略 --&gt; 这样的效果如下： 返回的是QuerySet类型，QuerySet是Django的查询集，可以通过QuerySet条件查询得到对应模型的对象集合。由此看出blog_types已经成功的引入到了blog_list.html里。 至于拆成每一个“博客类型”就很简单了，html部分如下： 12345678910&lt;h4&gt;博客分类&lt;/h4&gt; &lt;!-- ul是无项目的标签 --&gt; &lt;ul&gt; &#123;% for blog_type in blog_types%&#125; #开始一个for循环 &lt;li&gt;&lt;a href=&quot;&#123;% url &apos;blogs_with_type&apos; blog_type.pk %&#125;&quot;&gt;&#123;&#123; blog_type.type_name &#125;&#125; &lt;/a&gt;&lt;/li&gt; #对每一个类型加上一个a链接 &#123;% empty %&#125; #如果唯空就说“暂无分类” &lt;!-- li是具体的项目 --&gt; &lt;li&gt; 暂无分类 &lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt;]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加载css样式的两个方法]]></title>
    <url>%2F2018%2F05%2F12%2F%E5%8A%A0%E8%BD%BDcss%E6%A0%B7%E5%BC%8F%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景说明环境： django 2.0+python 3.6+pycharm 2018project名称: blog 普通的网页加载css网页使用了css才会更好看更炫酷，一般情况下的网页是这样的： 上面这个html文件里用到了模板，而且又对div和 a标签做了class定义，最后分别对各自的class进行了css说明。整个文档看下来比较直观。 但是这样就会有一个问题，就是把html内容和css内容写到了一起，一般来说为了后期维护，都会把css单独写到一个文件夹里，然后让这个html来引用这个css文件夹的具体某个css文件。 于是，我们就在blog这个project目录下建立一个叫static的文件夹，用它来专门装css\js这样的静态文件。 首先，建立了这个static文件，肯定就涉及到引用的问题，而如何让django可以识别static呢？ 打开blog/settings.py这个文件，这个文件是整个project的配置文件，在文件末尾加上这样的话，如下： 1234 #将项目根目录里的static制定成项目的静态文件夹,这样django就可以识别 #注意，static前面没有&apos;/&apos; STATICFILES_DIRS = [os.path.join(BASE_DIR, &apos;static&apos;),]​ 这样blog这个根目录就可以识别了static文件夹了。 然后在pycharm里新建一个css文件叫base.css，如果是专业版的pycharm是可以直接建立css类型文件的，免费社区版是没有这个功能。再将原文里面的所有关于css的内容拷贝到这个base.css里，如下： 1234567891011121314151617181920*&#123;margin: 5px;padding: 10px;&#125; div.nav &#123;background-color: gold;border-bottom: 2px solid #ccc;&#125; div.nav a&#123;text-decoration:none;color: blue;padding: 5px 10px;&#125; div.nav a.logo&#123;display: inline-block;font-size: 120%;&#125; 保存之后，为了验证django是否成功的识别此文件，可以在浏览器里输入外网IP：端口号/static/base.css查看是否返回就是上面内容，如果是就代表识别成功，如果是404就要重新检查settings.py了。 在原有的html里删除掉&lt;style&gt;标签内css内容，还要在head里添加一句话：&lt;link rel=&quot;stylesheet&quot; href=&quot;/static/base.css&quot;&gt;,如下： 这样就达到了引用css所在的static文件夹的目的。 Django内部的加载css方法上面说的是普通html加载css的方法，而django内部也有自己的一套方法，再次打开settings.py里看到有如下的内容： 123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog',] 上面的django.contrib.staticfiles就是django的css加载方法，使用这个方法也很简单。 首先要在html文件最上面先声明要调用这个方法: 12&#123;% load staticfiles %&#125;&#123;# 这个staticfiles是django自带的，可以在settings文件里看到 #&#125; 然后把link标签改成如下： 1&lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;% static &apos;base.css&apos; %&#125;&quot;&gt; 保存文件刷新即可，而且用了这种方法，在chrome浏览器里F12 查看，会解析成普通模式的方法，如图： 在django项目里，还是更推荐用django的方法。 额外补充如果html文件开头声明引用了某个模板，比如： 12&#123;% extends &apos;base.html&apos; %&#125; #声明引用了base.html这个模板&#123;% load staticfiles %&#125; 那么extends语句必须在最上面，不然就会报错：TemplateSyntaxError at /&lt;ExtendsNode: extends &#39;base.html&#39;&gt; must be the first tag in the template.]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>前端技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建Mysql容器过程]]></title>
    <url>%2F2018%2F05%2F12%2F%E5%88%9B%E5%BB%BAMysql%E5%AE%B9%E5%99%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[过程记录先docker pull mysql，当前最近的版本是8.0，然后docker images查看一下效果。 然后就是启动一个容器，命令是：docker run --name test-mysql -p 3306:3306 -e MYSQL\_ROOT\_PASSWORD=123456 -d mysql,这句话的意思是：启动一个叫test-mysql的容器， 端口影射是3306到宿主机的3306，同时设置root的密码是123456，然后以守护进程的形式启动。 但是如果在宿主机上使用mysql -h127.0.0.1 -uroot -p123456可能会报错，报错内容是：Authentication plugin ‘caching_sha2_password’ cannot be loaded: 那么就docker exec -it 容器ID号 env LANG=C.UTF-8 /bin/bash进入到容器里，使用mysql -uroot -p123456，看一下在容器里是否可以正常登录，如果可以的话，那么就在mysql的命令行里执行ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;。 退出容器在宿主机上重新连接，这样就OK了。至于原因就是，mysql的客户端是yum安装的，虽然是centos 7，但是安装的版本也是5.5版本的，所以8.0的客户端有一个新的密码加密方式：caching_sha2_password，客户端不支持，所以需要手动到命令行里更改一下。 mysql存储的坑先思考一个问题：假如某mysql容器里存储了100G的数据，那么这个容器关闭了，这100G的数据还在么？从宿主机是可以找到这100G的数据么？ docker inspect mysql-container-id，找到里面的volume字段，这里也显示挂载的host路径，可以通过这个路径来备份数据。或者使用docker cp mysql-container-id:/path/to/db-backup-file ./，把容器内数据放到当前目录下。如果是生产环境，必须使用Volume或数据容器。 参考资料http://binary-space.iteye.com/blog/2412769http://dockone.io/question/108]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>docker容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python报错：importError: No module named bz2]]></title>
    <url>%2F2018%2F05%2F12%2Fpython%E6%8A%A5%E9%94%99%EF%BC%9A'importError-No-module-named-bz2'%2F</url>
    <content type="text"><![CDATA[每日统计阿里云同步延迟的邮件早就编写完毕了，现在要放到专门跑脚本的服务器里，进去到这个服务器里发现这个机器已经被人装了两个python，分别是python 2.7.5（默认路径）和python 2.7.13（路径是/usr/local/python/bin/python），说实话我个人不太明白这么做的原因何在。 但是既然已经被人搞成这样了，那就适应环境吧，把脚本拷贝过来，把依赖库都安装好，但是在执行matplotlib的库的时候，爆了一个错误：ImportError: No module named bz2。 这就是因为两个python，但是启动的那个python文件夹里面是没有bz2.so这个文件的，于是就需要把系统里默认的2.7.5的bz2.so拷贝到2.7.13的lib路径里。 首先find / -name bz2.so找一下文件，如下： 1234[root@dvl-stun-002 GETDTS]# find / -name bz2.so/usr/local/aegis/PythonLoader/lib/python2.7/lib-dynload/bz2.so/usr/local/aegis/SecureCheck/lib/python2.7/lib-dynload/bz2.so/usr/lib64/python2.7/lib-dynload/bz2.so 然后cd /usr/local/python/lib/python2.7/，把/usr/lib64/python2.7/lib-dynload/bz2.so复制到这个文件夹里即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在已经运行的docker容器里面使用中文]]></title>
    <url>%2F2018%2F05%2F10%2F%E5%9C%A8%E5%B7%B2%E7%BB%8F%E8%BF%90%E8%A1%8C%E7%9A%84docker%E5%AE%B9%E5%99%A8%E9%87%8C%E9%9D%A2%E4%BD%BF%E7%94%A8%E4%B8%AD%E6%96%87%2F</url>
    <content type="text"><![CDATA[配置ldap公司搭建的gitlab现在需要开启ldap服务，也就是这样就可以用公司的域账号登陆gitlab，而不用开发一个一个去注册账号了。 开启ldap登陆的任务光荣了落到了我的身上，于是我就登陆到gitlab服务器一看，嚯，这还是在容器下启动的，如图： 于是我就docker exec -it 容器ID号 /bin/bash登陆到这个容器里，编辑/opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml，如下： 1234567891011121314ldap: enabled: true sync_time: host: '公司域账号服务器IP地址' port: 389 uid: 'sAMAccountName' method: 'plain' # "tls" or "ssl" or "plain" bind_dn: 'dahuatech\Ldap_System' password: '对应的密码' active_directory: allow_username_or_email_login: lowercase_usernames: base: user_filter: 但是在填写到base的时候发现了一个问题，公司的base是中文的，是&#39;OU=大数据研究院,OU=研发中心,OU=大华技术,DC=dahuatech,DC=com&#39;，但是在文件里输入中文却是乱码，如图： 容器默认是不支持中文的，在容器里的命令行输入中文也是空白。那么面对一个已经运行的容器，如何正常的输入中文呢？ 答案是：使用docker exec -it 容器ID号 env LANG=C.UTF-8 /bin/bash登陆，这样就能正常使用中文了，如图： gitlab-ctl restart之后，登陆到gitlab页面一看，已经添加ldap访问方式： 取消“注册”功能修改好配置文件gitlab.yml之后，现在就要把“注册”功能去掉，这样以后都统一用公司的域账号登陆，避免一些乱七八糟的用户来注册乱七八糟的账号。 首先用root账号登陆到gitlab里，在网页里进入到admin area，如图： 然后再点击最下面的settings，选择Sign-up restrictions，然后把Sign-up enabled前面的勾点掉，如图： 保存改变之后，退出root账号，重新看一下，gitlab的注册功能就暂时被取消了，需要的时候再开即可。 配置域名为了方便记忆，给gitlab服务配置一个域名，在阿里云的域名解析控制台给gitlab配置了域名之后，还要在gitlab.yml手动更改hostanme，把hostname改成域名的样子，如图： 这样没有结束，因为网页里的url还是显示外网IP而非域名,如下： 此时需要重启，重启的命令是gitlab-ctl restart，重启完了之后url也会发生变化。这样才算完整的配置了域名：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过阿里云服务器ID添加服务器资料到django的脚本]]></title>
    <url>%2F2018%2F05%2F07%2F%E9%80%9A%E8%BF%87%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8ID%E6%B7%BB%E5%8A%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B5%84%E6%96%99%E5%88%B0django%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[本文的环境是：centos 7 + django 2.0 + python 3.6 先给django里的project创建了models.py，里面内容如下： 123456789101112131415from django.db import models# Create your models here.class ecs(models.Model): name = models.CharField(verbose_name='云服务器名称',max_length=30) ecsid = models.CharField(verbose_name='云服务器ID',max_length=30,default='') inIP = models.GenericIPAddressField(verbose_name='云服务器内网地址') outIP = models.GenericIPAddressField(verbose_name='云服务器外网地址') osname = models.CharField(verbose_name='操作系统',max_length=50,default='') networktype = models.CharField(verbose_name='网络类型',max_length=20) CPU = models.IntegerField(verbose_name='云服务器CPU',default='2') memory = models.IntegerField(verbose_name='云服务器内存',default='2048') netwidth = models.IntegerField(verbose_name='云服务器外网带宽',default='0M') signtime = models.DateField(auto_now_add=True) remark = models.CharField(verbose_name='备注',max_length=255,blank=True) 可以看出这个就是一个很简单的云服务器的配置统计，但是要录入的阿里云服务器很多，一个一个手动输入实在太累，于是就要写一个脚本来达到django同步的效果！ 脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/env python#coding=utf-8#这个脚本通过查询阿里云服务器ID来达到同步django的目的import json,pymysqlfrom aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeInstancesRequestclt = client.AcsClient('这里是ak','这里是sk','这里是地域名')# 设置参数request = DescribeInstancesRequest.DescribeInstancesRequest()request.set_accept_format('json')request.add_query_param('RegionId', 'cn-hangzhou')request.add_query_param('InstanceIds', ['这里是服务器ID']) #如果是多个服务器ID，可以继续往下写# 发起请求response = clt.do_action(request)#print(response) #这里可以看一下返回的response，但是它是byte格式的data=str(response, encoding = "utf-8")ecs = json.loads(data) #转换成str格式name = str(ecs['Instances']['Instance'][0]['InstanceName'])ecsid = str(ecs['Instances']['Instance'][0]['InstanceId'])inIP = str(ecs['Instances']['Instance'][0]['VpcAttributes']['PrivateIpAddress']['IpAddress'])[1:-1] #如果不加[1:-1]的话，得到的是一个IP外面还有中括号outIP = str(ecs['Instances']['Instance'][0]['PublicIpAddress']['IpAddress'])[1:-1]networktype = str(ecs['Instances']['Instance'][0]['InstanceNetworkType'])CPU = int(ecs['Instances']['Instance'][0]['Cpu'])memory = int(ecs['Instances']['Instance'][0]['Memory'])osname = str(ecs['Instances']['Instance'][0]['OSName'])#创建数据库连接，注意这里我加入了charset和cursorclass参数conn = pymysql.connect( host = "127.0.0.1", user = "数据库账号", password = "数据库密码", database = "数据库名称", charset = 'utf8', cursorclass = pymysql.cursors.DictCursor)#获取游标cursor = conn.cursor()#三个引号里如何加入变量sql = """INSERT INTO ecs_ecs (name,ecsid,inIP,outIP,networktype,CPU,memory,netwidth,signtime,osname) VALUES (%(name)s,%(ecsid)s,%(inIP)s,%(outIP)s,%(networktype)s,%(CPU)d,%(memory)d,%(netwidth)d,NOW(),%(osname)s);""" % dict(name='\''+name+'\'',ecsid= '\''+ecsid+'\'',inIP=inIP,outIP=outIP,networktype='\''+networktype+'\'',CPU=CPU,memory=memory,netwidth=1,osname='\''+osname+'\'')#print (sql) #在这里可以先看看sql输出的是否正确cursor.execute(sql)# 关闭数据库连接conn.close() 正常来说应该是先建立一个def来获取阿里云服务器配置，再来一个def来将各配置录入到数据库里，同时让阿里云服务器的id作为变量，而且还要加上如果sql执行失败就回滚的语句。而我由于是临时使用，所以这个脚本按照流水式写下来的，不过不影响阅读。 ps.进化之后的脚本在我的github里，地址是： https://github.com/RorschachChan/chenWORK/blob/master/通过阿里云ID号将服务器信息同步到django.py 比如现在要添加一个服务器，这个服务器的id是：i-bp12ego6x9srzsytxeqo，如图： 那么对应填写好脚本里的ak/sk之后，就把i-bp12ego6x9srzsytxeqo填写到“服务器ID”的位置 ，执行这个脚本，结果如下： 不过这个脚本有两个缺点：第一：如果阿里云服务器是中文名称，那么使用api查询出现的是十六进制的符号；第二：如果服务器里没有外网IP或者是后开的临时带宽，那么在outIP的地方得到的值是空，sql语句会因为少一项而报错；第三：这个api没有查询服务器带宽值的功能，还需要另外写一个脚本搭配。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>django2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次nginx负载均衡配置问题]]></title>
    <url>%2F2018%2F04%2F28%2F%E8%AE%B0%E4%B8%80%E6%AC%A1nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[故障背景公司有三个实体服务器，内网IP分别是10.1.82.83、10.1.82.84、10.1.82.113，这三个作为源站使用专线连接到了阿里云的一台nginx服务器上，并且通过这个nginx做负载均衡展示这三个服务器里面的网页。负载均衡使用的是nginx 1.12版本，最外面在上一个CDN起到静态页面加速的作用。整个架构如图： CDN的配置界面如下： 但是现在很奇怪的是，所有节点启动之后，外网用户通过负载后访问均指向了10.1.82.84这一台服务器，nginx.conf配置是最小连接数的配置，如下： 123456789101112131415161718192021222324252627upstream eln.dahuatech.com &#123; #ip_hash; #hash $http_x_forwarded_for; #sticky; least_conn; server 10.1.82.83 max_fails=2 fail_timeout=30s; server 10.1.82.84 max_fails=2 fail_timeout=30s; server 10.1.82.113 max_fails=2 fail_timeout=30s;&#125;server &#123; server_name eln.dahuatech.com; listen 80; listen 443 ssl; access_log logs/eln.dahuatech.com.access.log main; error_log logs/eln.dahuatech.com.error.log; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location / &#123; proxy_pass http://eln.dahuatech.com; &#125;&#125; 测试的时候发现，即使绑定美国和香港的节点去curl，是能正常解析到其他机器上的。如下： 然而源站过来的请求IP集中到了只有一个，这太奇怪了。 故障解决后来发现ngnix后端会把http1.1转换成1.0变成短连接，这个连接存在的时间非常短，因为后端响应非常快。所以即使配上了least_conn，其实是没有任何效果的。这样负载均衡的nginx看到所有源站其实一直都是没有连接的，所以也就一直在给第一个转。 既然这样，就取消了least_conn改用轮询，nginx.conf也改成如下的样子： 最后终于均衡了，大功告成！ 后来琢磨了一下，是用sticky其实也是OK的。 几个主流负载均衡软件配置cookie的方法1.Apache的话首先打开httpd.conf配置文件，确保如下配置没有被注释。 1LoadModule usertrack_module modules/mod_usertrack.so 再在virtual host中添加以下配置。 1234CookieName nameCookieExpires "1 days"CookieStyle CookieCookieTracking on 2.Nginx参考以下配置，设置Cookie。 123456789server &#123; listen 8080; server_name wqwq.example.com; location / &#123; add_header Set-Cookie name=xxxx; root html; index index.html index.htm; &#125;&#125; 3.Lighttpd参考以下配置，设置Cookie。 12345server.modules = ( "mod_setenv" )$HTTP["host"] == "test.example.com" &#123; server.document-root = "/var/www/html/" setenv.add-response-header = ( "Set-Cookie" =&gt; "name=XXXXXX" &#125;&#125; 扩展阅读https://cloud.tencent.com/document/product/214/2736http://blog.text.wiki/2015/08/01/nginx-sticky-problem.htmlhttps://cloud.tencent.com/developer/article/1004547]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次阿里云oss云存储删除失败的问题]]></title>
    <url>%2F2018%2F04%2F27%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%98%BF%E9%87%8C%E4%BA%91oss%E4%BA%91%E5%AD%98%E5%82%A8%E5%88%A0%E9%99%A4%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[公司每天云存储都要删除过期的内容，工作细节是这样的：每天零点，采集模块开始收集应该删除掉的内容，然后把这个消息传给阿里云MQ，阿里云MQ又把消息传给删除模块，删除模块拿到名单之后，开始调用阿里云OSS的删除API进行删除。架构如图： 但是今天登陆监控平台发现，昨天oss没有删除，上涨了80多个T，如图： 老板一看，卧槽这怎么可以，80多个T的云存储费用可是不容小视的，于是责令追查一下为啥会发生这样的情况。 昨天我的手机又没有收到任何阿里云消息队列告警的信息，可见MQ应该是没问题的，查看一下是否有MQ的产生和消费情况，如下图： 产生的消息基本都消费掉了，由此推断之前的过程都应该是OK的。再查看一下会不会是删除模块外网带宽到期的问题，此时发现两天的流量有显著的不同： 流量明显减少，可以说是删除模块执行任务少了。于是到执行OSS删除API的模块上去抓了几个包，里面情况如下： 但是跑到阿里云对应的bucket里看一下文件情况，比如https://lechangecloud.oss-cn-hangzhou.aliyuncs.com/lechange/4B01F1FPAGE4E9D_img/Alarm/20180427000913997_0_fa62bec6dee24cc0bee42e1ee3e75743_thumb_qcif.dav这个文件，这个文件明明还在里面躺着好好的。如图： 文件00：27的时候就在了，但是2：53分的时候调用阿里云OSS的API去删除，明明返回了200，但是文件却没有真正的从OSS删除掉。 我觉得这样就拿去跟阿里云撕逼还是有点不太妥当，又回到刚刚的那个包里，我发现里面还有一些返回的内容是这样的： 这个图跟之前的图明显路径上不同，而这些文件在OSS上确认是被成功删除掉的，可见的确是文件路径的问题：失败的文件路径是完全路径，而成功的都是相对路径。于是就告诉开发赶快整改代码，把路径统一…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在安装docker私有仓库的时候遇到的openssl问题]]></title>
    <url>%2F2018%2F04%2F21%2F%E5%9C%A8%E5%AE%89%E8%A3%85docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E7%9A%84%E6%97%B6%E5%80%99%E9%81%87%E5%88%B0%E7%9A%84openssl%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[按照http://wiki.jikexueyuan.com/project/docker-technology-and-combat/local_repo.html 的方法本地安装一个私有仓库，在执行sudo pip install docker-registry这一步的时候，出现了这样的一个错误： 既然说我没有swig，于是我yum install swig -y，安装的是2.0.10-5.el7版本。然后再次pip install docker-registry，一顿噼里啪啦之后，这次成了这样： 又说没有openssl的文件，那执行yum install openssl-devel，OK了之后再次pip install docker-registry，再一次噼里啪啦，如下： 反馈我：/usr/include/openssl/opensslconf.h:44: Error: CPP #error &quot;&quot;This openssl-devel package does not work your architecture?&quot;&quot;. Use the -cpperraswarn option to continue swig processing.,这个提示大意是说openssl-devel版本不适合你的系统架构，也就是x86的去找x86的头文件，x86_64的去找x86_64文件，但现在是互相找不到对方。 既然说/usr/include/openssl/opensslconf.h这个第44行有错误，那我们就打开这个文件去看看第44行写的是啥： 123456741 #elif defined(__x86_64__)42 #include "opensslconf-x86_64.h"43 #else44 #error "This openssl-devel package does not work your architecture?"45 #endif46 47 #undef openssl_opensslconf_multilib_redirection_h 这里我把第44行改成了这样： 123456741 #elif defined(__x86_64__)42 #include &quot;opensslconf-x86_64.h&quot;43 #else44 #include &quot;opensslconf.h&quot; #去掉了原来的error提示，改成了安装opensslconf.h文件。45 #endif46 47 #undef openssl_opensslconf_multilib_redirection_h 这一次重新执行sudo pip install docker-registry，终于成功…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在国王杯前夕评巴萨]]></title>
    <url>%2F2018%2F04%2F21%2F%E5%9C%A8%E5%9B%BD%E7%8E%8B%E6%9D%AF%E5%89%8D%E5%A4%95%E8%AF%84%E5%B7%B4%E8%90%A8%2F</url>
    <content type="text"><![CDATA[今天凌晨的马竞在西甲意外输给了皇家社会，巴萨的积分优势扩大到了12分。这个周末巴萨要跟塞维利亚打国王杯决赛，4月30号对拉科鲁尼亚的西甲联赛巴萨只要获胜，就会拿到今年的西甲联赛冠军，从而以冠军姿态在诺坎普迎接本赛季第二场国家德比。 巴尔韦德的困境巴萨今年可以说是低姿态开始：从内马尔突然的离开到西超杯被皇马灌了5个，不可为说不惨。但是巴尔韦德在联赛却目前保持不败，这个成绩单可以说是相当不错的，这中间还有在伯纳乌的三球胜利。 赛季中前段，巴萨三线顺风顺水，前有塞梅多惊艳开场，后有大祭司维尔马伦扎实顶上，主教练巴尔韦德也给了阿奈斯这样小将出场机会，哪怕登贝莱那时候养伤，报纸媒体一片其乐融融。如果保利尼奥再有进球，更是一片狂欢。 然后巴尔韦德的保守开始慢慢让人所诟病，他是一个重视防守的教练，这很好，但是他有了库迪尼奥也有了归来的登贝莱，结果反而不敢搞轮换，甚至坚持让布教授打封闭出场，虽然不少人抱怨，但是由于球队整体战绩还算平稳，所以没有大规模的重视。可是巴萨欧冠的结果跟恩里克的第二个赛季一样，倒在了与罗马的第二回合比赛里，连续三年没有闯入欧冠四强。 其实对战罗马的第一回合，巴萨的4：1已经是靠意志拼下来的比赛，球员难免在第二回合的心态上有所轻敌，这种心态上的轻敌难免会影响到身体，但是巴尔韦德的临场指挥也让人严重不满。落下这耻辱一战，媒体和球迷之前的“忍气吞声”一并爆发，狂轰滥炸，直到现在依旧有人说“哪怕真的赛季双冠，也会因为欧冠的失利而让那两冠索然无味”。 所以，巴尔韦德要在这个周日的国王杯决赛和对阵拉科鲁尼亚的西甲联赛里稳扎稳打，把国王杯和西甲冠军彻底拿到手里，这样整个人也能轻松一些。可是说来说去罗马一役这一个跟头摔得太疼了，在那么重大的比赛里失败，肯定需要在一个同样重大的比赛里胜利以挽回颜面，第二回合的国家德比无疑就是一个好的机会，如果巴尔韦德成功捍卫了诺坎普，“联赛双杀皇马+国内双冠”也能成为一个功劳。但是如果那场比赛，一心要打破巴萨不败金身的皇马真的成功了，那巴尔韦德势必在巴萨主帅的位置上也是飘摇。 所以巴帅，请务必要拿下国王杯冠军+西甲冠军！在第二个国家德比里也请拼尽全力！这样才能多少挽回一点“罗马之耻”的颜面。 夏季转会展望我个人认为，巴萨很有可能在今年夏天卖掉如下几个人：西莱森、戈麦斯、小苏亚雷斯、艾尔卡塞尔、比达尔，自由走人的可能会是小白。这些人能套现7000万应该就满足了。 巴萨后卫现在四个人皮克和维尔马伦属于潜藏的伤员病号，米纳技术还是太糙，稍微让人放心的就是乌姆蒂蒂，他的续约问题肯定是休赛期的一个大事。不过我觉得米纳其实可以再留一年看看，他身体素质很好，而且人还年轻没伤病，只要心态练得沉稳，当一个合格的中后卫不难。 至于中场，个人希望小白再踢一年，现在我也觉得一个满血的小白应付普通的联赛、欧冠小组赛和杯赛都不是什么难事。但是目前的媒体趋势是小白赛季结束会来中超重庆队，即使这样巴萨也需要一个山寨的坎特和一个山寨的埃里克森，而罗贝托集这两个属性于一身，所以他就是一个“奉献的砖”，但是这样如果比达尔真的不留下来的话，巴萨还需要补进一个右后卫跟塞梅多良性竞争，这个右后卫的人选就比较挠头了。贝莱林？或许是一个选择，但是这个选择跟当年小法一样—要是双输就不好了。 前场如果能拿下格里兹曼肯定是好的，艾尔卡塞尔这种“躲着后卫”的踢法，虽然进球效率可以，但是没有真正起到轮换苏亚雷斯的作用。这样巴萨还需要在板凳上补充一个中锋（不用多能进球，哪怕搅屎棍也可以），同时也做好登贝莱/苏亚雷斯/梅西/格里兹曼（假设他真的来）的轮换。 总而言之，现在巴萨还是回归433比较好，配合442和4312的变化。那么休赛期最重要的补强就是格里兹曼+能抗中卫的前锋+一个中场+一个优秀的边后卫。 我个人希望的引援名单如下：中场是魏格尔和B队的阿莱尼亚，埃里克森、博格巴和维拉蒂这三个不算是好的选择，要么太贵，要么节奏太慢。至于伊斯科、大卫席尔瓦、皮亚尼奇，那想都别想了，母队不会放人的。至于格雷茨卡，拜仁不是善茬；边后卫可以考虑贝莱林，这个要看一下阿森纳的新教练是谁，摩纳哥的法比尼奥也可以，我知道他现在改中场了，也不耽误来一下跟罗贝托交叉换位…前锋的话，我个人推荐B队阿奈斯试试看，其他的人选估计就是在西甲联赛内部找了；这几个位置，最重要就是中场！梅西当初在哈白布的配合下威力无穷，一旦巴萨的中场重新掌握了控制力，不用频繁回撤的梅西依旧会进球如麻，这一点毋庸置疑。 温格会来？我个人首先不希望巴尔韦德下课，毕竟现在巴萨联赛冠军十拿九稳，国王杯如果也揽入怀中，这样一个成绩单也是一个80分，如果这个分数都炒掉主教练，那么继任者的压力势必很大，所以我个人倾向巴尔韦德留任，好好想一下，等阿图尔以及可能会来的格里兹曼到位了，巴萨应该怎么打。 不过如果温格真的来了，我个人也是赞成的，因为阿森纳的球风本来跟巴萨相似，相信温格跟梅西等人也会无缝接入，到时候教授或许真的可以在巴萨圆了欧冠梦想，不过这个想法成真的可能性低于5%，想想就得了。 下赛季的任务1.进攻体系依旧围绕梅西建队，让梅西继续火力全开的同时保证休息，欧冠要他有大用；2.新球员（包括库蒂尼奥和登贝莱）适应巴萨的风格和体系，让皮克和布教授也能轮换得到休息；3.欧冠一定要进入四强；4.欧冠四强的基础上，西甲联赛冠军和国王杯能拿还是要拿，同时最好也能阻击皇马；]]></content>
      <categories>
        <category>追乱花天</category>
      </categories>
      <tags>
        <tag>国际足坛</tag>
        <tag>巴塞罗那</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国内Docker的加速方法]]></title>
    <url>%2F2018%2F04%2F20%2F%E5%9B%BD%E5%86%85Docker%E7%9A%84%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[由于大陆政府的特殊政策，国内想访问一些国外的资源是非常的曲折和痛苦，比较有代表性的就是亚马逊的云存储以及docker，尤其在docker pull一些镜像的时候，更是心惊胆战，祈求不要出现timout，然而现实往往很骨感。如下图： 那么应该如何达到加速的效果呢？ 在CentOS 7里，对于使用systemd的系统，请在/etc/docker/daemon.json中写入如下内容：（如果文件不存在请新建该文件） 12345&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125; 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。 12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 注意：如果您之前查看旧教程，修改了docker.service文件内容，请去掉您添加的内容（–registry-mirror=https://registry.docker-cn.com）。 配置加速之后，如果拉取镜像仍然十分缓慢，请手动检查加速器配置是否生效，在命令行执行docker info |grep &#39;Registry Mirrors&#39; -A，如果从结果中看到了如下内容，说明配置成功。 现在再重新尝试一下docker pull training/webapp，看看效果： 仅用17秒就pull了几乎400MB的镜像，高下立判！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Grafana里添加worldping插件]]></title>
    <url>%2F2018%2F04%2F19%2F%E5%9C%A8Grafana%E9%87%8C%E6%B7%BB%E5%8A%A0worldping%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[安装插件worldping是一个监控网站的dns、ping、http响应、https响应的插件，要安装它很简单，在granafa服务器里执行如下命令： 12grafana-cli plugins install raintank-worldping-appsystemctl restart grafana-server.service 执行完毕之后在grafana的界面里选择Plugins，然后在APP里找到worldping，启动它，但是此时发现需要一个api，如图： 此时你需要登录grafana的官网，然后点击api keys和ADD API KEY，就可以生成一个API KEY，名字可以随便起，如下： 将生成的api key保存好，并且填回到grafana的api key里，这样worldping插件就可以使用了，如图： 监控网站节点此时点击黄色旋涡，发现多了worldping的选项，点击worldping Home，如图： 然后点击+ New Endpoint，这里我输入我公司的官网域名，然后begin auto-discovery，如图： 生成了结果之后，点击add，此时开始检查几个大城市，如芝加哥、东京、纽约、巴黎等大城市连接到刚刚输入的域名的情况，如图： 大约需要1~2分钟后，数据检查完成，可以点击GO to Summary Dashboard，就会看到图像了： 为什么我这个图里没有http?因为在nginx里我们做了http强制rewrite跳转到https，所以是读不到值的。 删除网站节点如果要删除网站节点，还是在worldping里点击要删除网站后面的齿轮图标，如图： 然后选择configuration，这里可以修改网站域名，要删除的话，选择最下面的destory，输入DELETE确认，然后就可以点击DELETE删除了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>grafana</tag>
        <tag>图像监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用非root用户启动tomcat进程]]></title>
    <url>%2F2018%2F04%2F18%2F%E4%BD%BF%E7%94%A8%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E5%90%AF%E5%8A%A8tomcat%2F</url>
    <content type="text"><![CDATA[使用非root用户启动进程是运维安全的一个主要环节，拿tomcat进程来说，如果是使用root用户去启动了tomcat，那么有一个严重的问题，那就是tomcat具有root权限。这意味着你的任何一个jsp脚本都具有root权限，所以那些不怀好意的人可以轻易地用jsp脚本去搞破坏，甚至删除你整个硬盘里的东西！所以为了活着，我们要极力避免这种现象。很多的软件都自带的用户/用户组，比如nginx、zabbix、elasticsearch，但是也有很多的软件没有这么贴心的服务，这就需要我们手动的更改了。 使用非root用户启动tomcat以tomcat为例，打算用chris账号(属于chen这个group)启动。那么首先先创建账号和组，如下： 12345[root@chen-docker ~]groupadd chen #创建chen这个组[root@chen-docker ~]useradd -s /bin/bash -g chen chris #在这个组里面添加chris这个用户[root@chen-docker ~]passwd chris #给这个用户设定密码[root@chen-docker ~]# id chrisuid=1000(chris) gid=1002(chen) groups=1002(chen) #可见添加成功 su chris切换到chris用户，在/home/chris里使用wget http://apache.fayea.com/tomcat/tomcat-9/v9.0.7/bin/apache-tomcat-9.0.7.tar.gz下载tomcat。然后解压缩在/home/chris里，因为chris用户在这里是有权限的。然后进行如下的操作： 12345cd ~/ 代表用户所在目录mkdir -p ~/shell-scriptcd ~/shell-script/touch start.shtoush stop.sh 这个start.sh的内容很简单，如下： 12345678#/bin/bashif [ "root" == "$USER" ] #不让root启动then echo "can't start with user 'root',retry after change user!" exit 1else cd /home/chris/apache-tomcat-9.0.7/bin/ &amp;&amp; ./start.shfi shutdown.sh的内容同理： 12345678#/bin/bashif [ "root" == "$USER" ] #不让root启动then echo "can't start with user 'root',retry after change user!" exit 1else cd /home/chris/apache-tomcat-9.0.7/bin/ &amp;&amp; ./shutdown.shfi chmod +x *.sh给上面两个脚本可执行权限，但是现在执行startup.sh或者shutdown.sh会出现一个问题： 12Neither the JAVA_HOME nor the JRE_HOME environment variable is definedAt least one of these environment variable is needed to run this program 这是因为chris用户没有权限去启动java这个可执行程序，如果使用java -version回答是bash: java: command not found，这个时候怎么办？ 编辑~/.bash_profile，在末尾处加上如下的内容： 然后source .bash_profile，再使用java -version确认一下应该是OK了。这个时候也是可以使用chris用户去启动刚刚的那个start.sh和shutdown.sh的。 由于我们的tomcat是源码解压缩，所以要使用root用户去创建一下/etc/init.d/tomcat。里面内容如下： 123456789#!/bin/bashcase $1 instart)su - chris -lc "sh /home/chris/shell-script/start.sh";; #如果要root启动，那就是su - root -lc "sh /home/utomcat/shell-script/start.sh";;stop)su - chris -lc "sh /home/chris/shell-script/shutdown.sh";;*)echo "parameter error, usage:(start|stop)";;esac 保存之后，执行一下service tomcat start看看效果。 如果要设置开机自启动，别忘了chkconfig --add tomcat和chkconfig tomcat on，在浏览器打开ip:8080看见汤姆猫~ 当普通用户要使用1024以下的端口众所周知，linux默认是不准许普通用户调用1024以下的端口的，那么遇到这样的需求怎么办呢？最好的方法是使用iptables。 首先让程序运行在非root帐户下，并绑定高于1024的端口，在确保能正常工作的时候，将低端口通过端口转发，将低端口转到高端口，从而实现非root运行的程序绑定低端口。要使用此方法可以使用下面的方式： 1234sysctl -w net.ipv4.ip_forward=1 #要长久保存，需要在/etc/sysctl.conf文件内修改，然后sysctl -p /etc/sysctl.confiptables -F -t natiptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to:8088 #将80端口转发到8088iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080 #这句话也可以 这么操作在速度上没有任何影响。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>运维安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用非root启动进程以及启动docker]]></title>
    <url>%2F2018%2F04%2F18%2F%E7%94%A8%E9%9D%9Eroot%E5%90%AF%E5%8A%A8%E8%BF%9B%E7%A8%8B%E4%BB%A5%E5%8F%8A%E5%90%AF%E5%8A%A8docker%2F</url>
    <content type="text"><![CDATA[使用非root用户启动普通进程使用非root用户启动进程是运维安全的一个主要环节，拿tomcat进程来说，如果是使用root用户去启动了tomcat，那么有一个严重的问题，那就是tomcat具有root权限。这意味着你的任何一个jsp脚本都具有root权限，所以那些不怀好意的人可以轻易地用jsp脚本去搞破坏，甚至删除你整个硬盘里的东西！所以为了活着，我们要极力避免这种现象。 很多的软件都自带的用户/用户组，比如nginx、zabbix、elasticsearch，但是也有更多的软件没有这么贴心的服务，这就需要我们手动的更改了。 docker不应该使用root启动1.8版本之前的docker是不支持user namespace的，所以那样的话，如果在docker容器内部使用root运行app，那么不可否认，这个root和宿主机的root是同一个UID。但是，需要特别注意的是，容器内的root与宿主机上的root权限并不一定是相等的。 但是为了绝对的安全，还是推荐把docker升级到1.8以上，然后彻底避免用root去启动容器，在http://www.projectatomic.io/docs/docker-image-author-guidance/里最下面一段也明文说了---生产环境里不要用root用户去启动docker!!! 使用非root用户启动docker的办法如下：创建docker组：sudo groupadd docker将当前用户加入docker组：sudo gpasswd -a ${USER} docker重新启动docker服务：sudo service docker restart或sudo systemctl restart docker当前用户退出系统再重新登陆。 参考资料https://www.zhihu.com/question/25580965]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用docker做一个主从同步的redis集群]]></title>
    <url>%2F2018%2F04%2F18%2F%E4%BD%BF%E7%94%A8docker%E5%81%9A%E4%B8%80%E4%B8%AA%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%9A%84redis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[查看容器内部信息之前用docker run -it --name redis-master redis /bin/bash创建了一个redis的docker，现在登陆发现状态已经是exit，于是就使用docker container start 容器ID号or容器名称来重新启动。如图： 然后书里说到要用docker inspect来查看所挂载volume的情况，使用命令: 1[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .Volumes &#125;&#125;&quot; f391531120b0 但是很不幸，系统反馈给我一个错误： 1Template parsing error: template: :1:3: executing &quot;&quot; at &lt;.Volumes&gt;: map has no entry for key &quot;Volumes&quot; 没有这个Volumes，那就干脆查看一下这个容器的所有信息：docker inspect f391531120b0，这个命令里面有Config、Mounts、HostConfig、NetworkSettings等等整个容器的所有信息，比如看一下NetworkSettings相关的内容，如图： 此时使用如下命令： 1234[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&quot; f391531120b0 #注意前面的.192.168.0.2[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .NetworkSettings.MacAddress &#125;&#125;&quot; f391531120b002:42:c0:a8:00:02 这样就可以获取到内网IP和mac地址，同理换成docker inspect f391531120b0 | grep Mounts -A 10，看一下挂载信息，如图： 原来容器里的/data其实就是宿主机的/var/lib/docker/volumes/94b3c20a6d269c7498ab59ee45c560e84fed64a636767a4baa54fa7befbcd4ff/_data这个文件夹。为了验证这一点，我先到宿主机去创建一个叫aaa文件，如下： 12root@f391531120b0:/data# cat aaa 123123 再返回到宿主机上看： 12345[root@chen-docker ~]# cd /var/lib/docker/volumes/94b3c20a6d269c7498ab59ee45c560e84fed64a636767a4baa54fa7befbcd4ff/_data[root@chen-docker _data]# lsaaa[root@chen-docker _data]# cat aaa 123123 这就搞定了！ 主从同步排错就是按书里写的开始配置和启动redis-slave，但是却发现同步没有成功，在redis-slave日志里发现这样的话： 12332677:S 08 Feb 16:14:40.952 * Connecting to MASTER 172.168.10.70:637932677:S 08 Feb 16:14:40.952 * MASTER &lt;-&gt; SLAVE sync started32677:S 08 Feb 16:14:40.953 # Error condition on socket for SYNC: Connection refused 这个的原因就是redis主服务器绑定了127.0.0.1，那么跨服务器IP的访问就会失败，从服务器用IP和端口访问主的时候，主服务器发现本机6379端口绑在了127.0.0.1上，也就是只能本机才能访问，外部请求会被过滤。所以需要修改redis-master的redis.conf，注释掉bind 127.0.0.1，如果是线上生产环境建议绑定IP地址。 重新启动redis之后，发现同步依然失败，日志变成了这样： 12345690:S 17 Apr 09:27:35.906 * Non blocking connect for SYNC fired the event.90:S 17 Apr 09:27:35.907 # Error reply to PING from master: &apos;-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect&apos;90:S 17 Apr 09:27:36.908 * Connecting to MASTER 192.168.0.2:637990:S 17 Apr 09:27:36.909 * MASTER &lt;-&gt; SLAVE sync started90:S 17 Apr 09:27:36.909 * Non blocking connect for SYNC fired the event.90:S 17 Apr 09:27:36.909 # Error condition on socket for SYNC: Connection reset by peer 这个日志的意思是说redis在没有开启bind和密码的情况下，保护模式被开启。然后Redis的只接受来自环回IPv4和IPv6地址的连接。于是还是要修改redis-master的redis.conf关闭保护模式：portected-mode no，然后重启redis-master即可。 容器内安装ping先检查你的容器是使用什么系统的景象，如果是ubantu那就是apt-get，安装ping的命令如下： 12apt-get updateapt-get install inetutils-ping 如何让容器一直启动如果用了一段时间的docker就会发现，我们的容器经常用了一段时间就自动退出了，docker ps已经找不到了，在docker ps -a里面了，如图： 然后我们docker start containerId想重新开启这个容器，可能这次来的更快，没几分钟容器又自己关了，由这个问题又可能引发其它很多的问题。 docker run指定的命令如果不是那些一直挂起的命令（比如运行top，不断echo），就是会自动退出的。-d命令是设置detach为true，根据官方的文档，意思是让这个命令在后台运行，但并不是一直运行，Docker容器后台运行,就必须有一个前台进程。主线程结束，容器会退出。 我们启动容器的时候不要-d命令启动，用-dit就好了，例如： 12docker run -d hello-world(不要这么做)docker run -dit hello-world(推荐)]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>docker</tag>
        <tag>主从同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix监控memcache]]></title>
    <url>%2F2018%2F04%2F03%2F%E4%BD%BF%E7%94%A8zabbix%E7%9B%91%E6%8E%A7memcache%2F</url>
    <content type="text"><![CDATA[监控memcache的原理跟监控redis差不多，都是通过一个类似info的东西可以查询到memcache的状态值，然后通过脚本去获取这些值给zabbix，当发现某值不正常就发出告警。 查询当年memcache状态的命令是echo stats |nc 127.0.0.1 11211，如果没有nc命令，那就yum install -y nc。 获得到的结果是这个样子的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@lconline-ec2 ~]# echo stats |nc 127.0.0.1 11211STAT pid 1859 memcache服务进程IDSTAT uptime 491093 服务器已运行秒数STAT time 1522740969 服务器当前Unix时间戳STAT version 1.4.25 memcache版本STAT libevent 1.4.13-stableSTAT pointer_size 64 操作系统指针大小STAT rusage_user 14.321822 进程累计用户时间STAT rusage_system 14.095857 进程累计系统时间STAT curr_connections 5 当前连接数量STAT total_connections 51010 Memcached运行以来连接总数STAT connection_structures 8 Memcached分配的连接结构数量STAT reserved_fds 20STAT cmd_get 0 get命令请求次数STAT cmd_set 0 set命令请求次数STAT cmd_flush 0 flush命令请求次数STAT cmd_touch 0 touch命令请求次数STAT get_hits 0 get命令命中次数STAT get_misses 0 get命令未命中次数STAT delete_misses 0 delete命令未命中次数STAT delete_hits 0 delete命令命中次数STAT incr_misses 0 incr命令未命中次数STAT incr_hits 0 incr命令命中次数STAT decr_misses 0 decr命令未命中次数STAT decr_hits 0 decr命令命中次数STAT cas_misses 0 cas命令未命中次数STAT cas_hits 0 cas命令命中次数STAT cas_badval 0 使用擦拭次数STAT touch_hits 0STAT touch_misses 0STAT auth_cmds 0 认证命令处理的次数 STAT auth_errors 0 认证失败数目STAT bytes_read 357040 读取总字节数 STAT bytes_written 60197691 发送总字节数STAT limit_maxbytes 1073741824 分配的内存总大小（字节）STAT accepting_conns 1 服务器是否达到过最大连接（0/1）STAT listen_disabled_num 0 失效的监听数STAT time_in_listen_disabled_us 0STAT threads 4 当前线程数STAT conn_yields 0 连接操作主动放弃数目STAT hash_power_level 16STAT hash_bytes 524288 当前存储占用的字节数STAT hash_is_expanding 0STAT malloc_fails 0 STAT bytes 0 当前存储占用的字节数STAT curr_items 0 当前存储的数据总数STAT total_items 0 启动以来存储的数据总数STAT expired_unfetched 0 STAT evicted_unfetched 0STAT evictions 0 LRU释放的对象数目STAT reclaimed 0 已过期的数据条目来存储新数据的数目STAT crawler_reclaimed 0STAT crawler_items_checked 0STAT lrutail_reflocked 0 END 修改zabbix_agentd.conf，添加一个新的自定义项： 1UserParameter=memcached.stat[*],(echo stats; sleep 1) | telnet 127.0.0.1 11211 2&gt;&amp;1 | awk '/STAT $1 / &#123;print $NF&#125;' 然后重启zabbix-agent，模板就用github里的就好，看到的效果如下：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix去监控网站和tcp连接]]></title>
    <url>%2F2018%2F04%2F02%2F%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[网页状态码监控在zabbix的web界面，配置–主机–选择一个有外网权限的服务器，比如选择zabbix server–Web检测，如图： 然后点击右上角的创建Web场景，然后依次填入名称，间隔，客户端等等，如图： 然后编辑步骤，先添加，填入对应的url，然后写上200状态码，意思就是返回200是OK的。保存即可，如果还有http认证，那么就继续填写认证。 至此，一个简单的监控官网状态码的配置过程就结束了，剩下就是增添一下触发器，如下： tcp连接监控首先在zabbix-agentd.conf里添加一个新的自定义监控项： 1UserParameter=tcp.status[*],netstat -a | awk '/^tcp/ &#123;++y[$NF]&#125; END &#123;for(i in y) print i,y[i]&#125;' | grep $1 | awk '&#123;print $NF&#125;' 然后service zabbix-agent restart重启客户端，模板就是https://gitee.com/careyjike_173/zabbix/tree/master/template 里的zbx_tcp_status_templates.xml，直接导入即可。如图： 然后自己配置一下time_wait/close_wait的告警阈值。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>web监控</tag>
        <tag>tcp连接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix去监控php-fpm]]></title>
    <url>%2F2018%2F04%2F02%2F%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7php-fpm%2F</url>
    <content type="text"><![CDATA[开启状态统计nginx有一个status来获取nginx处理信息的总览情况，php-fpm也有一个状态统计。要打开这个状态统计，需要先打开php-fpm.conf，将pm.status_path = /status前面的注释去掉。 然后跑到nginx里，在nginx.conf里添加一个location： 1234567 location ~ ^/(status|ping) &#123; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf; access_log off; allow 127.0.0.1; deny all;&#125; 然后重启一下php-fpm和nginx，在命令行里输入curl -s http://127.0.0.1:80/status，就会看到php的状态统计，如下图： php-fpm status详解pool - fpm池子名称，大多数为wwwprocess manager – 进程管理方式,值：static, dynamicstart time– 启动日期,如果reload了php-fpm，时间会更新start since – 运行时长accepted conn – 当前池子接受的请求数listen queue – 请求等待队列，如果这个值不为0，那么要增加FPM的进程数量max listen queue – 请求等待队列最高的数量listen queue len – socket等待队列长度idle processes – 空闲进程数量active processes – 活跃进程数量total processes – 总进程数量max active processes – 最大的活跃进程数量（FPM启动开始算）max children reached - 大道进程最大数量限制的次数，如果这个数量不为0，那说明你的最大进程数量太小了，请改大一点。slow requests – 启用了php-fpm slow-log，缓慢请求的数量 配置监控跑到zabbix-agentd.conf里添加一个自定义监控项，如下： 1UserParameter=php-fpm.status[*],/usr/bin/curl -s "http://127.0.0.1/php-fpm_status?xml" | grep "&lt;$1&gt;" | awk -F'&gt;|&lt;' '&#123; print $$3&#125;' 然后重启一下zabbix-agent，模板就是https://gitee.com/careyjike_173/zabbix/tree/master/template 里的zbx_php-fpm_templates.xml，直接导入即可！ 效果如下图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix去监控nginx]]></title>
    <url>%2F2018%2F04%2F02%2F%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7nginx%2F</url>
    <content type="text"><![CDATA[准备工作zabbix监控nginx，首先要确认nginx里是否有http_stub_status_module这个模块，一般来说，这个模块是自动安装的，nginx -V如下图： 如果你的nginx没有这个模块，请去看https://rorschachchan.github.io/2018/01/03/Nginx动态编译新的模块/ 。 然后在nginx.conf里添加一段话： 1234 location = /nginx-status &#123; stub_status on; access_log off;&#125; nginx -s reload一下，然后在命令行输入curl http://127.0.0.1/nginx-status，就会看到如下的界面： 这样就可以通过http_stub_status_module检查nginx情况了！ nginx status详解以上图的nginx status来做例子说明一下各个数字的意思：active connections – 活跃的连接数量accepts — 总共处理了3832000个连接handled — 成功创建3832000次握手requests — 总共处理了3295877个请求reading — 读取客户端的连接数writing — 响应数据到客户端的数量waiting — 开启keep-alive的情况下,这个值等于active – (reading+writing), 意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接 配置监控有了模块，还需要添加一个脚本，然后就可以获取上面的数值了，脚本如下： 1234567891011121314151617181920212223242526272829303132#!/bin/bash# Method of useHOST="127.0.0.1"PORT="80" #这个根据实际情况填写URL="http://$&#123;HOST&#125;:$&#123;PORT&#125;/nginx-status"active() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | grep "Active" | awk '&#123;print $NF&#125;'&#125;reading() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | grep "Reading" | awk '&#123;print $2&#125;'&#125;writing() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | grep "Writing" | awk '&#123;print $4&#125;'&#125;waiting() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | grep "Waiting" | awk '&#123;print $NF&#125;'&#125;accepts() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $1&#125;'&#125;handled() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $2&#125;'&#125;requests() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $NF&#125;'&#125;ping() &#123; ps -ef | grep nginx | grep -v grep -c&#125;$1 然后再去zabbix_agentd.conf里添加一句话: 1UserParameter=nginx.status[*],/usr/local/zabbix/script/nginx_status.sh $1 然后service zabbix-agent restart，自定义项就搞定了。 如果要导入模板，https://gitee.com/careyjike_173/zabbix 这个朋友的模板已经非常全面了，根据实际情况修改之后再导入他的xml就好，感谢前人付出！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[金山云api调用的两个例子]]></title>
    <url>%2F2018%2F03%2F29%2F%E9%87%91%E5%B1%B1%E4%BA%91api%E8%B0%83%E7%94%A8%E7%9A%84%E4%B8%A4%E4%B8%AA%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[今天另外一个运维要看一下金山云API返回的格式，于是就临时写了两个demo，也顺便记录下来，说不定以后开发脚本的时候可能用的着。 查询数据库的脚本需要先获取https://github.com/kscdb/krds_openapi_sdk.git，然后执行python setup.py install安装所用的金山库。 这个脚本是查询某个数据库的具体情况： 脚本如下： 1234567891011121314#!/usr/bin/env python# -*- encoding:utf-8 -*-from kscore.session import get_sessionfrom krds_client import *#密钥ACCESS_KEY_ID = "这里填写ak"SECRET_ACCESS_KEY = "这里填写sk"#连接s = get_session()krds_client = KRDSClient(ACCESS_KEY_ID, SECRET_ACCESS_KEY, '地域名')r = krds_client.DescribeDBInstances(DBInstanceIdentifier='5c664b16-fbfe-4373-8a00-67c9476e7386',DBInstanceType='HA') #DBInstanceIdentifier后面是实例IDprint r 执行脚本之后，可以看到返回的结果包括数据库里很多的资料，如图： 如果不加参数的话，就是返回账号内所有的数据库情况。 查询服务器的脚本需要先获取https://github.com/KscSDK/ksc-sdk-python.git，然后执行python setup.py install安装所用的金山库。 这个脚本是查询下面这个服务器的情况： 脚本如下： 123456789101112#!/usr/bin/env python# -*- encoding:utf-8 -*-from kscore.session import get_session#密钥ACCESS_KEY_ID = "这里填写ak"SECRET_ACCESS_KEY = "这里填写sk"#连接s = get_session()client = s.create_client("kec", "地域名", use_ssl=True,ks_access_key_id=ACCESS_KEY_ID, ks_secret_access_key=SECRET_ACCESS_KEY)print client.describe_instances(Search=['js-online-hlsproxy-20']) #Search后面接实例名 执行脚本之后，可以看到返回的结果包括数据库里很多的资料，如图： 如果不加参数的话，就是返回账号内所有的服务器情况。 参考资料https://github.com/KscSDK/ksc-sdk-pythonhttps://github.com/kscdb/krds_openapi_sdk]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>金山云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用pandas来做html表格]]></title>
    <url>%2F2018%2F03%2F27%2F%E4%BD%BF%E7%94%A8pandas%E6%9D%A5%E5%81%9Ahtml%E8%A1%A8%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[前言最近电子商城慢sql问题引了小BOSS的重视，于是就打算给开发们搞一个表格，在表格里可以看到前一天阿里云数据库的慢sql。这一次我不打算用html邮件了，因为慢sql数量不固定，今天可能三个，明天可能五个，后天抽风可能就一百个。而html邮件的格式是要事先写死的，于是我就用pandas来做这个表格，直接生成一个html文件，通过访问浏览器去让开发看慢sql。 慢日志脚本我要承认，阿里云自带的api在线调试工具真是一个好东西，有了它，脚本demo可以直接生成，地址是：https://api.aliyun.com/?spm=a2c4g.750001.952925.6.1QrDYe ，于是乎，阿里云获取慢日志脚本test.py如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/env python#coding=utf-8import json from aliyunsdkcore import clientfrom aliyunsdkrds.request.v20140815 import DescribeSlowLogRecordsRequest clt = client.AcsClient('这里是ak','这里是sk','这里是地域')# 设置参数request = DescribeSlowLogRecordsRequest.DescribeSlowLogRecordsRequest()request.set_accept_format('json')request.add_query_param('DBInstanceId', 'RDS的ID号')request.add_query_param('StartTime', '2018-03-26T08:00Z') #3月26日早上8点开始request.add_query_param('EndTime', '2018-03-27T08:00Z') #3月27日早上8点结束request.add_query_param('DBName', '对应的数据库名')request.add_query_param('PageSize', 100) #这个值只能是30/50/100# 发起请求response = clt.do_action_with_exception(request)print response#把json格式的返回值改成dict格式slow_log=json.loads(response)num = slow_log['TotalRecordCount']Hostaddress = []LockTimes = []ParseRowCounts = []QueryTimes = []SQLText = []#将有用的值做成listif num &lt; 100: for i in range(0,num): Hostaddress.append(slow_log['Items']['SQLSlowRecord'][i]['HostAddress']) LockTimes.append(slow_log['Items']['SQLSlowRecord'][i]['LockTimes']) ParseRowCounts.append(slow_log['Items']['SQLSlowRecord'][i]['ParseRowCounts']) QueryTimes.append(slow_log['Items']['SQLSlowRecord'][i]['QueryTimes']) SQLText.append(slow_log['Items']['SQLSlowRecord'][i]['SQLText'])else: for i in range(0,100): Hostaddress.append(slow_log['Items']['SQLSlowRecord'][i]['HostAddress']) LockTimes.append(slow_log['Items']['SQLSlowRecord'][i]['LockTimes']) ParseRowCounts.append(slow_log['Items']['SQLSlowRecord'][i]['ParseRowCounts']) QueryTimes.append(slow_log['Items']['SQLSlowRecord'][i]['QueryTimes']) SQLText.append(slow_log['Items']['SQLSlowRecord'][i]['SQLText']) 这个response的格式是一个json，在www.json.cn里查看是这个样子： 可以看到返回值里面TotalRecordCount就是总返回值，如果这个值大于PageSize，那么就会有第二篇，需要手动翻篇。所以我这里直接最大值就是100，一篇100已经够开发看了… 脚本如下在上面的脚本里可以获取到所有慢sql的json格式，那么就可以再写一个脚本把json转化成html格式并且生成一个html文件，然后在nginx里直接把这个文件展示出来。既然用到了pandas库，那么就要先安装pandas,方法如下： 1234pip install --upgrade pippip install pandas如果有“Please upgrade numpy to &gt;= 1.9.0 to use this pandas version”的反应，那么执行下一句pip install -U numpy 生成html的整个脚本如下： 123456789101112131415161718192021222324252627#!/usr/bin/env python#coding=utf-8from test import Hostaddress,LockTimes,ParseRowCounts,QueryTimes,SQLText #从刚写的test.py里得到那些list变量import pandas as pddef convertToHtml(result,title): #将数据转换为html的table #result是list[list1,list2]这样的结构 #title是list结构；和result一一对应。titleList[0]对应resultList[0]这样的一条数据对应html表格中的一列 d = &#123;&#125; index = 0 for t in title: d[t]=result[index] index = index+1 pd.set_option('max_colwidth',200) #默认的行长度是50，这里我调成了200 df = pd.DataFrame(d) df = df[title] h = df.to_html(index=False) return hif __name__ == '__main__': result = [Hostaddress,LockTimes,ParseRowCounts,QueryTimes,SQLText] title = [u'HostAddress',u'LockTimes',u'ParseRowCounts',u'QueryTimes',u'SQLText'] #生成一个叫biaoge.html with open('/nginxhtml路径/biaoge.html', 'w') as f: f.write(convertToHtml(result,title)) print "html文件已经生成！" 执行效果将这个biaoge.html直接生成到nginx的html文件夹里，在浏览器里打开这个html就看到效果了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pandas</tag>
        <tag>大数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次nginx出现了502的问题]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1nginx%E5%87%BA%E7%8E%B0%E4%BA%86502%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[背景交待市场运营在手机APP端推送了一个“家装节，部分商品优惠打折”消息，用户可以通过点击这个消息，在APP进入到商城界面，如果是已经登录的用户将通过免登陆直接跳转，如果是没有登录的用户会登陆到登陆界面。但是刚推送就发现，通过这个推送点击，没有正常登陆到商城界面，而是返回了502。 nginx 502的错误，一般来说就是php-fpm的问题，我登陆到电商服务器发现，php-fpm运行正常而且php-fpm的进程数也很正常。但是查看到mysql，发现mysql的CPU飙升，如图： 于是登陆到数据库里，使用show processlist一看，数据库里有大量的语句处于sending data状态，而且执行时间令人发指（command项处于Sleep状态的进程表示其正在等待接受查询，因此它并没有消耗任何资源，是无害的）： 先赶快通知运营先把推送的消息界面停用掉，不要让更多的用户登陆失败。然后写了一个脚本批量的kill掉这些进程，看看能不能让数据库恢复正常，过程如下。 首先先得到show processlist展现的所有的情况: 1mysql -uroot -p密码 -h数据库地址 -e "show processlist" | grep -i 'Locked' &gt; locked_log.txt 然后获得前面的进程号，并且加上kill的指令: 12345#/bin/bashfor line in `cat locked_log.txt | awk '&#123;print $1&#125;'`do echo "kill $line;" &gt;&gt; kill_thread_id.sqldone 在登陆到数据库，然后执行上面生成的kill_thread_id.sql：: 1mysql&gt;source kill_thread_id.sql 但是发现，kill掉一批之后，又有了新的慢sql出现，CPU依旧高居不下，于是只能跟产品经理说明情况，在征得了产品经理无奈的同意之后，重启了数据库，幸好时间没有很长，就耽误二三分钟而已。重启了之后，CPU就降下去了。赶快叫开发童鞋在线补充一个索引给用户登录的表来解决这个慢sql问题，没有了慢sql就没有了502。 补充nginx499nginx如果爆错499的话，代表客户端主动关闭连接，原因就是后端脚本执行的时间太长了or数据库有慢mysql，调用方超出了timeout的时间，关闭了连接。 这个时候需要更改一下nginx.conf: 12proxy_read_timeout 10s;proxy_send_timeout 10s; 把上面两个值适度调大然后重启nginx即可。或者就是proxy_ignore_client_abort on;，这话就是让代理服务端不要主动关闭客户端的连接。 参考资料https://blog.csdn.net/zhuxineli/article/details/14455029https://segmentfault.com/a/1190000012326158]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python调用redis的基本操作]]></title>
    <url>%2F2018%2F03%2F26%2F%E4%BD%BF%E7%94%A8python%E8%B0%83%E7%94%A8redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言最近有一个需求，里面涉及到把python获取到的数值存储到redis里，于是就简单研究一下python调用redis的方法。 python要调用redis的时候，需要先安装redis模块，有两个方法。第一个方法就是pip install redis，第二个方法就是easy_install redis，模块装完之后，就可以创建redis连接了。 redis-py提供两个类Redis和StrictRedis来实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令（比如，SET命令对应与StrictRedis.set方法）。 Redis是StrictRedis的子类，用于向后兼容旧版本的redis-py。 官方推荐使用StrictRedis方法，所以我这里只说StrictRedis。 如何连接连接的代码如下： 123456789101112&gt;&gt;&gt; import redis#这里是redis的基本情况&gt;&gt;&gt; host = '这里填写redis的host地址'&gt;&gt;&gt; port = 6379 #根据实际情况更改端口&gt;&gt;&gt; password = 'redis对应的密码'#使用StrictRedis去连接到目标redis&gt;&gt;&gt; r = redis.StrictRedis(host=host, port=6379, password=password, db=0) #db为选定的数据库，db=0代表选择了0号数据库。redis默认有16个数据库，在conf里面可以配置。如果没有指定的数据库，可以不写。&gt;&gt;&gt; r.set('age', '88')&gt;&gt;&gt; r.get('age')'88' 关系型数据库都有一个连接池的概念：对于大量redis连接来说，如果使用直接连接redis的方式的话，将会造成大量的TCP的重复连接，所以，就引入连接池来解决这个问题。在使用连接池连接上redis之后，可以从该连接池里面生成连接，调用完成之后，该链接将会返还给连接池，供其他连接请求调用，这样将减少大量redis连接的执行时间，那么使用StrictRedis的连接池的实现方式如下： 12pool = redis.ConnectionPool(host=host, port=6379, password=password)r = redis.StrictRedis(connection_pool=pool 或者使用pipeline（管道），通过缓冲多条命令，然后一次性执行的方法减少服务器-客户端之间TCP数据库包，从而提高效率，方法如下： 1234567891011接上文pipe = r.pipeline()#插入数据&gt;&gt;&gt; pipe.hset("hash_key","leizhu900516",8)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hset("hash_key","chenhuachao",9)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hset("hash_key","wanger",10)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.execute()[1L, 1L, 1L] 批量读取数据的方法如下: 123456789&gt;&gt;&gt; pipe.hget("hash_key","leizhu900516")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hget("hash_key","chenhuachao")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hget("hash_key","wanger")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; result = pipe.execute()&gt;&gt;&gt; print result['8', '9', '10'] #有序的列表 pipeline的命令可以写在一起，如p.set(&#39;hello&#39;,&#39;redis&#39;).sadd(&#39;faz&#39;,&#39;baz&#39;).incr(&#39;num&#39;).execute()，其实它的意思等同于是： 12345&gt;&gt;&gt; p.set('hello','redis')&gt;&gt;&gt; p.sadd('faz','baz')&gt;&gt;&gt; p.incr('num')&gt;&gt;&gt; p.execute()[True, 1, 1] 利用pipeline取值3500条数据，大约需要900ms，如果配合线程or协程来使用，每秒返回1W数据是没有问题的，基本能满足大部分业务。 如何存储上面已经举了一个age：88的例子，可见创建一个string类型的key并放入value是使用set方法，比如再多存几个名字： 123456789101112131415161718192021222324&gt;&gt;&gt; r.set('name', 'lilei')True&gt;&gt;&gt; r.get('name')'lilei'&gt;&gt;&gt; r.set('name2', 'zhaowei')True&gt;&gt;&gt; r.set('name3', 'james')True&gt;&gt;&gt; r.set('name4', 'yaoming')True#列出以name开头的所有key&gt;&gt;&gt; print r.keys("name*")['name3', 'name4', 'name2', 'name']#列出所有key&gt;&gt;&gt; print r.keys()&gt;&gt;&gt; r.dbsize() #当前数据库包含多少条数据 4L&gt;&gt;&gt; r.delete('name')1&gt;&gt;&gt; r.save() #执行“检查点”操作，将数据写回磁盘。保存时阻塞True&gt;&gt;&gt; r.get('name')&gt;&gt;&gt; r.flushdb() #清空r中的所有数据True 还有其他类型的存储方法，简单举例子如下： 1234567891011121314151617#创建一个hashr.hset('abc:def', 'name', "abcde")#获取一个hash的所有值print r.hgetall('abc:def')#获取一个hash的所有key print r.hkeys('abc:def') #创建listr.sadd('abcd:ef','nihao')r.sadd('abcd:ef','hello')r.sadd('xxxx','nihao')r.sadd('xxxx','good')#打印出该key中的值 listprint r.smembers('abcd:ef')#查询两个list中相同的值print r.sinter('abcd:ef', 'xxxx')#给两个list取并集print r.sunion('abcd:ef', 'xxxx') setnx是SET if Not eXists的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。python要使用它也是r.setnx(key,value)，当发现没有这个key的时候，就会插入这个新的key以及对应的value，如果发现有了个这个key了，那这条就等于没加。 如何删除py-redis中有个delete接口，既可以删除单个key，也可以全删除key，如果要删除几个key，用法是:r.delete(&#39;age&#39;)、r.delete(&#39;sex&#39;, &#39;age&#39;)，如果要全删除，那就是 12keys = r.keys()r.delete(*keys) 执行之后的效果等于flushall。 redis里默认情况下是不支持通配符的，那么要批量删除key怎么做呢？答案就是搭配xargs，比如要删除掉所有2018-03-开头的key： 1redis-cli -hredis地址 -a密码 keys "2018-03-*"|xargs redis-cli -hredis地址 -a密码 del python将两个list元素一一对应转换为dict使用python的zip函数和强大的集合操作可以方便的将两个list元素一一对应转换为dict，如下示例代码： 1234names = ['n1','n2','n3']values = [1,2,3] nvs = zip(names,values)nvDict = dict( (name,value) for name,value in nvs) 参考资料https://github.com/andymccurdy/redis-pyhttp://xiaorui.cc/2014/11/10/%E4%BD%BF%E7%94%A8redis-py%E7%9A%84%E4%B8%A4%E4%B8%AA%E7%B1%BBredis%E5%92%8Cstrictredis%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/http://debugo.com/python-redis/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python调用echart画图]]></title>
    <url>%2F2018%2F03%2F22%2F%E4%BD%BF%E7%94%A8python%E8%B0%83%E7%94%A8echart%E7%94%BB%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[前言之前说了如何使用阿里云的SDK获取云存储的值然后发送表格邮件，但是最近领导又发话了，说这个邮件每天一封看的有点审美疲劳，要顺应“数据可视化”的趋势，于是就要求画图，力求直观，要做到“从众多数据中突出特别数据，从特别数据中突出高价值数据”。我之前用python的matplotlib画过，这一次尝试用echart来做图！ echart是不太良心的百度良心的开源作品，提供各种各样精美的作图方案，分分钟把图片做的高大上，吸引周围人的目光。不过我对前端的了解非常浅薄，但是没关系。这次使用pyechart插件！这个插件可以让python直接调用echart接口，选择需要的图形之后，直接往里查数据就好，简单粗暴见效快，而且支持3D，可以说是居家旅行常备物品。可以说，有了它，作图能力顶呱呱。感谢开发者大神们的辛苦工作！ 作图首先先需要安装pyecharts插件，命令是pip install pyecharts。 然后我们就可以写一个简单的案例，如下： 123456789101112131415#!/usr/bin/env python#coding=utf-8from pyecharts import Bar #导入第三方库#attr = ["&#123;&#125;day".format(i) for i in range(1, 8)] #这样的话X坐标就是1day、2day、3day...attr = ["Mon", "Feb", "Wed", "Thu", "Fri", "Sat", "Sun"] #这样X坐标就是星期v1 = [1.49, 2.09, 4.03, 2.23, 5.26, 7.71, 7.56] v2 = [0.3, 0.9, 0.2, 0.4, 0.7, 0.7, 0.6]v3 = [18.15, 13.22, 11.28, 17.99, 18.7, 19.7, 15.6]bar = Bar("乐橙云存储情况总览", "本图表展示过去一周的云存储情况") #这里是主标题和副标题bar.add("录像分享文件", attr, v1, mark_line=["average"], mark_point=["max", "min"]) #每一个值的名称以及要展现平均值和最大最小值bar.add("视频直播文件", attr, v2, mark_line=["average"], mark_point=["max", "min"])bar.add("云录像、报警图片、全景图片", attr, v3, mark_line=["average"], mark_point=["max", "min"]) bar.render('/tmp/111.html') #在/tmp文件夹里生成一个111.html文件 如果服务器里有nginx，那么把这个html文件放到nginx/html路径里，再在浏览器里打开就会看到这样的图： 而且还可以通过点击网页上“A值”、“B值”、“C值”就可以达到屏蔽相应值的效果，而且如果点击红色箭头的“数据视图”，还可以直接看到对应的数据，非常贴心非常屌，如图： 如果你觉得图片有点小，那么可以修改这个地方：bar = Bar(&quot;XXX情况总览&quot;, &quot;本图表展示过去一周的ABC情况&quot;，width=1000,height=900)，我这里把宽和高分别从默认值调成了1000和900。 如果想要在一个html里做多个图，比如要做三个柱状图，那么example如下： 123456789101112131415161718192021222324252627282930#!/usr/bin/env python#coding=utf-8from pyecharts import Bar, Gridattr = ["一班", "二班", "三班", "四班"]v1 = [54, 81, 32, 32] v2 = [68, 69, 27, 32] bar = Bar("赞成票","本图表展示赞成票情况")bar.add("年纪长", attr, v1, mark_point=["max", "min"])bar.add("副年纪长", attr, v2, mark_point=["max", "min"])attr2 = ["一班", "二班", "三班", "四班"]x1 = [2, 0, 0, 1]x2 = [1, 3, 0, 2]bar2 = Bar("反对票","本图表展示反对票情况",title_top='bottom',title_color='#1d12eb') #title_color是标题颜色，这个跟html的颜色取值一样bar2.add("年纪长", attr2, x1, mark_point=["max", "min"])bar2.add("副年纪长", attr2, x2, mark_point=["max", "min"])attr3 = ["一班", "二班", "三班", "四班"]y1 = [2, 0, 0, 1]y2 = [2, 0, 0, 1]bar3 = Bar("弃权票","本图表展示弃权票情况",title_pos='right',title_color='#eb1212') #title_pos是标题的位置，如果不特殊说明，会重叠bar3.add("年纪长", attr3, y1, mark_point=["max", "min"]) bar3.add("副年纪长", attr3, y1, mark_point=["max", "min"])grid = Grid() grid.add(bar, grid_width="40%", grid_height="30%", grid_bottom="60%", grid_right="55%") #grid_height和grid_width是每一个小图的大小grid.add(bar2, grid_width="40%", grid_height="30%", grid_bottom="60%", grid_left="55%") #grid_bottom和grid_top是垂直位置grid.add(bar3, grid_width="40%", grid_height="30%", grid_top="60%", grid_right="55%") #grid_right和grid_left是水平位置grid.render('/tmp/grid.html') #在/tmp文件夹里生成一个grid.html文件 例子中的数字都是我虚拟的，实际情况中，这些数字都应该是存储在redis这样的数据库里，然后取出来使用。 上面的两个例子仅仅是pyechart使用的冰山一角，如果想更多的了解，请去看一下文末pyechart的中文说明文档，无论是柱状图、雷达图、曲线图、3D图都有相关的使用讲解，内容特别丰富！ 参考资料http://echarts.baidu.comhttp://pyecharts.org/#/zh-cn/prepare]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>echart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ的安装、配置与启动]]></title>
    <url>%2F2018%2F03%2F19%2FRabbitMQ%E7%9A%84%E5%AE%89%E8%A3%85%E3%80%81%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[前言环境介绍：Centos 7 + RabbitMQ：3.6.12 + Erlang：20.0 安装erlang由于RabbitMQ使用erlang语言编写的，所以要先安装erlang语言环境。但是yum源里的erlang版本太老了，于是这里选择手动安装，使用Erlang官方推荐的Erlang Solutions安装方法如下： 1234yum install gcc gcc-c++ glibc-devel make ncurses-devel openssl-devel autoconf java-1.8.0-openjdk-devel git wget wxBase.x86_64 #先把其他模块准备好wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpmrpm --import https://packages.erlang-solutions.com/rpm/erlang_solutions.asc 此时，查看/etc/yum.repos.d/erlang_solutions.repo，应该是这个样子： 123456[erlang-solutions]name=CentOS $releasever - $basearch - Erlang Solutionsbaseurl=https://packages.erlang-solutions.com/rpm/centos/$releasever/$basearchgpgcheck=1gpgkey=https://packages.erlang-solutions.com/rpm/erlang_solutions.ascenabled=1 这个时候可以yum安装了： 1yum install -y esl-erlang 此时得到的erlang就是20.0版本的了，如图： 如果不想使用这个办法，可以使用源码安装的方式，https://packages.erlang-solutions.com/erlang/ 这里面有Erlang官方的下载包，拆包解压缩然后make &amp;&amp; make install即可。 安装RabbitMQ安装RabbitMQ跟其他普通软件差不多，先去官网下载目前较稳定的rpm包，然后安装，步骤如下： 12wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.4/rabbitmq-server-3.7.4-1.el7.noarch.rpmyum install -y rabbitmq-server-3.7.4-1.el7.noarch.rpm 如果出现了Transaction Check Error的错误： 可见是要安装的包与已有的包相冲突，此时需要yum list|grep erlang，如图： 再yum remove esl-erlang.x86_64，然后重新执行yum install那一步即可。 如果出现Requires: socat的错误，如图： 此时需要执行如下命令即可： 12yum -y install epel-releaseyum -y install socat 配置RabbitMQRabbitMQ安装完毕，先chkconfig rabbitmq-server on设置开机启动。然后，配置一下用户名。我这个机器的用户名不规范，需要把hostname里的中文去掉，比如改成：3-dvl-hlsproxy-001，那么就要在/etc/hosts里添加一句： 内网IP地址 3-dvl-hlsproxy-001 然后执行rabbitmq-plugins enable rabbitmq_management来安装WEB图形界面，然后拷贝rabbitmq.config.example到/etc/rabbitmq/里，并且改名叫rabbitmq.config，命令如下： 123cp /usr/share/doc/rabbitmq-server-3.7.4/rabbitmq.config.example /etc/rabbitmq/cd /etc/rabbitmq/mv rabbitmq.config.example rabbitmq.config 编辑rabbitmq.config这个文件，把%%{loopback_users, []}.改成{loopback_users, []}，保存之后，执行service rabbitmq-server restart来启动RabbitMQ。 如果启动之后，执行rabbitmqctl status不断的刷Error when reading /var/lib/rabbitmq/.erlang.cookie: eacces的错误的话，执行chown rabbitmq:rabbitmq /var/lib/rabbitmq/.erlang.cookie。 在浏览器里登录外网IP:15672就会看到RabbitMQ的WEB配置界面了， 账号和密码都是guest，输入之后就会看到如下的界面，可以在界面里看到3-dvl-hlsproxy-001的情况了，如图： RabbitMQ 3.0以后版本的WEB端口是15672,服务的端口是5672,这俩都可以在配置文件里面更改。至此RabbitMQ的安装与配置结束了，但是这个仅仅是最简单的配置，RabbitMQ自身有一套很详细的用户管理规则以及它支持Python等很多语言的管理，这些内容以后再详细说明。 参考资料https://packages.erlang-solutions.com/erlang/https://laucyun.com/9849587ce75f31d534d52f906c94368f.htmlhttps://www.rabbitmq.com/access-control.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用nginx开启http2协议]]></title>
    <url>%2F2018%2F03%2F16%2F%E4%BD%BF%E7%94%A8nginx%E5%BC%80%E5%90%AFhttp2%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[部署过程HTTP/2是建立在TLS的基础上的，那么先要查看nginx的版本和openssl的版本，如果nginx版本在1.10.0以上且需要openssl版本在1.0.2以上那么就可以进行下一步了： 如果版本并不符合要求，可以按照https://rorschachchan.github.io/2018/01/03/Nginx动态编译新的模块/ 里的方法升级对应的模块版本。 先编辑https（443端口）对应的conf文件： 123456789101112131415161718192021server &#123; listen 443 ssl http2; #这里多加一句http2 server_name cuntao.lechange.com *.lechange.com; #这里填写实际的域名，我这里以cuntao.lechange.com为例 ssl_certificate /实际路径/server-com.crt; ssl_certificate_key /实际路径/server-com.key; ssl_session_timeout 30m; #客户端会话缓存时间 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #允许的协议 ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; #加密算法(CloudFlare 推荐的加密套件组) ssl_prefer_server_ciphers on; #优化 SSL 加密套件 ssl_session_cache builtin:1000 shared:SSL:10m; #SSL会话缓存类型和大小 ssl_buffer_size 1400; #每个MTU大小1400b location / &#123; root html; index index.html index.htm; &#125; error_page 404 /404.html; &#125; 保存之后再编辑http（80端口）对应的conf文件： 12345server &#123; listen 80 default; add_header Strict-Transport-Security max-age=15768000; return 301 https://$host$request_uri;&#125; 然后使用nginx -t检查一下是否文件有错误，如果是OK的话，那么就nginx -s reload平滑重启一下nginx即可。 验证HTTP/2协议是否开启很简单，有两个方法：1）登陆https://tools.keycdn.com/http2-test，将你的域名填写进去，查看一下配置成功： 2)在Chrome浏览器上可以通过安装HTTP/2 and SPDY indicator插件来检验，网址是https://chrome.google.com/webstore/detail/http2-and-spdy-indicator/mpbpobfflnpcgagjijhmgnchggcjblin ，如果地址栏出现蓝色的闪电就是该网站开启了HTTP/2协议，灰色的话就是HTTP/2协议没开启。 参考资料https://www.nginx.com/blog/nginx-1-9-5/https://blog.fazero.me/2017/01/06/upgrate-nginx-and-use-http2/https://iyaozhen.com/nginx-http2-conf.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HTTP 2.0应该知道的事]]></title>
    <url>%2F2018%2F03%2F16%2F%E5%85%B3%E4%BA%8EHTTP-2%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[HTTP 2.0的优势相比HTTP/1.x，HTTP/2在底层传输做了很大的改动和优化：1.每个服务器只用一个连接：HTTP/2对每个服务器只使用一个连接，而不是每个文件一个连接。这样，就省掉了多次建立连接的时间，这个时间对TLS尤其明显，因为TLS连接费时间;2.加速TLS交付：HTTP/2只需一次耗时的TLS握手，并且通过一个连接上的多路利用实现最佳性能。HTTP/2还会压缩首部数据，省掉HTTP/1.x时代所需的一些优化工作，比如拼接文件，从而提高缓存利用率;3.简化Web应用：使用HTTP/2可以让Web开发者省很多事，因为不用再做那些针对HTTP/1.x的优化工作了;4.适合内容混杂的页面：HTTP/2特别适合混合了HTML、CSS、JavaScript、图片和有限多媒体的传统页面。浏览器可以优先安排那些重要的文件请求，让页面的关键部分先出现、快出现，而且根本不会发生“浏览器明明在等关键的CSS和JS，而服务器还在发送黄图”的尴尬局面;5.更安全：通过减少TLS的性能损失，可以让更多应用使用TLS，从而让用户信息更安全。 HTTP 2.0性能增强之二进制分帧HTTP的定义大家都知道，叫超文本协议，也就是说http1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多。但是在HTTP/2里这里做了比较重大的改动—二进制分帧，HTTP/2在应用层(HTTP)和传输层(TCP or UDP)之间增加一个二进制分帧层。在这个新增的二进制分帧层里HTTP/2会将所有传输的信息分割为更小的消息和帧,并对它们采用二进制格式的编码 ，其中HTTP1.x的首部信息会被封装到Headers帧，而我们的request body则封装到Data帧里面。二进制与之前的文本不同，二进制只认0和1的组合。基于这种考虑http2.0的协议解析决定采用二进制格式，实现方便且健壮。 HTTP/2的格式定义十分高效且精简。length定义了整个frame的大小，type定义frame的类型（一共10种），flags用bit位定义一些重要的参数，stream id用作流控制，payload就是request的正文，如下图： HTTP 2.0性能增强之首部压缩虽然HTTP/2引入了二进制分帧的概念，但是试想如果所有的二进制帧都会带上Headers帧，这是多大的数据冗余传送啊。于是HTTP/2针对这个需求又搞出来一个东东—“首部表”。 “首部表”来跟踪和存储之前发送的键-值对，对于相同的数据，不再通过每次请求和响应发送；通信期间几乎不会改变的通用键-值对(用户代理、可接受的媒体类型等等)只需发送一次。事实上,如果请求中不包含首部(例如对同一资源的轮询请求)，那么首部开销就是零字节。此时所有首部都自动使用之前请求发送的首部。如果首部发生变化了，那么只需要发送变化了数据在Headers帧里面，新增或修改的首部帧会被追加到“首部表”。首部表在HTTP/2的连接存续期内始终存在,由客户端和服务器共同渐进地更新。 HTTP 2.0性能增强之TCP请求集中TCP的优势是很直白的：面向连接、提供可靠的数据传输服务、流量控制。那么有效地使用TCP连接的方法就是长时间连接传输大块数据。于是HTTP/2就尽大化的把这一特点发扬：所有HTTP/2通信都是在一个TCP连接上完成。前面说过，HTTP/2把HTTP协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息，并行地在同一个TCP连接上双向交换消息(注意这个“双向交换消息”)。举个例子，请求一个页面https://www.google.com，页面上所有的资源请求都是客户端与服务器上的一条TCP上请求和响应的！ 这样“单链接多资源”的方式，使到至上而下的层面都得到了好处： 1.可以减少服务链接压力,内存占用少了,连接吞吐量大了； 2.由于TCP连接减少而使网络拥塞状况得以改观; 3.慢启动时间减少,拥塞和丢包恢复速度更快。 综上所述，“资源合并减少请求”对于HTTP/2是无用的优化手段。 上面的文字说了要注意“双向交换消息”，那么啥是“双向交换消息”？ 就是把HTTP消息分解为独立的帧,交错发送,然后在另一端重新组装。专业一点说就是“一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的id将request再归属到各自不同的服务端请求里面”。这是HTTP/2重要的一项增强。事实上,这个机制会在整个Web技术栈中引发一系列连锁反应, 从而带来巨大的性能提升,因为： 可以并行交错地发送请求,请求之间互不影响; 可以并行交错地发送响应,响应之间互不干扰; 只使用一个连接即可并行发送多个请求和响应; 消除不必要的延迟,从而减少页面加载的时间; Keep Alive与HTTP/2集中TCP的区别HTTP1.1的keep-alive是为了尽可能使用持久链接，以消除TCP握手和慢启动。但是keep-alive使用多了同样会给服务端带来大量的性能压力，并且对于单个文件被不断请求的服务(例如图片存放网站)，keep-alive可能会极大的影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。 举个例子：下载a.js创建一个TCP链接，就会需要TCP握手和慢启动而产生了约300ms下载延迟。当a.js下载完成后这时候b.js也要下载，如果a.js创建TCP链接是keep-alive的，b.js就可以复用其TCP而不需要重新TCP握手和慢启动（没有了那300ms）。 而HTTP/2是使用一个TCP链接的，其慢启动和握手只在第一次链接的时候产生一次，其后面链接都是持久化的。并且一个TCP下载多个资源，可以将TCP吞吐量最大化来提升性能，这方面可以参考一下TCP的拥塞预防及控制。 NGINX上如何配制HTTP/2上面说了这么多HTTP/2这个好那个好，是未来的趋势blablabla，但是要实现HTTP/2，还是需要“客户端和服务器都开启了HTTP/2”这一个首要条件。不过现在客户端（浏览器）大多数都已经支持HTTP/2，那么主要就是在服务器端如何开启HTTP/2，nginx的配置方法请见：https://rorschachchan.github.io/2018/03/16/使用nginx开启http2协议/ 。 按照这样的操作下来，服务器就开了HTTP/2协议，那些支持HTTP/2的浏览器在请求页面的时候就会走HTTP/2模式，而不支持HTTP/2的浏览器会议就按照HTTP/1.X的方式发送请求，如图： 支持HTTP/2的Web Server基本都支持HTTP/1.1。这样，即使浏览器不支持HTTP/2，双方也可以协商出可用的HTTP版本，没有兼容性问题。 参考资料http://www.alloyteam.com/2015/03/http2-0-di-qi-miao-ri-chang/comment-page-1/#commentshttps://segmentfault.com/a/1190000007637735https://github.com/creeperyang/blog/issues/23https://www.nginx.com/blog/nginx-1-9-5/https://ye11ow.gitbooks.io/http2-explained/content/part6.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大牛之路</tag>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos 7里安装zsh来提升shell的高逼格]]></title>
    <url>%2F2018%2F03%2F15%2Fcentos-7%E9%87%8C%E5%AE%89%E8%A3%85zsh%E6%9D%A5%E6%8F%90%E5%8D%87shell%E7%9A%84%E9%AB%98%E9%80%BC%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[zsh本体的安装先用chsh -l查看当前的bash情况，如下： 123456789 [root@zabbix ~]# chsh -l/bin/sh/bin/bash/sbin/nologin/bin/dash/bin/tcsh/bin/csh/usr/bin/tmux[root@zabbix ~]# 如果是centos的话，使用yum install -y zsh来安装zsh，装完了zsh然后就是装oh my zsh，使用wget方法安装： 1wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 再使用which zsh查看安装的zsh在/usr/bin/zsh，这个时候使用chsh -s /usr/bin/zsh，出现了Shell changed.这样就切换到了zsh界面，需要logout退出连接重进。 重新连接就会发现bash界面就变了，原本是路径的地方变成了一个小图标。界面主题是可以变化的，比如我个人比较喜欢af-magic这个模板，于是乎就把/root/.zshrc里的ZSH_THEME=&quot;robbyrussell&quot;改成ZSH_THEME=&quot;af-magic&quot;，保存文件，再一次退出连接重新进入就能看见模板变化了。 如果在使用vim的时候发现了tab键的补全爆错_arguments:451: _vim_files: function definition file not found，如下图： 这个时候需要把/root/.zcompdump改一个名字，比如叫.zcompdump-bak，然后重新ssh连接即可。 autojump插件安装autojump这个插件安装之后，zsh会自动记录你访问过的目录，通过j + 目录名可以直接进行目录跳转，而且目录名支持模糊匹配和自动补全，例如你访问过hadoop-1.0.0目录，输入j hado即可正确跳转。j –s可以看你的历史路径库，安装方法如下： 1git clone git://github.com/joelthelion/autojump.git 然后在autojump目录里执行./install.sh，此时屏幕会出现如下的显示： 把上面那个[[ -s /root/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; source /root/.autojump/etc/profile.d/autojump.sh autoload -U compinit &amp;&amp; compinit -u复制到/root/.zshrc的文件里，最好复制在source $ZSH/oh-my-zsh.sh这句话上面，保存之后source ~/.zshrc即可。 zsh-syntax-highlighting插件安装这个插件安装之后主要效果就是命令高亮，如果是错误的命令，颜色是红色，正确的命令是绿色的，安装方法如下： 12345cd .oh-my-zsh/pluginsyum install -y git #如果已经安装了git就不用执行的git clone git://github.com/zsh-users/zsh-syntax-highlighting.gitsource /root/.oh-my-zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh添加到 .zshrc 的最后面source ~/.zshrc 效果立竿见影。 尾声至此，你现在的zsh应该具备如下几个特性：1、各种补全：路径补全、命令补全，命令参数补全，插件内容补全等等。触发补全只需要按一下或两下tab键，补全项可以使用ctrl+n/p/f/b上下左右切换。比如你想杀掉java的进程，只需要输入kill java + tab键，如果只有一个java进程，zsh会自动替换为进程的pid，如果有多个则会出现选择项供你选择。ssh + 空格 + 两个tab键，zsh会列出所有访问过的主机和用户名进行补全；2、即使你没有安装autojump，只要输入d，就会列出你在这个回话中访问的目录，输入前面的序号，就可以直接跳转；3、可以忽略cd命令, 输入..或者…和当前目录名都可以跳转；当然，除了上面几点，zsh还有很多丰富的插件可以使用，这就需要继续的探索了… 参考资料https://github.com/robbyrussell/oh-my-zshhttp://macshuo.com/?p=676]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装vim8.0的过程]]></title>
    <url>%2F2018%2F03%2F14%2F%E5%AE%89%E8%A3%85vim8-0%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.先卸载老的vim 1yum remove vim-* -y 2.下载第三方yum源 1wget -P /etc/yum.repos.d/ https://copr.fedorainfracloud.org/coprs/mcepl/vim8/repo/epel-7/mcepl-vim8-epel-7.repo 3.安装vim 1yum -y install vim-enhanced 4.验证vim版本 12345rpm -qa |grep vimvim-enhanced-8.0.0704-1.1.26.el7.centos.x86_64vim-common-8.0.0704-1.1.26.el7.centos.x86_64vim-minimal-8.0.0704-1.1.26.el7.centos.x86_64vim-filesystem-8.0.0704-1.1.26.el7.centos.x86_64]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>编辑器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用expect来实现远程登录ssh]]></title>
    <url>%2F2018%2F03%2F14%2F%E4%BD%BF%E7%94%A8expect%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95ssh%2F</url>
    <content type="text"><![CDATA[先说说shebang我们在写一个shell脚本时，总是习惯在最前面加上一行#!/bin/bash,这个就是脚本的shebang,可以把它理解成是一种解释器。至于为什么叫这么个奇怪的名字，C语言和Unix的开发者Dennis Ritchie称它为可能是类似于“hash-bang”的英国风描述性文字； 贴一段wiki上的解释: 在计算机科学中，shebang是一个由井号和叹号构成的字符串行，其出现在文本文件的第一行的前两个字符。 在文件中存在shebang的情况下，类unix操作系统的程序载入器会分析shebang后的内容，将这些内容作为解释器指令，并调用该指令，并将载有shebang的文件路径作为该解释器的参数。 简单的说，它指示了此脚本运行时的解释器，所以，使用文件名直接执行shell脚本时，必须带上这个shebang; 此外，我们还可以在shebang后面直接附加选项，执行时默认使用选项执行； 比如test.sh的shebang为#!/bin/sh -x，那我们执行脚本时: 1./test.sh hello 相当于： 1bin/sh -x ./test.sh hello; 而expect编写的脚本，需要用到的shebang为/usr/bin/expect; 需要注意的是：在指定脚本解释器来执行脚本时，shebang会被指定的脚本解释器覆盖，即优先使用指定的脚本解释器来执行脚本（习惯性地用sh ./test.sh却提示command not found） 实例脚本expect的具体语法我这里就不说了，看一下下面的参考资料就好了。其实说来说去，就是根据命令栏上的反馈来输入对应的内容，举一个ssh登陆的例子。如图: 从这个我们非常熟悉的ssh登陆的过程就看到，在登陆的时候，页面会返回几个交互的问题，而我们就可以针对这几个问题的关键字来输入答案。最后也根据“Welcome”这个关键字认为我们已经登陆成功了，这样就直接在连接的服务器里操作命令。 于是根据这个思路，来写一个远程ssh到A机器上的脚本： 1234567891011121314151617#!/usr/bin/expect -fset timeout 30 #设定超时时间是30秒，如果是-1那就是永不超时spawn ssh root@A服务器IP地址 #这里开始ssh连接到目标服务器上expect &#123; "*(yes/no)?" &#123; #如果是第一次连接，那么命令栏里就会出现(yes/no)的字样 send "yes\r" #此时匹配yes expect "*password:" &#123;send "服务器密码\r"&#125; #如果命令栏出现了password的字样，直接填写密码 &#125; "*password:" &#123;send "服务器密码\r"&#125; #如果不是第一次连接，那么就会直接出现password，所以可以直接填写密码&#125;expect "*Welcome*" #连接成功就会出现welcome的字样send "echo '我就是你的爹地' &gt;&gt; /tmp/123321.txt\r" #此时执行第一个命令send "df -h\r" #执行第二个命令send "cp /tmp/123321.txt /tmp/123123.txt\r" #执行第三个命令interact #脚本fork的子进程会将操作权交给用户，允许用户与当前A服务器的shell进行交互 参考资料http://blog.sctux.com/?p=343http://www.zyy1217.com/2017/07/02/linux%20expect%E8%AF%A6%E8%A7%A3/https://github.com/jiangxianli/SSHAutoLoginhttps://peiqiang.net/2014/05/10/ssh-auto-login.htmlhttps://www.jianshu.com/p/9bee08dc3dca]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>expect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python去做一个生成随机码的页面]]></title>
    <url>%2F2018%2F03%2F13%2F%E4%BD%BF%E7%94%A8python%E5%8E%BB%E5%81%9A%E4%B8%80%E4%B8%AA%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E7%A0%81%E7%9A%84%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[先说一下mkpasswdlinux里是自带生成密码的命令的，比较出名的一个是mkpasswd，另一个是passwdgen。 mkpasswd命令是附属在expect模块里的，如图 passwdgen的话也要手动执行一下yum install -y passwdgen来安装命令。 这里主要说说mkpasswd，它支持如下几个参数： 12345-l (length of password, default = 7) 指定密码的长度，默认是7位数-d (min # of digits, default = 2) 指定密码中数字最少位数，默认是2位-c (min # of lowercase chars, default = 2) 指定密码中小写字母最少位数，默认是2位-C (min # of uppercase chars, default = 2) 指定密码中大写字母最少位数，默认是2位-s (min # of special chars, default = 1) 指定密码中特殊字符最少位数，默认是1位 比如现在要生成一个含有“六位数字而且5位特殊字符的总共16位”的密码，那么命令就是：mkpasswd -l 16 -d 5 -s 5，再聚几个其他的例子，感受一下： 12345678[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -d 5 -s 5g]7Hu-L5,t+32%0m[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -C 5YvjtFWaV5jr8h%Wy[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -s 10qoB#^V_=/!??*59:[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -c 4 9mJOqymatvg*n9sl 脚本在此这个生成随机码的算法部分就使用上面那个mkpasswd了，省了我们不少事。 整个html界面的代码如下： 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;随机密码生成器&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="/cgi-bin/dropdown.py" method="post" target="_blank"&gt;&lt;select name="dropdown"&gt;&lt;h2&gt;密码长度：&lt;/h2&gt;&lt;option value="8" selected&gt;8&lt;/option&gt;&lt;option value="16"&gt;16&lt;/option&gt;&lt;option value="20"&gt;20&lt;/option&gt;&lt;option value="24"&gt;24&lt;/option&gt;&lt;option value="48"&gt;48&lt;/option&gt;&lt;/select&gt; &lt;br /&gt;&lt;input type="checkbox" name="runoob" value="on" /&gt; 包含小写字母 &lt;br /&gt;&lt;input type="checkbox" name="google" value="on" /&gt; 包含大写字母 &lt;br /&gt;&lt;input type="checkbox" name="runoob" value="on" /&gt; 包含数字 &lt;br /&gt;&lt;input type="checkbox" name="google" value="on" /&gt; 包含特殊字母 &lt;br /&gt;&lt;input type="submit" value="提交"/&gt; &lt;br /&gt;&lt;h2&gt;密码：&lt;/h2&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 补充再分享一个python生成密码的代码，但是这个密码不含特殊字符： 12345678#!/usr/bin/env python# -*- coding: utf-8 -*- import randomimport stringsalt = ''.join(random.sample(string.ascii_letters + string.digits, 8))print salt 参考资料https://balajiommudali.wordpress.com/2015/11/27/unable-to-install-mkpasswd-on-centos-6-4/http://www.runoob.com/python/python-cgi.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次mysql无法启动的解决过程]]></title>
    <url>%2F2018%2F03%2F12%2F%E8%AE%B0%E4%B8%80%E6%AC%A1mysql%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E7%9A%84%E8%A7%A3%E5%86%B3%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[正文今天开发人员反馈一个问题，就是某一台开发环境机器的mysql无法启动了，但是如果这台服务器重启的话，mysql就好使，而第二天就会出现mysql死掉然后无法启动的情况。我使用service mysqld restart，命令行反馈如下的内容： 123[root@iZ2373j9xivZ data]# service mysqld restartMySQL server PID file could not be found! [FAILED] Starting MySQL........The server quit without updating PID file (/data/mysql/data/sock/mysql.pid). [FAILED] 打开错误日志看一下，里面是这么写的： 123456782018-03-10 00:26:24 25919 [Note] InnoDB: Using CPU crc32 instructions2018-03-10 00:26:24 25919 [Note] InnoDB: Initializing buffer pool, size = 4.0GInnoDB: mmap(549453824 bytes) failed; errno 122018-03-10 00:26:24 25919 [ERROR] InnoDB: Cannot allocate memory for the buffer pool2018-03-10 00:26:24 25919 [ERROR] Plugin 'InnoDB' init function returned error.2018-03-10 00:26:24 25919 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.2018-03-10 00:26:24 25919 [ERROR] Unknown/unsupported storage engine: INNODB2018-03-10 00:26:24 25919 [ERROR] Aborting 爆InnoDB: mmap(549453824 bytes) failed; errno 12，然后我就free -m查看一下，当前服务器的内存已经不够用了。 12345[root@iZ2373j9xivZ sock]# free -m total used free shared buffers cachedMem: 7869 7747 121 0 16 15-/+ buffers/cache: 7716 152Swap: 0 0 0 那么是什么在占用这台服务器的内存？使用ps aux | sort -k4nr |head -5 这个命令查找当前占用内存最大的五个进程一看，全是php-fpm，同时也发现服务器里面运行大量的php-fpm，在征得开发人员的同意之后，重启php-fpm进程，内存空出来很多。 此时再次service mysqld restart，发现mysql的错误日志改成如下的样子了： 12342018-03-12 10:53:42 28238 [Note] InnoDB: Highest supported file format is Barracuda.2018-03-12 10:53:42 28238 [Note] InnoDB: The log sequence numbers 16939991440 and 16939991440 in ibdata files do not match the log sequence number 16940121908 in the ib_logfiles!2018-03-12 10:53:42 28238 [Note] InnoDB: Database was not shutdown normally!2018-03-12 10:53:42 28238 [Note] InnoDB: Starting crash recovery. 这次变成了The log sequence numbers 16939991440 and 16939991440 in ibdata files do not match the log sequence number 16940121908 in the ib_logfiles!，我打开my.cnf，适当的调小了max_connections和innodb_buffer_pool_size，然后service mysqld restart的时候发现错误又变了： 123456782018-03-12 11:03:57 29190 [Note] InnoDB: 5.6.27 started; log sequence number 169401219182018-03-12 11:03:57 29190 [Note] Server hostname (bind-address): '*'; port: 33062018-03-12 11:03:57 29190 [Note] IPv6 is not available.2018-03-12 11:03:57 29190 [Note] - '0.0.0.0' resolves to '0.0.0.0';2018-03-12 11:03:57 29190 [Note] Server socket created on IP: '0.0.0.0'.2018-03-12 11:03:57 29190 [ERROR] Can't start server : Bind on unix socket: Permission denied 2018-03-12 11:03:57 29190 [ERROR] Do you already have another mysqld server running on socket: /data/mysql/data/sock/mysql.sock ?2018-03-12 11:03:57 29190 [ERROR] Aborting 这就是文件权限问题了，我再次打开my.cnf发现里面的user填写的是mysql，那么把/data/mysql/data/sock/mysql.sock这一系列的文件的所属人都改成了mysql用户，这一次重启mysql就OK了。 为什么这个mysql会好好的突然自动死掉呢？我发现日志里面有这样的字样：InnoDB: Database was not shutdown normally!，于是我猜想很有可能是php-fpm这进程不断地增长，占用的内存太大，导致mysql被linux的内核杀死了。于是查看/var/log/message的文件，结合mysql的错误日志时间找到了如下的字样： 12345Mar 10 00:26:22 iZ2373j9xivZ kernel: Out of memory: Kill process 1883 (mysqld) score 53 or sacrifice childMar 10 00:26:22 iZ2373j9xivZ kernel: Killed process 1883, UID 501, (mysqld) total-vm:6849508kB, anon-rss:429368kB, file-rss:176kBMar 10 04:11:38 iZ2373j9xivZ kernel: php-fpm invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0Mar 10 04:11:38 iZ2373j9xivZ kernel: php-fpm cpuset=/ mems_allowed=0Mar 10 04:11:38 iZ2373j9xivZ kernel: Pid: 4375, comm: php-fpm Not tainted 2.6.32-431.23.3.el6.x86_64 #1 证据确凿，php-fpm的无休止增长导致服务器的可用内存变小，最后内核把mysql杀死，修改php-fpm的文件之后，暂时好了点… 参考资料http://robinchen.me/tech/2016/03/14/tech-aliyun-centos-mysql-shutdown-itself-irregularly.htmlhttp://www.wisedream.net/2017/12/20/traps/mysql-corrupt/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HTTP-Alive应该知道的事]]></title>
    <url>%2F2018%2F03%2F11%2F%E5%85%B3%E4%BA%8EHTTP-Alive%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[总体概述七层协议是一个广为人知的协议，tcp协议是在传输层，http协议是在应用层，也就是说客户端与服务器端先建立tcp连接，然后在tcp连接的基础上传送http报文。 http协议是一个请求-应答的模式，也就是当没有启动keep-alive的时候，每一次建立http连接都是现用现建立，用完就断开的工作样式。而如果开启了keep-alive模式的话，客户端和服务器之间http连接就会被保持，不会断开（超过Keep-Alive规定的时间，意外断电等情况除外），当客户端发送另外一个请求时，就使用这条已经建立的连接。 Keep-Alive的规定时间在客户端（浏览器里）是如何确定的呢？例如Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100表示这个长连接最多接收100次请求就断开。 Keep-alive在http 1.1版本里是默认开启的，只有加入Connection: close才会关闭，现在大部分浏览器都是使用http 1.1协议，所以说在客户端已经是默认发起keep-alive的连接请求。但是能否会完成一个完整的keep-alive还要看服务器端的具体配置情况。 在nginx里就直接支持keepalive_timeout指令，其使用0值来停用keep-alive，举例配置如下: 12345location /XXX/ &#123; alias /url/var/www/html/; keepalive_timeout 75; expires 5m; &#125; 使用长连接之后，客户端和服务端怎么知道本次传输结束呢？两部分：1. 判断传输数据是否达到了Content-Length指示的大小，这个是最简单的最傻瓜的，普遍应用于静态的图片或者页面；2. 往往动态生成的文件没有Content-Length，它是分块传输（chunked），这时候怎么办呢？就要根据chunked编码来判断，chunked编码的数据在最后有一个空chunked块，表明本次传输数据结束，这种情况更多应用于动态的页面。 进一步的说chunkedHTTP请求报文的格式是这样的： 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 其中在请求头的地方有一个叫Content-Length的字段，如果没有这个字段那么就会有叫Transfer-encoding的字段，它用来表示http报文的传输格式，这个字段的取值有很多，但是真正有意义的只有一个—chunked。 如果一个HTTP消息（请求消息或应答消息）的Transfer-Encoding消息头的值为chunked，那么，消息体由数量未定的块组成，并以最后一个大小为0的块为结束。 每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个CRLF（回车及换行），然后是数据本身，最后块CRLF结束。在一些实现中，块大小和CRLF之间填充有白空格（0x20）。 最后一块是单行，由块大小（0）、一些可选的填充白空格、以及CRLF组成。最后一块不再包含任何数据，但是可以发送可选的尾部，包括消息头字段。消息最后以CRLF结尾。 注意1.chunked和multipart两个名词在意义上有类似的地方，不过在HTTP协议当中这两个概念则不是一个类别的。multipart是一种Content-Type，标示HTTP报文内容的类型，而chunked是一种传输格式，标示报头将以何种方式进行传输； 注意2.chunked传输不能事先知道内容的长度，只能靠最后的空chunk块来判断，因此对于下载请求来说，是没有办法实现进度的。在浏览器和下载工具中，偶尔我们也会看到有些文件是看不到下载进度的，即采用chunked方式进行下载； 注意3.chunked的优势在于，服务器端可以边生成内容边发送，无需事先生成全部的内容。HTTP/2不支持Transfer-Encoding: chunked，因为HTTP/2有自己的streaming传输方式。 http keep-alive与tcp keep-alivehttp的keep-alive与tcp的keep-alive可不是同一回事，意图也不一样。http的keep-alive是为了让tcp活得更久一点，以便在同一个连接上传送多个http，提高socket的效率。而tcp的keep-alive是tcp的一种检测tcp连接状况的保鲜机制。tcp的keep-alive是一个保鲜定时器，支持三个系统内核配置参数： 123echo 1800 &gt; /proc/sys/net/ipv4/tcp_keepalive_timeecho 15 &gt; /proc/sys/net/ipv4/tcp_keepalive_intvlecho 5 &gt; /proc/sys/net/ipv4/tcp_keepalive_probes keepalive是TCP保鲜定时器，当网络两端建立了tcp连接之后，闲置idle（双方没有任何数据流发送往来）了tcp_keepalive_time后，服务器内核就会尝试向客户端发送侦测包，来判断TCP连接状况(有可能客户端崩溃、强制关闭了应用、主机不可达等等)。如果没有收到对方的回答(ack包)，则会在tcp_keepalive_intvl后再次尝试发送侦测包，直到收到对对方的ack,如果一直没有收到对方的ack,一共会尝试tcp_keepalive_probes次，每次的间隔时间在这里分别是15s、30s、45s、60s、75s。如果尝试tcp_keepalive_probes,依然没有收到对方的ack包，则会丢弃该TCP连接。TCP连接默认闲置时间是2小时，一般设置为30分钟足够了。 也就是说，仅当nginx的keepalive_timeout值设置高于tcp_keepalive_time，并且距此tcp连接传输的最后一个http响应，经过了tcp_keepalive_time时间之后，操作系统才会发送侦测包来决定是否要丢弃这个TCP连接。一般不会出现这种情况，除非你需要这样做。 keep-alive与TIME_WAIT使用http的keep-alive，可以减少服务端TIME_WAIT数量(因为由服务端httpd守护进程主动关闭连接)。道理很简单，相较而言，启用keep-alive，建立的tcp连接更少了，自然要被关闭的tcp连接也相应更少了。 补充建议在服务器提供Web站点服务时(一个页面除了动态内容，还包含非常多的JS、图片、css文件等)开启keep-alive。在“服务器提供的是一个接口服务，除了动态内容，几乎没有引用任何静态内容”这样的场景，不建议开启keep-alive。 参考资料http://www.cnblogs.com/skynet/archive/2010/12/11/1903347.htmlhttps://hit-alibaba.github.io/interview/basic/network/HTTP.htmlhttp://51write.github.io/2014/04/09/keepalive/http://www.nowamagic.net/academy/detail/23350305]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大牛之路</tag>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh连接port22:Socket error Event:32 Error:10053]]></title>
    <url>%2F2018%2F03%2F07%2Fssh%E8%BF%9E%E6%8E%A5port22-Socket-error-Event-32-Error-10053%2F</url>
    <content type="text"><![CDATA[今天遇到了一个奇怪的现象，据开发人员反馈，有一台阿里云服务器在控制台重启了之后，发现无法登陆了。我先使用阿里云的控制台打算远程登陆到这台机器发现，远程登陆总是显示密码错误。然后我使用xshell登陆对应的外网IP和22端口的时候发现爆出如下的错误： 12345678Connecting to X.X.X.X:22...Connection established.To escape to local shell, press 'Ctrl+Alt+]'.Socket error Event: 32 Error: 10053.Connection closing...Socket close.Connection closed by foreign host. 这种情况很罕见，google了一下也没有对于我有用的处理办法，于是我就只好给阿里云后台发了一下工单。授权给阿里云让他们登陆一下这台机器看一下里面发生了什么，阿里云的售后人员过了一会打过电话过来说，发现这台机器里面有人操作了chmod -R 777 /，破坏了比如/etc/passwd和/etc/shadow的权限，所以会爆出这样的错误。如图： 阿里的售后说他们也把几个跟登陆有关的文件暂时恢复权限，这样这个机器就可以成功登陆了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[孤儿进程和僵尸进程]]></title>
    <url>%2F2018%2F03%2F07%2F%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原理与定义首先要知道，linux有父进程和子进程这样的说法。那父进程如何创建子进程呢？fork。 子进程的进行和父进程的进行是异步的，但是父进程就像父母一样对自己的小孩也有一定的控制欲，这个控制欲就表现在如果子进程如果结束了，它释放了之前占用的资源、内存、文件等等，但是它还保留了一点信息：进程号PID、退出状态、运行时间等等。而这些残留信息是父进程通过wait/waitpid来获取，如果父进程一直不获取，那么子进程就会一直保留这些信息直到海枯石烂。 孤儿进程：父进程退出，子进程继续进行，那么此时子进程就是孤儿进程。这个时候init进程（进程号为1）来作为子进程的监护人，发出wait/waitpid来完成状态收集工作； 僵尸进程：父进程没有退出，但是它迟迟不发出wait/waitpid来回收子进程的资源。就好比儿子死了，当爹的不给收尸，这个儿子就成了孤魂野鬼成了僵尸。 影响与危害孤儿进程是没有什么大的危害，虽然他虽然没有了亲生父亲，但是也有init进程来通过循环的wait()来处理它的善后工作，所以迟早会把占用的资源释放掉。 甚至有的用户可以把进程弄成孤儿进程，以使之与用户会话脱钩，并转至后台运行。这一做法常应用于启动需要长时间运行的进程，也即守护进程。另外，nohup命令也可以完成这一操作。 但是僵尸进程不一样，要是父进程对子进程一直不使用wait/waitpid，那么pid就会不回收，可是系统内的pid总是是有限的，这样久而久之就是对pid的一个霸占，新的进程也无法生成，这就是僵尸进程的危害。 如何处理僵尸进程僵尸进程是杀不死的，怎么办？杀他爹，把父进程杀掉了，那么这些僵尸就成了孤儿进程，然后再由init收养，最后入土为安。 查看当前服务器僵尸进程的方法： 1ps -A -o stat,ppid,pid,cmd | grep -e '^[Zz]' 如果服务器上的僵尸进程不是出自一个父进程之手，那么就用下面这个命令批量解决： 1ps -A -o stat,ppid,pid,cmd | grep -e '^[Zz]' | awk '&#123;print $2&#125;' | xargs kill -9 但是如果父进程是init进程，那么这样的僵尸进程怎么办？答案，不用刻意管他，相信init的能力，它迟早会被init回收的，成为僵尸进程也是暂时的。 参考资料https://zh.wikipedia.org/wiki/%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8Bhttps://zh.wikipedia.org/wiki/%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8Bhttp://blog.csdn.net/YuZhiHui_No1/article/details/53011390]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蚂蚁金服运维面试全纪录]]></title>
    <url>%2F2018%2F03%2F07%2F%E8%9A%82%E8%9A%81%E9%87%91%E6%9C%8D%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E5%85%A8%E7%BA%AA%E5%BD%95%2F</url>
    <content type="text"><![CDATA[早上接到蚂蚁金服的运维面试电话，有点突然袭击，下面是整个的面试记录。 首先，面试官先向我讲述了一下他们平时运维的工作内容，然后结合我的简历开始提问。 1）都用过我们的什么产品？这一阶段老老实实、正常回答工作中所用到的阿里云产品和使用情景。 2）VPC网络有哪些好处？我就答出来更加安全…面试官说其他方面呢，我就不知道了。【事后补充】VPC网路的灵活性更高，可以自由定义网段划分、IP地址和路由网络。 3)一个vpc的服务器如何与外网交互？我说可以改写路由或者通过iptables转发。 4）iptables里PREROUTING和POSTROUTING都是啥？PREROUTING处理刚到达本机并在路由转发前的数据包；POSTROUTING处理即将离开本机的数据包。 5）问：RDS在什么操作下会CPU飙升，任举一例？答：在我实际工作中，比较明显的是在数据同步的时候会飙升。 6）RDS为什么会在DTS的时候有飙升的现象？这个我答的不好，有点东拉西扯…（尴尬） 7）mysql备份的时候使用过什么参数？答：--skip-opt 防止运行中的MYSQL锁库加速数据备份的参数是什么？-q 提高导出性能-e 提高导入性能，使用包括几个VALUES列表的多行INSERT语法；--max_allowed_packet=XXX 客户端/服务器之间通信的缓存区的最大大小；--net_buffer_length=XXX TCP/IP和套接字通信缓冲区大小，创建长度达到net_buffer_length的行； 注意！max_allowed_packet和net_buffer_length在mysql里有参数值，不能超过参数值！查看方法：show variables like &#39;max_allowed_packet&#39;; 8）cache和buffer有什么区别？cache是缓存，弥补高速设备与低速设备的鸿沟引入的中间层，达到数据快取的目的（救火车与蓄水池）；buffer是缓冲区，用户流量整形，把大量的小的io整理一个平稳的大io，减少磁盘响应次数；buffer是即将要写入磁盘的，cache是要被从磁盘里读出来的。当然这只是普通用途，buffer用来读、cache用来写也是有可能的。具体问题具体分析。 9）他俩的调用有什么区别？我问是要说“块读取”什么的么，面试官说是。我就蒙说cache是块读取，buffer我不清楚…（尴尬 again）【事后补充】 10）谈一谈time_wait和close_wait，各自在什么情况下出现？time_wait和close_wait是出现在“四次挥手”的环节里，time_wait是服务器接收到客户端发来的断开TCP连接的请求，并且服务器发送确认断开的包给客户端，此时服务器处于time_wait状态，如果服务器等待两个msl的话，就会默认断开连接，如果想修改msl可以通过修改/etc/systl.conf文件；close_wait是客户端已经发送了断开TCP请求，但是服务器端没有接收到，也就是time_wait的上一步，此时这个资源就一直被程序霸占。 11）为什么time_wait需要等待两个msl?1.99行不行？2.01行不行？我当时说防止上一次连接中的包，迷路后重新出现，影响新连接。面试官好像觉得不是很满意…（尴尬 again）【事后补充】MSL是指一个片段在网络中的最大存活时间，2MSL是一个发送和一个回复所需的最大时间，如果直到2MSL，客户端都没有收到fin包，那么客户端就可以断定他发出去的ack已经被服务端接收，结束TCP连接。 12）说出一个你使用过的python库。我说我前两天用matpoltlib画图，就谈了谈这个画图的库。 13）python装饰器了解么？没什么深入的了解，就没敢答，怕被问死。 14）僵尸进程和孤儿进程，了解么？马蛋，这个让我给说反了…(闹心啊啊啊啊啊啊啊)【事后补充】孤儿进程：父进程退出，而它的一个或者多个子进程还在运行，这些子进程就叫孤儿进程，孤儿进程被init进程收养，由init进程对它们完成状态收集工作；僵尸进程：一个进程用fork创建了子进程，然后这个子进程退出了，而父进程并没有调用wait或者waitpid去获取子进程的状态信息，那么这个子进程的进程描述符还在系统中，这种进程叫僵尸进程； 孤儿进程不怕，由于孤儿虽然没有父母，但是有民政局（init进程）收养，孤儿进程退出后也有init做一切善后工作；而僵尸进程会一直霸占其PID号，但是系统总共的PID是有限的，这样就会让可用的PID越来越少，所以僵尸进程是要避免的。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大牛之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper的选举原理]]></title>
    <url>%2F2018%2F03%2F05%2FZookeeper%E7%9A%84%E9%80%89%E4%B8%BE%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言Zookeeper是一款比较常见的式应用程序协调服务软件，如果配置了多台zookeeper自然要选择一个头头，这个头头就是leader，很明显不能所有的zookeeper都是leader，那样就失控了；也不能所有的zookeeper都是follower，那就群龙无首无法协调。 插播一句，这种一老大N跟班的模式是过去分布式软件里很常见的工作模式，而最近比较火热的区块链不同，它是一种去中心化的工作模式，大家人人都当节点，然后放在一起整合，有点原始社会的意思。所以说，算法有时候来自于人类学，也会在一定程度反过来上影响人类。 选举leader的方式是一种叫FastLeaderELection的算法，以3.4.6版本为例，它被保存在/usr/zookeeper/src/java/main/org/apache/zookeeper/server/quorum/这个文件夹下。 选举的中心思想实际上FastLeaderELection说的中心思想无外乎以下几个关键点： 全天下我最牛！在我没有发现比我牛的推荐人的情况下，我就一直推举我当leader，第一次投票那必须推举我自己当leader。 每当我接收到其它的被推举者，我都要回馈一个信息，表明我还是不是推举我自己。如果被推举者没我大，我就一直推举我当leader，是我是我还是我！ 我有一个票箱， 和我属于同一轮的投票情况都在这个票箱里面。一人一票重复的或者过期的票，我都不接受。 一旦我不再推举我自己了（这时我发现别人推举的人比我推荐的更牛），我就把我的票箱清空，重新发起一轮投票（这时我的票箱一定有两票了，都是选的我认为最牛的人）。 一旦我发现收到的推举信息中投票轮要高于我的投票轮，我也要清空我的票箱。并且还是投当初我觉得最牛的那个人（除非当前的人比我最初的推荐牛，我就顺带更新我的推荐）。 不断的重复上面的过程，不断的告诉别人“我的投票是第几轮”、“我推举的人是谁”。直到我的票箱中“我推举的最牛的人”收到了不少于N/2 + 1的推举投票。这也回答了为什么zookeeper在少于N/2 + 1的节点处于工作状态的情况下会崩溃了。因为，无论怎么选也没有任何节点能够获得N/2 + 1的票数。 这时我就可以决定我是flower还是leader了（如果至始至终都是我最牛，那我就是leader咯，其它情况就是follower咯）。并且不论随后收到谁的投票，都向它直接反馈“我的结果”。 判断依据上面第二步里说了，如果接收到其他被推举者的消息，而且判断出这个被推举者比我牛，我就要推举他，那么判断依据是啥呢？答案是依次比较epoch、zxid、serverid。 先说说啥是epoch、zxid、serverid： epoch: 表示选举轮数。 zxid: 事务zxid包含了本地数据的最后更新时间相关的信息。 serverid: 当前server的 ID, 通过配置文件指定(echo &#39;1&#39; &gt; myid)。 具体的判断过程是：接收到的消息中，有epoch比我大的，则选epoch大的消息中确定的server；如果epoch相等，则选zxid最大的server；如果zxid也相等，则选serverid最大的server(有的节点生来就是当leader的）。 为什么要有epoch呢？这样是为了防止中途有选举者掉线，他们错过了选举，再次连上来的时候，他们发现自己的投票轮已经小于现有的投票轮了，那么他们比如要清空自己的投票箱然后无条件的改为推荐接收到的最新选举中大家推荐的最牛的那个人（如果没有人比我牛，那还是推荐我自己）。由于有最后一条serverid大的最后压阵，而且serverid又不能重复，所以基本上都能最后选出一台作为leader。 参考资料http://blog.csdn.net/yinwenjie/article/details/47613309https://mozillazg.com/2017/03/zookeeper-fastleader-elect-leader.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从韩国民主电影三部曲浅谈我对民主的认识]]></title>
    <url>%2F2018%2F03%2F04%2F%E9%9F%A9%E5%9B%BD%E6%B0%91%E4%B8%BB%E7%94%B5%E5%BD%B1%E4%B8%89%E9%83%A8%E6%9B%B2%2F</url>
    <content type="text"><![CDATA[这个周末周五晚上看了《出租车司机》，周六下午看了《1987：黎明到来的那一天》，再加上之前就在B站看过又被下架的《辩护人》，韩国民主运动三部曲都看完了。 韩国民主运动电影还有一部叫《华丽的假期》，这个片子是2007年公映的，也是讲光州事件，但是这部片从电影角度上不如上面这三者，所以影响力和传播程度相对有限。 一直以来我对韩国的政治采取一种“黑”的态度，因为他们的总统基本没有好下场，哪怕是我个人比较喜欢的卢武铉总统也是以自杀结束了自己的一生，而且他们的演艺圈和体育圈也是以各种“黑”和“潜规则”出名。但是我不得不佩服韩国正直电影人的精神以及韩国正直记者们的精神，他们坚持了自己的操守而且履行了自己的职责，用骨气和勇气记录了他们能接触到的真相并且在日后拍成电影反思历史。 论民主化运动，韩国可以说是亚洲里第一档的存在，大型示威的次数加起来比越南、缅甸、柬埔寨加起来还要多，远超于同样是发达国家的日本。韩国民主化运动主要集中在1980-1987年全斗焕执政那一段时间，那时韩国人民虽然经历了初期经济水平腾飞的甜蜜，但是对后期经济调控不力和政府打压言论表示不满和愤怒。暴动的人民反抗意识比较强，不仅有大规模游行，甚至有这几部电影里没有提到的抢劫军火库的行为。而这些抢劫军火的行为日后也成了全斗焕在法庭上力图脱罪的一个辩控点。 这几部电影虽然被部分人影评“有明显的韩国特色，会导致审美疲劳”，但是并不耽误它们一次又一次的刷新票房记录，可见参与政治追求民主和公平其实是公民的一种本能。但是说实话，截止至今，光州事件虽然被平反但是没有得到彻底的清算。新闻说现任韩国总统文在寅先后观看了《出租车司机》和《1987：黎明到来的那一天》，会不会重审当年的光州罪犯，我们拭目以待。 民主可能本身不是一个效率很高的政治制度，因为它要坚持“少数服从多数”的原则，在具体条款颁布和施行的时候，由于不同人看待事物的水平和深度有高有低，以及侧重面的不同，那么肯定会有一些不一样的声音。而独裁的“一言堂”则相对效率很快，从历史来看，独裁政府甚至有战争上打败民主政府的先例，而且独裁政府挑头并且通过集权形式搞经济的话，在国家原有经济非常落后的前提下，的确可以快速进步，但是这种进步并不是那种“可持续发展”式的，而且中后期会由于民众监督不力，导致政府腐败的先例数不胜数。所以说集权就是一个春药，服用肯定会上瘾，但是也只会用暂时的爽换来将来的无穷尽的苦。独裁无论是理论还是事实都已经被当今社会唾弃，只有民主化才是迟早的选择，因为它至少可以守得住下限。 而且我个人认为，民主是一个持续的过程而不是一个简单的结果。绝对意义上的民主和拖沓低效的民主只会害了广大的底层百姓，极力避免的同时，也要最小程度的限制人滥用民主，这些就需要政府工作的透明化和规范化。 不过韩国的民主也有它的独特性，主要就是它有特殊的外界因素—-既不能得罪美国人，又不能惹毛了朝鲜（这一点跟台湾很像），所以无论是强权政府还是抗议民众都没有把事情搞得太过火。其次还有韩国中产阶级在抗议中也扮演了“理性和保守的一面”：他们是经济发展的受益者，对秩序有相当的敏感性，一旦社会民主斗争极端化，中产阶级便会退出民主运动，这是其保守性的表现。除此之外，还有比如基督教的传播代替了原有的儒家思想更追求自由等等因素，我这里水平有限，就不展开了。 最后补充一句，各位都知道《辩护人》里宋康昊的原型是卢武铉总统，据说片里宋康昊parter的原型就是韩国现在的总统—文在寅。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>政治</tag>
        <tag>亚洲民主</tag>
        <tag>影评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动手做一个网络简历并且保存成PDF]]></title>
    <url>%2F2018%2F03%2F02%2F%E5%8A%A8%E6%89%8B%E5%81%9A%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E7%AE%80%E5%8E%86%E5%B9%B6%E4%B8%94%E4%BF%9D%E5%AD%98%E6%88%90PDF%2F</url>
    <content type="text"><![CDATA[环境说明服务器:nginx浏览器:firefox 制作网页简历过程首先先下载简历的模板文件，过程如下： 1234wget http://labfile.oss.aliyuncs.com/courses/624/cv-template.zipunzip cv-templatemv cv-template/* .rm -rf cv-template* __MACOSX* 然后在浏览器里的地址栏里输入服务器外网IP，就可看到下面的界面，如图： 我们发现这个界面是可以编辑的，于是就在前人的基础上修改即可，这里感谢前人栽树！！！ 但是修改了并不是就保存了，如果你刷新这个界面发现又变成了初始的界面。所以这个时候我们要把修改过的网页的前端代码拷贝下来。 在firefox浏览器的配置里选择WEB开发者，如图： 然后选择查看器： 这个时候在页面就出现了整个网页的代码，选择复制—HTML外面： 然后把这个html代码拷贝到nginx服务器里的index.html里覆盖原有的内容，再重新刷新浏览器，就会成为已经保存过的界面了！ 将网页保存成PDF在浏览器里的配置里选择打印，然后现在页面设置里的勾选打印背景（颜色和图片）再修改一下页眉和页脚。再点击打印，默认情况就会保存成PDF文件了。 参考资料https://segmentfault.com/a/1190000006820290]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师笔试题第十五套]]></title>
    <url>%2F2018%2F03%2F01%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98%E7%AC%AC%E5%8D%81%E4%BA%94%E5%A5%97%2F</url>
    <content type="text"><![CDATA[正文1.粘包是什么意思？TCP和UDP是否会出现粘包？出现了粘包如何处理？[我的答案]粘包就是当客户端连续不断的往服务端发送数据包的时候，服务端接收的数据会出现两个数据包粘在一起的情况；UDP（非面向连接）是不会出现粘包的，因为UDP协议是基于报文的，UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP（面向连接）是基于字节流的，它无法识别包的长度，所以会出现粘包的现象。 解决办法主要有以下三种：1）发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了，有较高的效率而且少冗余，但是编程较复杂；2）发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来，编程简单但是效率一般甚至很低；3）可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开； 2.time_wait是什么情况？如果出现了过多的close_wait可能是什么原因？[我的答案]TIME_WAIT是主动关闭连接的一方保持的状态，在保持这个状态2MSLmax segment lifetime时间之后，彻底关闭回收资源。遇到TIME_WAIT数过大导致的服务器异常，很容易解决，修改下/etc/sysctl.conf就ok了。 如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。这个情况多半是代码的问题，在服务器端是无能为力的，要检查代码。 3.epoll和select的区别？边缘触发和水平触发的区别？[我的答案]select查询速度较慢，因为他每次产生fd时候会有整体fdset的拷贝，而且每次有回送，select要查询整个fdset；epoll查询速度较快，因为他为每个fd都regist了一个单独的回调函数。 水平触发(LT)：当epoll检测到其上有事件发生并通知应用程序时，应用程序可以不立即处理，这样当应用程序再次调用epoll中调用函数时，epoll会再次通知应用程序此事件,直到被处理。 边沿触发(ET)：当epoll检测到其上有事件发生并通知应用程序时，应用程序必须立即处理，并且下一次的epoll调用，不会再向应用程序通知此事件。 所以ET模式大大得降低了同一个epoll事件被重复触发的次数，因此ET模式工作效率比LT模式更高。select、poll、epoll的默认工作模式都是水平触发(LT)模式，但是epoll是支持边沿触发(ET)模式的。 4.varchar和char的区别是什么？utf8字符集下varchar最多存多少个字符？[我的答案]前面那个问题去看http://blog.51cto.com/chenx1242/1742467，这里说后面那个。在utf-8状态下的varchar，最大只能到 (65535 - 2) / 3 = 21844 余 1。在gbk状态下的varchar, 最大只能到 (65535 - 2) / 2 = 32766 余 1。 5.primary key和unique的区别？[我的答案]首先先说明primary key = unique + not null，其次Unique Key可以是空，可以在一个表里的一个或多个字段定义，也就是爱有几个有几个，同时存在也可以；但是Primary Key不能为空不能重复，而其一个表里只能有一个Primary Key。 6.乐观锁是啥，悲观锁是啥？[我的答案]悲观锁Pessimistic Lock, 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁Optimistic Lock, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。 两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 7.如何在python的三引号里添加变量？[我的答案] 1234567891011121314151617~$ pythonPython 2.7.3 (default, Jan 2 2013, 16:53:07) [GCC 4.7.2] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; &gt;&gt;&gt; context = """Here is an example block template:... name: %(name)s... age: %(age)d... job: %(job)s... """&gt;&gt;&gt; &gt;&gt;&gt; print context % dict(name="Tim Wang", age=45, job="Coder")Here is an example block template: name: Tim Wang age: 45 job: Coder &gt;&gt;&gt; 8.redis满了会怎么样？[我的答案]默认情况下redis满了就不会存储新的数据了，不过这个可以调整，redis在达到指定内存的时候可以通过设定的策略来做不同的动作，常见策略如下：1）noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）2）allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。3）volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。4）allkeys-random: 回收随机的键使得新添加的数据有空间存放。5）volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。6）volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。 9.啥是“脏读”、“不可重复读”、“幻读”？[我的答案]脏读又称无效数据的读出，是指在数据库访问中，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。 不可重复读是指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据。这是由于查询时系统中其他事务修改的提交而引起的。比如事务T1读取某一数据，事务T2读取并修改了该数据，T1为了对读取值进行检验而再次读取该数据，便得到了不同的结果。 幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 10.ext2、ext3、ext4的区别是啥？[我的答案]ext3和ext2的主要区别在于，ext3引入Journal。ext2和ext3的格式完全相同，只是在ext3硬盘最后面有一部分空间用来存放Journal（日志）的记录；在ext2中，写资料到硬盘中时，先将资料写入缓存中，当缓存写满时才会写入硬盘中；在ext3中，写资料到硬盘中时，先将资料写入缓存中，待缓存写满时系统先通知Journal，再将资料写入硬盘，完成后再通知Journal，资料已完成写入工作；在ext3中，也就是有Journal机制里，系统开机时检查Journal的资料，来查看是否有错误产生，这样就快了很多； ext4和ext3的主要区别在于:首先ext4与ext3兼容,ext3只支持32,000个子目录，而额ext4支持无限数量的子目录;ext3所支持的16TB文件系统和最大的2TB的文件，而ext4分别支持1EB（1,048,576TB，1EB=1024PB，1PB=1024TB）的文件系统，以及16TB的文件;ext3的数据块分配策略是尽快分配，而ext4是尽可能地延迟分配，直到文件在cache中写完才开始分配数据块并写入磁盘;ext4允许关闭日志，以便某些有特殊需求的用户可以借此进一步提升性能等等等等。 11.简述一下A记录与NS记录的区别1.A记录是名称解析的重要记录，它用于将特定的主机名映射到对应主机的IP地址上。你可以在DNS服务器中手动创建或通过DNS客户端动态更新来创建。2.NS记录此记录指定负责此DNS区域的权威名称服务器。3.A记录和NS记录的区别是，A记录直接给出目的IP，NS记录将DNS解析任务交给特定的服务器，NS记录中记录的IP即为该特定服务器的IP地址。4.NS记录优先于A记录，A记录优先于CNAME记录 参考资料https://blog.insanecoder.top/tcp-packet-splice-and-split-issue/http://blog.csdn.net/tiandijun/article/details/41961785http://www.redis.cn/topics/lru-cache.htmlhttp://blog.csdn.net/d_guco/article/details/53166722http://www.hollischuang.com/archives/934http://zhaodedong.leanote.com/post/Linux%EF%BC%9AExt2-Ext3-Ext4%E7%9A%84%E5%8C%BA%E5%88%AB]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>面试经验</tag>
        <tag>大牛之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[调用阿里云api获取阿里云数据同步服务（DTS）并且作图发送邮件的整个流程]]></title>
    <url>%2F2018%2F02%2F28%2F%E8%B0%83%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91api%E8%8E%B7%E5%8F%96%E9%98%BF%E9%87%8C%E4%BA%91%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%EF%BC%88DTS%EF%BC%89%E5%B9%B6%E4%B8%94%E4%BD%9C%E5%9B%BE%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E7%9A%84%E6%95%B4%E4%B8%AA%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言在https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/ 文章里已经说了“领导要求每天查看阿里云dts同步的延迟情况和同步速率情况”，并且在https://rorschachchan.github.io/2018/02/27/使用matplotlib画图的一个脚本/ 里面也放了一个使用python matplotlib画图的demo，这篇文章的目的就是把整个过程实现，并且把dts图形以每日邮件的形式发送给领导的效果！ 实现需求的思路本次需求有四个动作，分别是获取一天以内的DTS延迟和同步速率、将获取到的DTS值做成PNG图像、将生成的PNG图像上传到阿里云云存储OSS、把图片展示到邮件里并发送给相关领导。由于第一步获取一天以内的DTS延迟和同步速率需要将这个脚本每小时执行一次，执行24次，才可以执行生成png图像这一步，所以后三个其实可以写成一个大脚本。不过在本文为了表述的清楚，就把各自不同用途写成了不同的脚本。 获取阿里云DTS延迟和同步速率的脚本这个脚本之前写过了，这里再拿出来晒一遍： 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python#coding=utf-8#这个脚本是用来获取dts延迟数字的from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionimport time,json,syssys.path.append('/解压缩路径/aliyunsdkdts/request/v20160801/') #这里看不懂去看https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/import DescribeSynchronizationJobStatusRequest# 创建 Client 实例clt = client.AcsClient('这里填写ak','这里填写sk','cn-shenzhen')# 创建 request，并设置参数request = DescribeSynchronizationJobStatusRequest.DescribeSynchronizationJobStatusRequest()request.set_SynchronizationJobId("这里填写DTS的ID号")response = clt.do_action_with_exception(request)delay = json.loads(response)rate = str(delay["Performance"]["FLOW"])[0:4] #由于同步速率默认是带单位的，这里就取前四位#用A.txt来存储延迟时长fd = open("/存储路径/A.txt","a")fd.write(str(delay["DataSynchronizationStatus"]["Delay"]))fd.write('\n')fd.close()#用B.txt来存储同步速率 fr = open("/存储路径/rate.txt","a")fr.write(rate)fr.write('\n')fr.close() 将获取到的值做成图片的脚本由于脚本执行环境是无图像的阿里云服务器，系统是centos 7，ps.slow这一步会爆错RuntimeError: could not open display，所以只能采取把生成的PNG图像文件保存到本地路径里的方法。脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env python# -*- coding: utf-8 -*-import matplotlib as mplmpl.use('Agg') #在无法生成图像的环境下要添加了上面两句话import matplotlib.pyplot as pltimport numpy as npimport pylab as plx=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]#横坐标的内容labels=['10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','1','2','3','4','5','6','7','8','9']#y1是delay延迟时长with open('/存储路径/A.txt', 'r') as f: y1 = [] for line in f: lst = line.split('\n') #增加一个换行符，不然数字是不换行的 y1.append(float(lst[0]))#y2是rate同步速率with open('/存储路径/B.txt', 'r') as f: y2 = [] for line in f: lst = line.split('\n') y2.append(float(lst[0]))#输入对应的坐标，后面是颜色plot1,=pl.plot(x,y1,'r')plot2,=pl.plot(x,y2,'b')pl.xticks(x,labels)pl.title('这里写标题',size=20) #中文会显示乱码，推荐还是英文pl.xlabel('这里是X轴标题', size=14)pl.ylabel('这里写Y轴标题', size=14)pl.ylim(0.0,5.0)#曲线对应注释pl.legend([plot1,plot2],('Delay','Sync rate'),'best',numpoints=1)#开启网格pl.grid()#图片保存路径plt.savefig('/保存路径/图片名称.png', format='png') 将生成的图片上传到阿里云OSS的脚本由于不想让“领导去手动点开附件查看图像”，所以我们干脆把图片作为邮件的正文展示出来，那么就在html里就需要img src=图片的网络地址的方法。于是就把刚刚生成的图片上传到阿里云OSS里，这样就可以获得图片的网络地址。而且阿里云OSS是“相同文件名会覆盖”，所以不用再去删除。整个脚本内容如下： 1234567891011121314151617# -*- coding: utf-8 -*-import osimport shutilimport oss2access_key_id = os.getenv('OSS_TEST_ACCESS_KEY_ID', '这里填写ak')access_key_secret = os.getenv('OSS_TEST_ACCESS_KEY_SECRET', '这里填写sk')bucket_name = os.getenv('OSS_TEST_BUCKET', '这里填写bucket名称')endpoint = os.getenv('OSS_TEST_ENDPOINT', '这里填写内网end-point')# 确认上面的参数都填写正确了for param in (access_key_id, access_key_secret, bucket_name, endpoint): assert '&lt;' not in param, '请设置参数：' + param# 创建Bucket对象，所有Object相关的接口都可以通过Bucket对象来进行bucket = oss2.Bucket(oss2.Auth(access_key_id, access_key_secret), endpoint, bucket_name)bucket.put_object_from_file('上传到OSS的图片名称.png', '/服务器保存路径/图片名称.png') 将图片作为内容发邮件的脚本整个脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/env python# -*- coding: UTF-8 -*-import os,time,re,smtplib,loggingfrom email.mime.text import MIMETextfrom email.header import Headerdef send_mail(to_list, cc_list, html, sub): me = mail_user msg = MIMEText(html, _subtype='html', _charset='utf-8') # 格式化邮件内容为html，编码为utf-8 msg['Subject'] = sub # 邮件主题 msg['From'] = me # 发件人 msg['To'] = ";".join(to_list) # 收件人，将列表转换为字符串 msg['Cc'] = ";".join(cc_list) # 抄送人，将列表转换为字符串 try: send_smtp = smtplib.SMTP() # 实例化 send_smtp.connect(mail_host) # 连接smtp服务器 send_smtp.login(mail_user, mail_pass) # 使用定义的账号密码进行登录 send_smtp.sendmail(me, to_list+cc_list, msg.as_string()) # 发送邮件 send_smtp.close() # 关闭连接 return True except Exception, e: logging.basicConfig(filename='logger.log', level=logging.DEBUG) logging.debug(e) print ("ERROR!!!!") return Falseif __name__ == '__main__': mail_host = 'mail.dahuatech.com' mail_user = '这里填写发件人地址' mail_pass = '填写对应的密码' mailto_list = ['收件人邮箱地址'] mailcc_list = ['抄送人1的邮箱地址'，'抄送人2的邮箱地址'] html = """ &lt;body&gt; &lt;br&gt;&lt;img src="这里填写的是图片的http地址"&gt;&lt;/br&gt; &lt;table color="CCCC33" width="800" border="1" cellspacing="0" cellpadding="5" text-align="center"&gt; &lt;tr&gt; &lt;td test-align="center"&gt;上图是阿里云深圳VPC区数据同步过去24小时的情况。&lt;br /&gt; 注意事项 1:dts的延迟时间是5秒计算一次，api请求会取到最新的延迟时间，而控制台是每隔20秒才刷新一次； 注意事项 2:api在延迟时间取值为整数，即1.x显示为2，请知悉; 注意事项 3:此邮件是系统自动发出，如果有任何疑问请联系运维人员； &lt;/tr&gt;&lt;/br&gt; &lt;/table&gt; &lt;/body&gt; """ sub = "阿里云深圳VPC数据同步情况" if send_mail(mailto_list,mailcc_list,html,sub): logging.debug("Send mail succed!") else: logging.debug("Send mail failed") 上面四个脚本整个执行下来，效果如下，至此大功告成！ 参考资料https://github.com/aliyun/aliyun-oss-python-sdk/blob/master/examples/object_basic.pyhttps://hk.saowen.com/a/fe355cb5cc3ab17dbc84e9489621d2ab31da72b511092839832bc9e89d63bf71http://blog.csdn.net/baoli1008/article/details/47980779https://www.digglife.net/articles/html-mail-with-inline-images-python-perl.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个监控挂载盘的python脚本]]></title>
    <url>%2F2018%2F02%2F27%2F%E4%B8%80%E4%B8%AA%E7%9B%91%E6%8E%A7%E6%8C%82%E8%BD%BD%E7%9B%98%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[前言公司产品线有一个公用的挂载盘，主要是用来方便各位开发人员去放置他们自己的一些工作材料，比如异常的日志或者tcpdump的抓包等等杂七杂八的东西，但是这个挂载盘由于使用人众多，容量自然要有监控，于是就有了写这个脚本的动机。 在这里我写了两个脚本，上面这个是用来监控磁盘容量，然后通过df -h的排序生成前十名占容量最大的文件夹，把这个文件夹的名字和对应的大小重定向到一个叫alarm.txt这个文件里，这个文件就是邮件正文。然后在确定他们的主人，统一加上公司邮箱后缀来得到他们主人的邮箱地址，最后对应他们各自的邮箱地址用下面那个脚本来发送文件夹容量过高的邮件。 监控挂载盘的脚本12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# coding=utf-8import osimport AutoMailimport commands#设定变量判断是否挂载和挂载盘的容量mount = commands.getoutput("mount | grep ':.*nfs'|wc -l")size = commands.getoutput("df -h | grep share | awk '&#123;print $5&#125;' | cut -d '%' -f 1") ##建立发邮件的文本文件def Createalarm(): if os.path.exists('/root/chenscript/alarm.txt') == True: os.system("python /root/chenscript/weixin_sharealarm.py") print ("微信告警已经发送！") os.system("cd /root/chenscript; echo 'share盘容量大于80%，现在将调出容量排名前十位的文件夹名字及对应的容量，请各位处理一下不需要的文件！' &gt;/root/chenscript/alarm.txt") os.system("cd /挂载盘名称 ;du -s * --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹'|sort -nr |head &gt;&gt;/root/chenscript/alarm.txt") os.system("echo '\n' &gt;&gt; /root/chenscript/alarm.txt") if os.path.exists('/root/chenscript/alarm.txt') == False: os.system("cd /root/chenscript;touch alarm.txt")def Sendmail(): fp = open('/root/chenscript/alarm.txt', 'r') content = fp.read() AutoMail.send_mail('share挂载盘容量大于80%！收到邮件的各位请整理自己对应的文件夹！', content) #将邮件的文件刷新def Dellist(): os.system("cd /root/chenscript/;rm -f alarm.txt;touch alarm.txt")if mount == '1' and size &gt;= '80': print ("挂载盘存在！") print ("share盘容量大于80%...") Createlist() Sendmail() Dellist()elif mount == '1' and size &lt; '80': print ("挂载盘存在！") print ("share盘容量正常...")else: print ("挂载盘不存在，现在重新挂载...") os.system("mount -t nfs -o acl,rw,intr,soft,nolock,rsize=8192,wsize=8192 10.160.43.172:/share /share ") 发送告警邮件脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/env python#coding=utf-8#这个脚本的用途是用来发送邮件import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.mime.application import MIMEApplicationmailto_list=[] #这里为空list，会从list.txt里一行一行的当做元素添加进来#生成list.txtif os.path.exists('/root/chenscript/list.txt') == True: os.system("cd /挂载盘名称;du -s * --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹'|sort -nr |head|awk \'&#123;print $2\"@dahuatech.com\"&#125;\' &gt;&gt;/root/chenscript/list.txt")if os.path.exists('/root/chenscript/list.txt') == False: os.system("cd /root/chenscript/;rm -f list.txt;echo '本人的邮箱地址'&gt;list.txt")with open('/root/chenscript/list.txt','r') as f: f=f.readlines()for i in f: i=i.strip('\n') mailto_list.append(i)mail_host="这里填写邮箱主机"mail_user="这里填写发送人的邮箱地址"mail_pass="发送人的邮箱密码"mail_postfix="dahuatech.com"mail_sender="与mail_host内容相同"def send_mail(sub, content): me=mail_sender msg = MIMEMultipart() msg['Subject'] = sub msg['From'] = me msg['To'] = ";".join(mailto_list) content1 = MIMEText(str(content), 'plain', 'utf-8') msg.attach(content1) try: s = smtplib.SMTP() s.connect(mail_host) s.login(mail_user,mail_pass) s.sendmail(me, mailto_list, msg.as_string()) print('发送成功！\n') s.close() except Exception as e: print(str(e))os.system("cd /root/chenscript/;rm -f list.txt;echo '我本人的邮件地址'&gt;list.txt") 执行的效果如下： 隐藏的知识点1）du -s是按照字节来统计，--exclude=&#39;yunwei&#39;是在排序的时候忽略掉yunwei这个文件夹，容后再用sort -nr|head是得到从大到小前10名，如果得到后10名就是sort -nr|tail；2）如果使用的是import commands，那么commands.getoutput得到的是字符串！3）用mount | grep &#39;:.*nfs&#39;来判断挂载盘是否存在是一个很简单的方式，如果挂了多个，就用ip in的方式来进一步判断；4）python要一行一行的读取文件，就readline；5）python按行读取文件，去掉换行符\n的方法： 12for line in file.readlines(): line=line.strip('\n') 6）import Automail的时候，就已经把Automail.py这个脚本固定住了，这时候mailto_list已经不能变化了，所以要把添加list.txt放到这个脚本里。 发了邮件，连吼带骂一顿，终于把share盘容量下降到了69这样一个美妙的数字…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用matplotlib画图的一个脚本]]></title>
    <url>%2F2018%2F02%2F27%2F%E4%BD%BF%E7%94%A8matplotlib%E7%94%BB%E5%9B%BE%E7%9A%84%E4%B8%80%E4%B8%AA%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[准备工作之前在https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/ 里已经可以获取到阿里云DTS服务的延迟时长和同步速率。下一步就是把这些值以24小时为周期作一个图像，然后每天在固定时间发送到领导们的邮件里。 python作图的第三方工具叫matplotlib，安装步骤如下： 1234pip install matplotlib #画图模块pip install numpy #依赖的库pip install scipy #又一个依赖的库yum install -y Tkinter #如果是python3，那么就是yum install -y tkinter 脚本内容由于我是在centos 7里进行脚本操作，而linux服务器有没有安装图像，所以在执行import matplotlib.pyplot as plt的时候可能会爆错：RuntimeError: could not open display，这个时候需要在前面改成如下样式（注意先后顺序）： 123import matplotlib as mplmpl.use('Agg')import matplotlib.pyplot as plt 举一个简单的脚本例子如下，就是给予（x,y）然后连成曲线图的效果，脚本里数字的部分不加引号也是可以识别的，当然使用变量也可以。 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# -*- coding: utf-8 -*-import matplotlib as mplmpl.use('Agg') import matplotlib.pyplot as pltimport numpy as np import pylab as pl x=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]#横坐标的内容labels=['10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','1','2','3','4','5','6','7','8','9']a = '1'b = '2'c = '3'd = '4'#y1是延迟y1=['2','3','5','4','2','1','2','2','3','5','4','2','1','2','2','3','5','4','2','1','2','2','3','5']#y2是同步速率y2=[a,b,c,d,0.13,0.12,0.14,0.14,0.14,0.16,0.15,0.13,0.12,0.14,0.14,0.14,0.16,0.15,0.13,0.12,0.14,0.22,0.18,0.11]#输入对应的坐标，后面是颜色plot1,=pl.plot(x,y1,'r') #这里是有逗号的，用于参数解包plot2,=pl.plot(x,y2,'b') pl.xticks(x,labels)#图片的标题以及对应的字号大小pl.title('The DTS status of Shenzhen VPC',size=20)#X轴的标题和字号大小pl.xlabel('Time', size=14)#Y轴的标题，字号大小和长度pl.xlabel('Time', size=14)pl.ylim(0.0,5.0)#曲线对应注释pl.legend([plot1,plot2],('Delay','Sync rate'),'best',numpoints=1)#图片保存路径plt.savefig('/tmp/dts.png', format='png') 脚本执行效果之后，会在对应的路径里生成一个图片文件，然后把这个图片转移到windows，打开就看到效果了，如图： 这个图是全英文的，如果是中文的话，就会出现乱码，研究了半天也没搞明白，这一点让我很郁闷。 参考资料http://python.jobbole.com/81182/https://absentm.github.io/2017/03/18/Python-matplotlib-数据可视化/https://liam0205.me/2014/09/11/matplotlib-tutorial-zh-cn/https://morvanzhou.github.io/tutorials/data-manipulation/plt/1-1-why/https://www.lookfor404.com/%E8%BF%90%E8%A1%8Cggplot%E5%87%BA%E7%8E%B0%E9%97%AE%E9%A2%98no-display-name-and-no-display-environment-variable/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决https证书在赛门铁克认证失败的问题]]></title>
    <url>%2F2018%2F02%2F26%2F%E8%A7%A3%E5%86%B3https%E8%AF%81%E4%B9%A6%E5%9C%A8%E8%B5%9B%E9%97%A8%E9%93%81%E5%85%8B%E8%AE%A4%E8%AF%81%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述今天电子商城的市场接到一个故障，说更换了.lechange.com的https证书（原有的证书到期了，新买了一个依旧还是.lehcange.com域名证书）之后，订单在支付宝支付的时候提示支付失败。我把request id提供给支付宝的客服请他们查看一下后台，支付宝客服说我们电商的https证书没有认证成功。于是我就登陆https://cryptoreport.websecurity.symantec.com/checker/ 去检查一下电商的域名，果不其然，赛门铁克的反馈是错误的，如图： 但是登陆网站，在浏览器里却显示https证书是OK的，如图： 然后我用symantec的那个网站测试了一下电商平台开发环境的域名，发现也是OK的，如图： 这就郁闷了，到底哪里出问题了？ 问题排查首先跟研发确认，开发环境与线上环境在涉及到证书的代码是否一致，得到研发的确认之后。就检查服务器里的nginx，发现服务器nginx的配置文件里是没有涉及到ssl，无论是开发环境和线上环境都是通过阿里云slb配置的https证书。而且两者的证书指纹一模一样，如图： 既然都是用的一样的证书，为啥一个检验通过，另一个检验不通过呢？这个时候我想到线上环境与开发环境唯一的不同就是线上环境多了一个cdn，于是就登陆到cdn的控制页面，找到对应的https证书，发现cdn的https证书指纹也是跟上面的指纹一样，如图： 既然指纹一样，那证书也应该是一样的，场面又进入了一个僵局。 于是我就到一台服务器里使用curl -vv https://www.lechange.com，看到的结果如下： 提示未配置签发者根证书，我这时候想起来了，首先证书指纹一致不能说明证书是完全一致的，只能说明key文件是一样的！其次这个https证书是中级机构证书，那么中级机构颁发的证书链规则是这样的： 12345678-----BEGIN CERTIFICATE----------END CERTIFICATE----------BEGIN CERTIFICATE----------END CERTIFICATE----- 那么我怀疑就是https证书链那部分可能在cdn配置错误了，或许在slb配置错误了，甚至两个都配置错误了！ 于是干脆删除掉线上电商原有的https证书，重新导入cdn和slb的https证书，返回到symantec刷新，这次的检验结果就OK了。 补充虽然这个问题解决了，但是我还是不明白，为什么在网页端查看证书是绿色OK的呢？在sf.gg上提问之后，一个叫Avro的朋友是这么回答我的： 以chrome为例，他信任了[所在平台的信任证书列表][1]，而这些平台集成了一系列信任的根证书，如iOS 11 中可用的受信任根证书列表可以找到你的根证书“04 00 00 00 00 01 15 4B 5A C3 94 ”(序列号)，因此验证过程中没有问题，而对于其他的工具，如果未使用这些平台根证书信任列表依然需要完整的证书链（这个证书链在ssl握手过程中被下发）进行校验。 参考资料https://openclub.alipay.com/read.php?tid=3451&amp;fid=57&amp;page=1https://www.jianshu.com/p/84af353f43c5https://help.aliyun.com/knowledge_detail/39468.html?spm=a2c4g.11186631.2.2.w2qcWT]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>https证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录Apache Storm的部署始末]]></title>
    <url>%2F2018%2F02%2F25%2F%E8%AE%B0%E5%BD%95Apache-Storm%E7%9A%84%E9%83%A8%E7%BD%B2%E5%A7%8B%E6%9C%AB%2F</url>
    <content type="text"><![CDATA[前言Storm是一个流式处理框架（你可以把它当成一种消息队列），开发人员开发出特定的项目，然后通过storm这个渠道下发各种任务，从而达到任务执行的效果。 Storm有两个比较重要的组件：nimbus和supervision，其中nimbus主要是承接任务和分配任务用，而每一个supervision可以有若干worker（视服务器硬件而定），而supervison的主要任务就是监控对应的worker，一旦worker死了，supervision就会把他们唤醒。 本次试验是用的是金山云服务器，storm的版本是1.0.2，配置是1个nimbus，三个supervision，每一个worker上只执行一个任务，总共三个任务。 准备工作安装storm之前需要在storm里新安装一套zookeeper，因为storm是需要一个zk集群的，nimbus和每一个supervisior是通过zk的心跳来传递存活的信息，于是我们就在每一个supervision里面安装一个zookeeper，并且启动zookeeper的server端，安装zookeeper的方法可以移步http://chenx1242.blog.51cto.com/10430133/1889715 。 上面这段话用图来说就是这样子： 启动zookeeper之后，就需要在nimbus和supervisior里安装storm，上面说过本次安装的storm是1.0.2版本，路径直接是/storm/apache-storm-1.0.2。 将storm安装完之后，需要在nimbus和supervisior里更改/etc/hosts文件，改成如下的格式： 1234567891011127.0.0.1 localhost nimbus的内网IP online-nimbus-001supervision1的内网IP supervision-001supervision2的内网IP supervision-002supervision3的内网IP supervision-003 zookeeper的内网IP zookeeper的名称 #注意，这里的zk是给模块拉取配置的zkstorm的zk1的内网IP storm的zk1 #这里的zk就是给storm集群用的zkstorm的zk2的内网IP storm的zk2 #如果storm的zk是standalone模式，这里就不要写了。storm的zk3的内网IP storm的zk3 #如果storm的zk是standalone模式，这里就不要写了。 保存完/etc/hosts之后，还有一个比较重要的步骤，就是在/etc/ld.so.conf.d/这个路径里面建立一个ffmped.conf这个文件，文件的内容如下： 12/storm/apache-storm-1.0.2/lib/storm/apache-storm-1.0.2/lib/3rd 注意，/storm/apache-storm-1.0.2是我的storm路径，在实际情况下需要根据自己的路径进行更改。 把这个ffmped.conf建立成功之后，我们可以测试一下，如果输入ldconfig的话，会出现如下的内容，就证明达到了我们的效果： storm本身的bin目录夹里也有很多命令可以直接使用，为了调用storm list方便，我们需要把bin/storm这个可执行文件作一个软连接，方法就是先cd /usr/local/bin/，然后ln -s /storm/apache-storm-1.0.2/bin/storm storm。这样的话，我们就可以直接使用storm list来查看任务列表了。 Storm的具体配置安装了storm，调整了命令行，同时也搞定了ffmpeg.conf，下面就是调整storm的配置文件了，nimbus和supervisior都要修改。 storm的配置文件叫storm.yaml，路径位于storm文件夹下的/conf/文件夹，我们需要在这个文件里面输入如下的内容： 下面对配置文件作一个简单的解释：1）storm.zookeeper.port:zk的默认端口2181；2）storm.cluster.mode:storm的集群运行模式，这里我们也是采用默认的distributed（分布式）；3）storm.local.dir:storm使用的本地文件的目录，这个目录必须存在而且storm进程可读写；4）supervisor.slots.ports：这个地方在nimbus里可以不用管，但是在supervisior里是需要改的，如果你只打开6700，那么就只放开了6700端口，即只有一个worker，如果你打开了6700、6701、6702三个端口，那么就意味这个supervisior将有三个worker在工作，由于这次试验里我们每一个supervisor只开启一个任务，所以在supervisior的storm.yaml里这个节点就只保留6700，其他的就全部注释掉；5）nimbus.task.launch.secs:task启动时的一个特殊超时设置.在启动后第一次心跳前会使用该值来临时替代nimbus.task.timeout.secs；6）worker.childopts:设定每个worker (JVM任务)的最小和最大内存； 更改完了storm.yaml之后，就要在nimbus里面安装zkclient。直接复制粘贴过来就好了。 如果你不喜欢storm自带的日志格式，想更改一下日志的内容，那么就要在/storm/apache-storm-1.0.2/log4j2文件夹里面修改worker.xml，不过在这里善意的提醒，最好在修改之前先备份原有的worker.xml。 连接具体任务这次的实验包用的是我所在的公司开发内部使用的包，先把这个包的内容复制到/storm/文件夹下，同时mkdir install和makir properties这两个文件夹，在install文件夹里有开发写的任务的jar包和启动程序，如下： 而在properties文件夹里，应该有这个任务的配置文件，如下： 由于我们已经事前在/etc/hosts里指定了zkclient需要访问的zk的ip地址了，那么如果zk项配置正确，zkclient这个时候是可以成功启动的。同时在install文件夹里./update_stormserver_config.sh也应该是反应正确的。 然后我们就可以启动storm了。 启动nimbus和supervision启动storm要先启动nimbus，在/storm/apache-storm-1.0.2/bin里面启动run_nimbus.sh，然后等一下会有一大片东西出现，再jps一下就能看到nimbus已经启动了，如图： 从上图我们可以看到，18141的进程就是zkclient，只不过在jps里它名字叫AppServerDaemon，而zkServer在jps里叫QuorumPeerMain。 如果 storm出现Did you specify a valid list of nimbus hosts for config nimbus.seeds?的错误提示，那么就是nimbus没有启动的缘故。 启动了nimbus之后，就可以在supervisor的机器里去效仿着启动supervisor，但是这里要注意，如果你开启了一个supervisior，那么按照我们上面的配置文件，就启动了一个6700端口的worker，这个时候在nimbus执行下派一个任务的命令，nimbus就会下派这个任务给这个worker。 下派命令的例子如下： 1storm jar storm-starter-0.9.2-incubating-jar-with-dependencies.jar com.lechange.recordshare.RecordShareTopology 1 这样就启动了一个叫videoshare的任务，这个任务只用1个worker。 如果在命令行里反馈这样的错误： 1Error: Could not find or load main class storm.starter.recordshare.RecordShareTopology 或者exception in thread main java.lang.NoClassDefFoundError这样的错误，那就要检查jar包和路径。 而如果你再打开一个supervisor，在nimbus端又下发了一个任务，那么这个任务就会给刚刚新启动的supervisor。这样，启动一个下发一个，就会对每一个worker具体干的任务情况有一个比较清晰的了解。 在nimbus上执行storm list，就可以获得上图的样子，可以看出，我在nimbus端下发了三个任务，就是topology_name这一栏，他们的状态也是active，而workers数量都是1，也就是说在那三台supervisor里都在工作。而跑到supervisor一看日志，也是对应有各自的任务日志。 至此整个storm和具体的模块工作的搭建就完成了。 补充如果你事前一口气把三个supervisor都打开了，即开启了3个worker，然后一口气在nimbus端，一口气输入了三个下发任务的命令，那么这三个命令会随机的到这三个worker里，没有任何顺序而言，你只能通过日志的关键词来判断具体的worker做哪些任务。 而如果你的worker数量少于nimbus下发任务的数量，会有什么反应呢？ 答案就是任务根本没有worker去干，在storm list里，多余的任务对应的num_workers的数字是0，而如果这个时候你新增一个supervisor到这个storm集群，那么这个任务就会吭哧吭哧开始工作了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大数据分析</tag>
        <tag>storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DockerFile创建一个nginx容器的全过程]]></title>
    <url>%2F2018%2F02%2F25%2FDockerFile%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAnginx%E5%AE%B9%E5%99%A8%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[创建容器首先，随便建立一个文件夹，比如先mkdir sample，然后我在这个sample文件夹里建立一个Dockerfile，内容如下： 12345678FROM ubuntu:14.04MAINTAINER Chris Chan "chenx1242@163.com"ENV REFRESHED_AT 2016-12-05RUN apt-get -y update &amp;&amp; apt-get install -y nginxRUN mkdir -p /var/www/html/websiteADD nginx/global.conf /etc/nginx/conf.d/ADD nginx/nginx.conf /etc/nginx/nginx.confEXPOSE 80 从这个Dockfile里面看出：我们使用了ubuntu的基础镜像，然后下载了nginx，同时建立一个/var/www/html/website文件夹，然后又拷贝了宿主机上的两个文件，一个是global.conf，另一个是nginx.conf，这两个文件需要我们自己写。于是我们就要在sample下再建立一个叫nginx的文件夹，里面写上这两个文件，其中global.conf的内容如下： 12345678server &#123; listen 0.0.0.0:80; server_name _; root /var/www/html/website; index index.html index.htm; access_log /var/log/nginx/default_access.log; error_log /var/log/nginx/default_error.log;&#125; 而nginx.conf的内容如下： 123456789101112131415161718user www-data;worker_processes 4;pid /run/nginx.pid;events &#123; &#125;http &#123; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; gzip on; gzip_disable "msie6"; include /etc/nginx/conf.d/*.conf;&#125; 全部搞定之后，我们就来build这个镜像，比如这个镜像名叫做chentest/nginx001，在sample文件夹里使用的命令语句就是：docker build -t=&#39;chentest/nginx001&#39; .。 一顿七七八八之后，显示OK，docker ps -a就会显示我们新建的镜像，如图： 有了镜像，再在sample文件夹里新增一个文件夹，比如就叫webiste，里面有一个文件叫index.html。而index.html的内容如下： 1this is a nginxtest page. 保存退出之后，返回到sample目录。 现在我们可以制作一个容器了，制作容器命令是docker run -d -p 8080:80 --name test02 -v $PWD/website:/var/www/html/website chentest/nginx001 nginx -g &quot;daemon off;&quot;,这句话里规定容器的8080端口映射到宿主机的80端口，同时引入了当前目录的website目录到容器的/var/www/html/website目录，nginx也默认在前台进程进行。执行之后，docker ps -a看一下： 看见port这一栏已经显示8080与80端口的相勾结成功，于是我们可以登录这台机器的80端口看一下。 而如果现在我更改一下上面的index.html，改成另外一句话。比如说改成“why so serious??”,保存文件之后，直接刷新网页，就会看到网页的内容已经发生了变化，如图： 可见引入-v这个命令在容器里，可以随时调试内容，而不是每次都要重新打包生成镜像。这一点再调试阶段为我们提供了很大的方便。 docker端口映射的问题docker run命令里指定端口的格式是-p 容器端口:宿主机端口。如果想要随机指定就是大写的P。如图： 这里就是随机分配了一个32775端口给宿主机，访问的时候也是要访问这个32775端口。 有时候port这里却不显示端口映射的情况，如图： 这个情况是因为这个容器的status是exited，docker会在容器主进程结束后自动终止容器运行，而nginx启动后就会在后台运行，docker以为nginx已经结束运行了，所以就会停止容器。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DockerFile创建一个redis容器的全过程]]></title>
    <url>%2F2018%2F02%2F25%2FDockerFile%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAredis%E5%AE%B9%E5%99%A8%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[正文本次目标是用Centos 7的基础镜像做一个redis容器供开发人员在开发环境里蹂躏。 首先，创建一个叫redis-test的文件夹，在这个redis-test文件夹里建立一个Dockerfile，内容如下： 1234567FROM centos:latestMAINTAINER Chris Chan "chenx1242@163.com"ENV REFRESHED_AT 2017-02-16RUN yum -y update &amp;&amp; yum -y install epel-release &amp;&amp; yum -y install redis &amp;&amp; yum -y install net-toolsEXPOSE 6379ENTRYPOINT [ "/usr/bin/redis-server" ]CMD [] 这里我们简单说一下整个Dockerfile的内容： 首先选择了基础镜像是centos的最新版，即centos 7，然后填写作者信息； 在yum这一块要注意，如果没有安装epel-release的话，是无法正常安装redis的，这是centos与ubuntu不一样的地方。至于后面又补充安装了net-tools是因为centos 7里不自带ifconfig命令，所以需要安装一下net-tools，这样就有了ifconfig了； 随即我们又开放了6379端口； 然后就是entrypoint和cmd，这两个命令的区别很重要，具体区别请看：http://cloud.51cto.com/art/201411/457338.htm 这篇文章。 然后我们就可以依照这个Dockfile去建立一个镜像，因为目的是要在“centos环境下建立一个redis”，那么我们这个镜像的名字就叫作lccentos/redis，具体操作就是在redis-test文件夹下执行docker build -t lccentos/redis .。 然后根据这个镜像需要制作一个容器，容器的名字就叫redisforcentos，那么命令就是：docker run -d -p 6379 --name redisforcentos lccentos/redis。 然后我们docker ps -a看一下效果，如下： 可见宿主机的32774端口和容器的6379端口“融为一体”，这个时候，我们测试一下这个redisforcentos的容器是否已经正常启动了redis，如图： 而且对于Docker来说，可以多个docker对应宿主机的同一个端口，比如我这台机器搞了两个redis，两个容器都可以指向6379的端口，如图： Dockerfile的优化原则1）ADD和VOLUME应该放在Dockerfile底部，因为它们相对比yum安装那些变化的更勤；2）EXPOSE可以一口气对应多个端口，比如EXPOSE 80 2003 2004 7002的效果跟下面的效果一样； 1234EXPOSE 80 EXPOSE 2003 EXPOSE 2004 EXPOSE 7002 3）ADD的操作应该放在Dockerfile的最下面； 参考资料http://dockone.io/article/255?spm=5176.100239.blogcont40494.25.8RXqDX]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云获取DTS服务延迟值的脚本]]></title>
    <url>%2F2018%2F02%2F24%2F%E9%98%BF%E9%87%8C%E4%BA%91%E8%8E%B7%E5%8F%96DTS%E6%9C%8D%E5%8A%A1%E5%BB%B6%E8%BF%9F%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[正文春节“嗖”的一下就过完了，在年前领导交代另一个任务，想要每天统计一下在阿里云DTS（数据同步）服务的延迟情况，于是我就要使用阿里云的api去写一个脚本，每小时运行一次，然后将这24个数字输出出来给领导过目。 阿里云dts的sdk包在这里：https://help.aliyun.com/document_detail/57694.html?spm=a2c4g.11186623.6.675.W811bN ，直接点击Python下载即可，不过这个地址经我测试使用非国内IP 地址是打不开的，需要使用国内IP地址下载。 下载完毕之后，上传到linux服务器并解压，解压后的样子如图： 由于我们这次只是查看同步作业状态，所用的py就是DescribeSynchronizationJobStatusRequest.py，现在我们就可以写脚本，假设这个脚本叫getDTS.py,那么整个内容如下： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#auther:ChrisChan@2018-2-24#这个脚本是用来获取DTS服务的延迟值from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionimport jsonimport sys #由于这个包不是通过pip install的方式安装,要调用其它路径的python脚本就要使用sys方法sys.path.append('sdk压缩包的绝对路径')import DescribeSynchronizationJobStatusRequest # 创建Client实例clt = client.AcsClient('阿里云AK','阿里云SK','所属地域')# 创建request并设置参数request = DescribeSynchronizationJobStatusRequest.DescribeSynchronizationJobStatusRequest()request.set_accept_format('json')# 写上对应的服务IDrequest.set_SynchronizationJobId("这里写上DTS的ID")response = clt.do_action_with_exception(request)print responsedelay = json.loads(response)print "===================================================="print "当前延迟是：" + str(delay["DataSynchronizationStatus"]["Delay"])print "当前同步速度是：" + str(delay["Performance"]["FLOW"]) 整个脚本执行的效果如下： dts的延迟时间是5秒计算一次，API请求会取到最新的延迟时间，控制台是每隔20秒才刷新一次。 补充getDTS.py这个脚本获取到的response是一个str字符串，这里我使用json.loads来将其转化成了dict模式。但是除了这个方法还有两个方法： 123456789101112&gt;&gt;&gt; user"&#123;'name' : 'jim', 'sex' : 'male', 'age': 18&#125;"&gt;&gt;&gt; b=eval(user)&gt;&gt;&gt; b&#123;'age': 18, 'name': 'jim', 'sex': 'male'&#125;&gt;&gt;&gt; print b['sex']male&gt;&gt;&gt; exec("c="+user)&gt;&gt;&gt; c&#123;'age': 18, 'name': 'jim', 'sex': 'male'&#125; &gt;&gt;&gt; print c['name']jim 但是要注意！上面这两个方法有一定的安全隐患，而且只能全是字符串可用，如果有的value是True、False、Null这样的字眼的话，eval是不支持的，所以没法正确转换，就会爆这样的错：NameError: name &#39;True&#39; is not defined。 参考资料https://help.aliyun.com/document_detail/49453.html?spm=a2c4g.11186623.6.667.sRyVqYhttps://segmentfault.com/q/1010000000174694https://www.crifan.com/resolved_in_python_using_eval_to_force_variable_to_convert_a_string_to_a_dictionary_when_the_error_nameerror_name_39null39_is_not_defined/https://segmentfault.com/q/1010000000345915]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atlas的几种常见故障解决方法]]></title>
    <url>%2F2018%2F02%2F23%2FAtlas%E7%9A%84%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[使用atlas却发现“读库闲置，框架还是去主库读写数据”配置完atlas之后，发现使用jdbc框架的话，读库和写库各司其职，但是使用mybatis框架之后，就发现框架的读写都去了主库，把读库放置一边，那么这种情况是因为有事务存在的话，atlas就会强制走主库，遇到这种情况就检查一下是否有事务的存在，比如@Transactional，如果要解决的话，就加上@Transactional(propagation=Propagation.NOT_SUPPORTED)即可。 自动读写分离挺好，但有时候我写完马上就想读，万一主从同步延迟怎么办?SQL语句前增加 /*master*/ 就可以将读请求强制发往主库。在mysql命令行测试该功能时，需要加-c选项，以防mysql客户端过滤掉注释信息。不过这不能从本质上解决问题，使用Atlas需要考虑到这点，提高主机的IO性能，加大memory可以缓解延迟症状，但依旧不能避免延迟的出现，尤其是读多写少的应用。 resource limit的问题atlas有自己的连接池，会吃掉很多CPU, php应用端改用短链接来连接atlas, 这时候atlas对php发送来的sql只负责验证和转发的操作，后端DB的连接由atlas自己管理,未使用的连接线程进行剔除操作(DB的wait_timeout和interactive_timeout设置为300s,超时亦退出)。 1234562014-04-12 20:56:29: (warning) (libevent) event_del: event has no event_base set.2014-04-12 20:56:29: (critical) last message repeated 5 times2014-04-12 20:56:29: (critical) network-conn-pool-lua.c.144: socket() failed: Too many open files (24)2014-04-12 20:56:29: (warning) (libevent) event_del: event has no event_base set.2014-04-12 20:56:30: (debug) chassis-unix-daemon.c:168: 12951 returned: 129512014-04-12 20:56:30: (critical) chassis-unix-daemon.c:196: [angel] PID=12951 died on signal=11 (it used 16 kBytes max) ... waiting 3min before restart 如果MySQL后端的连接数也满了可能会报以下错误: 1232014-11-13 12:21:07: (critical) network_mysqld_proto_password_scramble: assertion `20 == challenge_len' failed2014-11-13 12:21:07: (warning) (libevent) event_del: event has no event_base set.2014-11-13 12:21:07: (critical) 可以临时增加MySQL connection数量: 1echo -n “Max processes=SOFT_LIMIT:HARD_LIMIT” &gt; /proc/`pidof mysqld`/limits 出现Too many open files的错误，怎么办？关于Too many open files错误，可能由两种情况引起:一、php长连接连接到atlas后，每个线程占用一个FD,直到超出系统资源限制而出现too many错误;二、php应用端发送到atlas的sql过多，大量并发的情况下,linevent维护的队列过多，每个event吃一个FD，超出系统资源限制引起Too many open files错误; 避免Too many open files错误,增加用户的ulimit值加大FD的使用量,可增加系统ulimit资源到 ~/.bash_profile文件或/etc/security/limits.conf文件: 123456# cat .bash_profile # .bash_profile......export PATHulimit -n 16384]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>atlas</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何手动释放linux内存]]></title>
    <url>%2F2018%2F02%2F23%2F%E5%A6%82%E4%BD%95%E6%89%8B%E5%8A%A8%E9%87%8A%E6%94%BElinux%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[在生产过程中，一些java模块会比较残忍的吃系统内存，然后如果这个模块写的比较挫，产生的垃圾就会比较多，如果linux系统的内存释放也不会及时，然后恶性循环，最后就把进程卡死，但是服务器是不可以down机的，所以这个时候就需要我们运维出来，手动的释放内存。 首先，我们登陆一台服务器，free -m看一下目前的情况： 然后cat /proc/sys/vm/drop_caches，会看到里面的值是0，0是不释放的意思。 sync,将系统缓存区中的脏数据写入磁盘中，包括已修改的i-node、已延迟的块I/O和读写映射文件。 echo 3 &gt; /proc/sys/vm/drop_caches 为什么这里是3呢？这是因为echo 1的话代表“清理页面缓存”，echo 2的话代表“清理索引节点（inode）链接”，echo 3就是包括上面两者。 sysctl -p,这样不用重启服务器也可以生效。出现下面的一连串文字之后，再free -m看一下： 从112释放到2790，可见效果立竿见影。 上面整个过程的自动化脚本是这样的： 12345678910#!/bin/bash#Author:Chris Chan#E-mail:chen_shuo@dahuatech.comoldmemory=$(free -m|sed -n '2p'|awk '&#123;printf $4&#125;')echo "开始的空余内存值："$oldmemorysyncecho 3 &gt; /proc/sys/vm/drop_cachessysctl -pcorrectmemory=$(free -m|sed -n '2p'|awk '&#123;printf $4&#125;')echo "释放完后的空余内存值："$correctmemory]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回家过年]]></title>
    <url>%2F2018%2F02%2F21%2F%E5%9B%9E%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[我承认我是一个很恋家的人，但是我在3年之前还不是这样。 我记得我在哈尔滨上大学的时候，虽然坐火车也就一个半小时的时间，但是是“能不回家就不回家”，哪怕自己一个人蹲在寝室也是自由舒服，后来上班，我也是有很长的时间自己独住，只有周末才回去一次。那时候我奶不止一次的批评我“都快成一个客人了”。 真的应了那句传烂了的话“只有失去的才是美好的”，现在我人在杭州，天天忙成狗。最欢喜的事情第一个是涨工资，第二个是发工资，第三个是放假，第四个就是放假回家。当初的我总是忽略家庭的温暖，在家里逗留的时间不长，现在却倍感珍惜回家的机会，唉，那几年真是简单的可笑。 这一次回家过年看到了许许多多亲人：生病的大姨夫的精神状态也好了许多，不过他这次回来又害了一次发烧；小外甥和他那婴儿肥的脸蛋，在《守望先锋》里越死越勇；我那几个弟弟们全都瘦了也更精神了，从我妈和女票看我的眼神里，我觉得我的体重是应该好好管控一下了：体型太腐败。 短短的六天时间，吃完三姨家吃四姨家，吃完老叔家吃小舅家，总之就是带着女票游走于各种亲戚家。中途还抽空跟龙南数据班的几个老同事一起吃了顿“一口猪”，主要也是带我女票看看东北菜，看上去我这几个老同事们都过得很不错，至少几杯酒下去均红光满面，依旧插科打屁、大呼小叫。这次过年唯一可惜的是，没有给四姨夫装上翻墙软件，害得他要继续挠墙忍耐。 我吃我妈的菜已经吃了30年，但是这次过年真正在家里吃饭仅仅只有一顿。我妈烧了虾，做了孜然羊肉，而且煮了酸菜馅饺子。这都是我爱吃的，杭州的确能吃到很多美味，但我妈的手艺却是独一份儿。我跟我爹依旧话不算多，但是关系却比之前好了许多倍。有可能是我现在比以前有了一点进步，让我爸看起来顺眼了一点，这一次回家没有跟我爸单独喝上酒，但是他有几顿喝的很开心。看到他俩这个年过得快乐满足，我这个做儿子的，心底涌起了最大的温暖。 离开家的时候，依旧是箱子沉沉，里面有爸妈装的许多东西，有给我的也有给我女票她妈的，每一个东西都是代表了他们的心思。其实家中长辈身体健康、心情愉悦，就是给我们这些在外的儿女最大的宽慰了。假期就这样结束了，我也马上要踏上回杭州的航班，希望家里所有长辈都平平安安，也希望我今年能够达到自己给自己定下的目标！]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>春节</tag>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国梦，宪政梦]]></title>
    <url>%2F2018%2F02%2F13%2F%E4%B8%AD%E5%9B%BD%E6%A2%A6%EF%BC%8C%E5%AE%AA%E6%94%BF%E6%A2%A6%2F</url>
    <content type="text"><![CDATA[本文原作者：《南方周末》评论部编辑戴志勇 天地之间，时间绽放。 这是我们在2013年的第一次相见，愿你被梦想点亮。 2012年，你守护自己的生活，他们守护自己的工作。守护这份工作，就是在守护他们对生活的梦想。 2012年，庙堂之上发出的宪政强音嗡然回响：”宪法的生命在于实施，宪法的权威也在于实施。”我们期待宪法长出牙齿，宪政早日落地。惟如此，才能成就这个沧桑古国的艰难转型；惟如此，国家与人民，才能重新站立于坚实的大地之上。 今天，已是能够梦想的中国，今天，已是兑现梦想的时代。经历过宪政缺失的”文革”梦魇，我们花费三十多年的时间来逐渐回归常理与常情。从土地联产承包责任制到个体户、乡镇企业到”民企”，稍稍归还国人自主安排生活的权利，我们便创造了繁华城市，收获了满仓粮食。 我们重新体认什么是真，什么是假，是其是，非其非；我们重燃对公义的热爱，对自由的向往。面对暴虐强力，我们双手相握，一起走过艰难时刻，迎接生活转机。 今天，我们终于可以从厚厚的历史尘埃中挺起胸，从琐碎的日常生活中抬起头，重走先辈的宪政长征，重温先辈的伟大梦想。 一百七十多年前，我们开始从天朝上国的迷梦中醒来。先败于英，后败于日。百姓愈加民不聊生，耻感深深刺痛中国士人。保国！保种！由洋务而君宪，由立宪而革命。从器物到制度再至文化，激愤者不惜彻底打倒”孔家店”，决绝地将自己的文明连根拔起。 辛亥革命后，清帝退位，先辈们终于建立了亚洲第一个共和国。但是，一个自由、民主、富强的宪政中国并没有随之而来。 国家内外，战争连连；人群内外，残酷不断。 一度，人们远离仁，远离义，远离天道，远离对自由的坚守。 一度，人们认错为对，指鹿为马，万千生灵生机断绝。 美梦与山河，齐齐破碎。自由与宪政，双双消隐。 度尽人世劫波，深味人性幽暗，我们依然是能做梦的人，有颗能做梦的心。 今天，我们断断不只梦想物质丰盛，更希望性灵充盈；我们断断不只梦想国力能强盛，更希望国民有自尊。新民和新国，救亡与启蒙，谁也离不开谁，谁也不能压倒谁。而宪政便是这一切美梦的根基。 兑现宪政，坚守权利，人人才能心如日月流光溢彩；鳏寡孤独才能感受冬日暖意而非瑟瑟发抖；”城管”与小贩才能谈笑风生；房屋才能成为自己与家人的城堡； 兑现宪政，限权分权，公民们才能大声说出对公权力的批评；每个人才能依内心信仰自由生活；我们才能建成一个自由的强大国家。 兑现宪政大梦，每个人才能做好个人的美梦。而这需要我们就从手边做起，就从守护此时此刻的生活做起，而不要将重任留给子孙。 很多人一直深深懂得这一点，很多人早就努力践行这一点。 不是杰出者才做梦，是善于做梦者才杰出。 你的天赋权利就是可以梦想，并且兑现梦想！ 为你的梦想鼓掌，为这个国家的梦想加油，这就是很多新闻人的梦想，是他们不大不小的野心。他们忠于新闻，更忠于内心。愿你也有个玫瑰色的美梦；自由成就自己，完成天之所赋。 总会梦想人人都可以做一个有尊严的人，不论身居高位，还是街头卖艺； 总会梦想人人内心有爱，即使罪犯也未必穷凶极恶，总有恻隐之心自由闪动； 总会梦想阶层只是引人自由流动的动力，而不再是相互猜忌和仇视的天堑；总会梦想这五千年文明生生不息，为改善人类的现代处境，捧出一掬甘冽清泉…… 兑现这一千一万个梦想，才能抚平这一百多年的刻骨痛楚。 兜兜转转一百七十年，美梦成真何其难！一百七十年后，依然有人渴望良知萌新芽，重温天命之谓性；依然有人坚持要求权利一一落地，政治复归于正，公义自在流淌。 依然有人相信，不管多难，梦想终会落实为宪政良制，风行为敦敦美俗。 先辈们筚路蓝缕，践义成仁。如今，后人承继其志，燃灯前行。 兑现梦想，自然要借鉴前贤智慧，与古人的信仰、习俗和情感和解。儒释道法墨，百家皆是源泉；周汉唐宋明，代代皆有可取。 但这决不是要复古，古人不能给予今天所需的一切。只是不再轻易贬损先辈，平心静气地吸收转进，以让中华文明开新花，结新果。 兑现梦想，自然要吸取世界经验。所以要认真审视希腊民主，罗马法治，借鉴英美宪政，追赶现代科技文明。 但这也不是仅仅作一个西方文明的优等生，西人有西人演进的轨迹，同样未必能直接给予我们今天所需的一切。 我们要站在自己的大地上，与各国人民一起，生活出一种古今相融的新生活，文明出一种中西合璧的新文明。在古今中西的激荡中，要遵循人类共通的价值，也要不惮于做自己的新梦。 称美古人，赞扬邻居，不是因为他们足够完美，而是因为我们熟悉他们眼中洋溢的快乐，心底流淌的自由。 中国人本应就是自由人。中国梦本应就是宪政梦。 宪政之下，才能国家持续强盛，宪政之下，才有人民真正强大。兑现宪政梦想，才能更好地外争国权，维护国家的自由；才能更好地内争民权，维护人民的自由。而国家的自由最终必得落脚于人民的自由，必得落脚于人人可以我口说我心，人人可以用心做美梦。 生而为人，谁能不热爱自由？这自由，不仅是权利针对权力而言，也是宽恕针对报复而言，是般若针对无明而言，是仁爱针对暴虐而言，是有道针对无道而言。 大道之行，天下为公；万物自在，各正性命。这就是古人的梦想，先辈的梦想，也是今天很多人的梦想。 中国梦，自由梦，宪政梦。 万物速朽，但梦想永在。万物诞生，因梦想不灭。梦想就是生生之几，就是当你失败了一百次，那第一百零一次充实你内心的不死之希望。 依然有人倾听你的梦想，期待你敢于做梦。你从苦难中爬起，他们为你加油；你尝尽人世冷暖，他们为你加油；你收获美好生活，他们为你加油……他们别无所资，惟有对梦想的执着；他们别无所长，惟有对真相的追求。 一句真话能比整个世界还重，一个梦想能让生命迸射光芒！]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>中国政治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于logrotate的额外补充]]></title>
    <url>%2F2018%2F02%2F12%2F%E5%85%B3%E4%BA%8Elogrotate%E7%9A%84%E9%A2%9D%E5%A4%96%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[https://rorschachchan.github.io/2018/02/12/日志文件管理者：Logrotate/ 里面已经简单介绍了logrotate命令，这里还有一些额外补充的东西： 1）查看logrotate对log文件的具体执行情况的语句是cat /var/lib/logrotate.status，效果如图： 2）使用-v或-d参数时，显示log does not need rotating，这是因为logrotate在对status未记录的文件进行转储时，会在status添加一条该文件的记录，并将操作时间设为当天。之后程序再次对此文件进行转储时发现这个文件今天已经操作过，就不再进行相关操作。要是想解决这个问题可以使用-s指定logrotate状态文件； 3）分割日志时报错：error: skipping &quot;/var/log/nginx/test.access.log&quot; because parent directory has insecure permissions (It&#39;s world writable or writable by group which is not &quot;root&quot;) Set &quot;su&quot; directive in config file to tell logrotate which user/group should be used for rotation.这是当前用户不是root，需要添加su root list这个语句到对应的logrotate配置文件里，比如： 1234567891011121314151617181920 /var/log/nginx/*.log &#123; su root list #第一句添加 daily missingok rotate 52 compress delaycompress notifempty #ifempty create 0640 www-data adm sharedscripts postrotate [ ! -f /var/run/nginx.pid ] || kill -USR1 `cat /var/run/nginx.pid` endscript &#125;4）如果觉得使用`logrotate`很麻烦，而当某个文件过大的时候，要实现把该文件压缩并且拆成若干个指定大小的文件，怎么办？ ```js tar -zcvf 新文件名.tar.gz 原文件名 | split -b 每个分格包大小 -d -a 1 - 新文件名.tar.gz 比如：tar -zcvf ABC.tar.gz ABC | split -b 4000M -d -a 1 - ABC.tar.gz。这个命令就是把ABC这个文件压缩成ABC.tar.gz，但是如果ABC大于4000M就会切块，切成ABC.tar.gz.0,ABC.tar.gz.1,ABC.tar.gz.2……这个样子。 123//使用split命令，-b 4000M 表示设置每个分割包的大小，单位还是可以k// -d 参数指定生成的分割包后缀为数字的形式//-a x来设定序列的长度(默认值是2)，这里设定序列的长度为1 如果要把这一堆已经切块的文件重新接压缩的命令：cat ABC.tar.gz.* | tar -zxv; 5）如果用kill -HUP来重启一个包含守护进程的进程，比如httpd，一条语句搞定： 1ps -ef | grep httpd | grep -v grep | awk '&#123; print $2; &#125;' | xargs -L 1 sudo kill -HUP 这里面首先用awk获取到httpd的pid进程号，然后把这个进程号传给了xargs，通过-L 1来一次提取一行pid值，然后分批进行kill -HUP; 6）想更多的了解守护进程，参看http://www.cnblogs.com/mickole/p/3188321.html；]]></content>
      <categories>
        <category>技术与工作</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>logrotate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志文件管理者：Logrotate]]></title>
    <url>%2F2018%2F02%2F12%2F%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E8%80%85%EF%BC%9ALogrotate%2F</url>
    <content type="text"><![CDATA[前言服务器在服务运行的时候，难免会生成大量日志，一般来说遇到日志过多的情况，就会写一个看门狗：监控磁盘容量的大小，如果磁盘剩余空间小于某个值，就去日志文件夹里把一个月或者几个月之前的废弃日志删除掉以达到释放磁盘空间的目的。 但是往往有的时候过期的日志很重要，或者即使是一周的时间内，也会生成容量非常可观的日志，那么就需要使用logrotate命令来管理这些日志，这个命令是linux自带的。 logrotate这个命令的用法请看：https://linux.cn/article-8227-1-rel.html和https://linux.cn/article-4126-1.html 。 实验开始首先，假设服务器里某个日志文件夹里的日志auc.log.10是这样的： 然后在logrotate的配置文件是这么写的： 12345678/mnt/hswx/auc/logs/auc.log.10 &#123; 这里是目标日志的绝对路径 daily 每天执行一次 minsize 200M 文件容量大于200M开始处理，如果到了时间但是没有大于200M，不会处理 compress 压缩 dateext 文件会以日期为后缀 create 777 root root 新建的那个日志文件属性是777 rotate 2 保留最多2个文件&#125; 然后执行logrotate -vf /etc/logrotate.conf，看到的效果是： 命令执行后，服务器create了新的auc.log.10，而且属性变成了777，同时把原有的部分压缩成gz的格式。 上面那个测试的对象是已经过期的日志，现在我们要压缩当前的日志，目的是在压缩了auc.log并且重命名之后，可以生成新的auc.log，同时这个新的auc.log会被写入。 现在我们尝试一下，把原来的配置文件改成这样： 123456/mnt/hswx/auc/logs/auc.log &#123; weekly minsize 200M compress rotate 2&#125; 但是执行之后，我们发现变成了这样： 原来的auc.log不见了，而出现的auc.log.1里面的内容是原来auc.log的内容，可见原有的auc.log已经被顶掉了。这是因为我们上面的配置文件里面没有加上dateext，所以默认会以.1、.2、.3为后缀。 问题是我们没有生成auc.log，那么这段时间的日志就会找不到auc.log而凭空消失。可见这个方法没有达到我们的目的，需要改进。 改进之后我们这个内部模块auc只有重新启动这个进程才会生成auc.log，既然要解决这样的问题，我们很自然的就想到kill -HUP这种平滑启动的方式，但是要注意！kill -HUP对deamon会进行重新读取配置启动，但是对于普通的进程只会把其杀死！而这个auc就是一个普通的java程序，没有配套的守护进程。所以只能使用一般的重启方式来达到生成auc.log这个目的。 首先我们把原来的配置文件改成这样： 1234567891011/mnt/hswx/auc/logs/auc.log &#123; weekly #每周执行 dateext #以日期作为后缀 minsize 200M #到达了200M自动执行，不然即使到了一周的时间也不执行 compress #压缩 rotate 2 #最多保留两个文件 sharedsripts postrotate #在执行完日志压缩之后就执行如下动作 /bin/bash /root/restart.sh #动作就是执行这个绝对路径的脚本 endscript #收工&#125; 而这个restart.sh的内容很简单: 1234#!/bin/bashcd /mnt &amp;&amp; ./stopAUC.sh #停止auc进程cd /mnt &amp;&amp; ./startAUC.sh #启动auc进程echo HAHAHAHA！！！ #表示已经OK了，让我们发出杠铃一般的笑声 现在我们重新跑一下logrotate，logrotate -vf /etc/logrotate.conf。看一下效果： 可以看到先把日志改名压缩，完事后也执行了restart.sh这个脚本，再日志里一看，auc.log也顺利生成了！ 参考资料http://www.pythondev.org/post/8.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个暗藏杀机的脚本]]></title>
    <url>%2F2018%2F02%2F11%2F%E4%B8%80%E4%B8%AA%E6%9A%97%E8%97%8F%E6%9D%80%E6%9C%BA%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[脚本背景老总最近总是发现某台relay服务器的CPU值会突然彪很高，于是勒令几位工程师检查问题，但是工程师一时半会也想不到究竟是什么程序这么耗费CPU，于是就委托运维写一个脚本，具体要求是这样的：每隔一秒钟输出一下top命令的前十二行情况（其实就是配置总览和耗费cpu前五名程序情况），将这些情况保存到一个文件里，如果这个文件大于500MB，就把这个文件删除（为啥要删除？我也不知道），重新再生成一个文件用来保存top命令结果。 分析由于脚本无法自己跳出运行并检查自己的大小，所以这个任务需要两个脚本，一个是单纯的把top命令重定向到一个文件（recordTOP.sh），另一个脚本就是一个if判断大小（checksize.sh）。再加上crontab每一天一检查（其实完全没必要，500MB足够top这个命令跑5天的），应该可以满足开发人员的需求。 脚本内容获取top.txt的脚本recordTOP.sh如下： 12345678910#!/bin/bash#written by ChenShuo @2016-8-15#Desription:每一秒钟记录一次top命令里占用cpu前五程序while true do $(top -bn 1 | head -12 &gt;&gt; /root/top.txt) echo "------------------------------------------------" &gt;&gt; /root/top.txt sleep 1 done 判断top.txt大小的脚本checksize.sh如下： 12345678910#!/bin/bash#written by ChenShuo @2016-8-15#Desription:当recordTOP.sh文件大小超过500MB的时候将会重新覆盖size=$(ls -l | grep top.txt |cut -d " " -f 5)if [[ $size -ge 536870912 ]] then $(ps -ef|grep recordTOP.sh|grep -v grep|awk '&#123;print $2&#125;'|xargs kill -9) $(rm -rf /root/top.txt) bash /root/recordTOP.sh &amp; fi crontab这一步我就略掉不写了。 补充说明1）top不可以直接重定向，如果是top &gt; 123.txt，它将会不断的导入，因为top就是一个实时更新的命令，所以这里要用top -bn 1|head 12 &gt;&gt; /top.txt； 2）shell脚本里调用shell，不能采用$()的方法了，因为$()是一个返回值，而.sh是一个不断进行的脚本，所以要用bash +脚本名的方式； 3）recordTOP.sh这个脚本是可以同时存在多个的，但是如果不小心后台启动多个，用checksize脚本ps -ef语句就会报错，因为获得到的不是一个数字，而是多个数字，没法一波kill掉。同理，直接调用checksize也会报错，因为没有ps -ef的值； 4）因为是要先关闭原来的top重定向脚本，所以才用了保守的ps -ef，然后kill的方式，这里不可以使用pkill，因为pkill是干掉整个类型程序，比如pkill -9 java，就是干掉所有java的进程。而在linux里，千万不可以pkill -9 sh，可以想象一下，这个命令的结果就是会从ssh上跳出，同时无法登陆，因为整个sh都被你杀死了。那么真的出现了这个结果怎么办？答曰：重启，重启能救命。 整个执行效果如下，可见top.txt文件是在不断的扩大，由于是测试，我把文件大小调整为20000字节，即大于20000字节就覆盖原文件，当文件大于20000字节的时候，就会把原来的top.txt删除，同时生成一个新的top.txt。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>top</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http返回码是000...]]></title>
    <url>%2F2018%2F02%2F11%2Fhttp%E8%BF%94%E5%9B%9E%E7%A0%81%E6%98%AF000%2F</url>
    <content type="text"><![CDATA[正文今天开发童鞋在测试往一个网站发请求的时候，发现返回码是000，如图： 众所周知，常见的返回码是以下四种： 12342XX 成功；3XX 重定向；4XX 客户端错误；5XX 服务器端错误； 但是000是啥玩意？简单的说就是没有有效的http状态码，比如连接被拒绝，连接超时等。 使用curl -w &quot;%{http_code}\n&quot; -m 5 https://60.191.94.115:38303/cloudSignalling/events/deviceState ; echo &quot;Exit code: $?看一下详细的code，显示如图： 可以看到提示：curl: (60) Peer certificate cannot be authenticated with known CA certificates，翻译过来就是对方的证书不能用已知的CA证书验证。但是下面也说了可以用-k或者--insecure来跳过这一步。 于是我又使用curl -I -k https://60.191.94.115:38303/cloudSignalling/events/deviceState这个命令，效果如图： 里面这一下说的就很明白了，405，方法不正确，再搭配一下curl -k -w &quot;%{http_code}\n&quot; -m 5 https://60.191.94.115:38303/cloudSignalling/events/deviceState，看一下： 这么上下一结合，明白了GET是不准许的，准许POST。于是反馈给60.191.94.115告诉他们把前后台接口请求方式、参数传递方式都拿回去整改。 参考资料http://www.1987.name/365.htmlhttps://superuser.com/questions/501690/curl-http-code-of-000]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将redis加入到elk日志系统里]]></title>
    <url>%2F2018%2F02%2F09%2F%E5%B0%86redis%E5%8A%A0%E5%85%A5%E5%88%B0elk%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E9%87%8C%2F</url>
    <content type="text"><![CDATA[之前在https://rorschachchan.github.io/2018/01/16/记录日志系统ELKB-5-6-4的搭建过程/里面，我画的那个架构图里说了整个架构可以加入redis，但是在文章里我没有写到redis怎么加进去。为了让整个系统更好的分层，是非常建议引入Redis的，毕竟Redis服务器是logstash官方推荐的broker选择。Redis作为一个缓存，能够帮助我们在主节点上屏蔽掉多个从节点之间不同日志文件的差异，负责管理日志端（从节点）的人可以专注于向 Redis 里生产数据，而负责数据分析聚合端的人则可以专注于从Redis内消费数据。所以这一次实验要把redis加进去，同时也要部署一个nginx，让elk再去采集nginx的日志。 整个架构图图下： 部署redis安装redis的方法请去看http://blog.51cto.com/chenx1242/1793895，我这里使用的redis版本是4.0.6，在执行make test的时候可能会有如下的错误： 那就安装新一点的tcl吧，方法如下： 12345wget http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gztar xzvf tcl8.6.1-src.tar.gz -C /usr/local/cd /usr/local/tcl8.6.1/unix/./configuremake &amp;&amp; make install 然后重新去make test就会看到成功的字样，如图： 现在redis的漏洞比较多，大多数就是因为密码太简单导致的，所以把redis密码改一下，在redis.conf里，改成如下的样子： 123456789bind 内网IP地址 127.0.0.1 ###仅允许内网和本机访问protected-mode yes ###保护模式开启port 6379 ###端口默认为6379，按需修改daemonize yes ###守护模式开启pidfile /usr/local/redis/redis.pid ###指定pid文件路径和文件名logfile "/usr/local/redis/redis.log" ###指定日志文件路径和文件名dbfilename redis.rdb ###指定数据文件RDB文件名dir /usr/local/redis/ ###指定数据文件RDB文件的存放路径requirepass 『YOURPASSWORD』 ###设置访问密码，提升密码强度 保存之后启动redis即可。 如果redis是主从配置，若master配置了密码则slave也要配置相应的密码参数否则无法进行正常复制的。需要在slave的redis.conf里找到#masterauth mstpassword，去掉注释，也改成跟master一样的密码，重启一下即可。 nginx的安装这里就不写了，直接看http://www.runoob.com/linux/nginx-install-setup.html这个就行了。 安装x-packx-pack是elk官方提供的认证授权插件，安装方法很简单，分别找到下面三个文件，然后后面加上install x-pack即可： 123./elasticsearch-plugin install x-pack --batch ./logstash-plugin install x-pack ./kibana-plugin install x-pack 如果要查看已经安装的插件，那就是： 1234[root@chen-elk-001 bin]# ./elasticsearch-plugin listx-pack[root@chen-elk-001 bin]# ./kibana-plugin listx-pack@5.6.4 如果kibana-plugin要卸载x-pack，那就是：./kibana-plugin remove x-pack。 重启服务即可登录，默认的登录用户名: elastic，密码:changeme。 这里注意一下，./logstash-plugin install x-pack的时候可能是出现ruby源的错误，如图： 这是因为中国特色社会主义的网络限制访问https://rubygems.org，一般来说，可以把它更改成阿里的ruby源https://ruby.taobao.org/，不过如果你的服务器无法跨越长城的话，那么更改也是不好使的，所以在这一步，我选择离线安装x-pack。也就是先把https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-5.6.4.zip这个文件下载到本地上传到服务器的root文件夹里，然后安装： 123[root@chen-logstash-001 bin]# ./logstash-plugin install file:///root/x-pack-5.6.4.zipInstalling file: /root/x-pack-5.6.4.zipInstall successful 配置filebeat由于这个nginx我们需要先让filebeat把nginx.log和error.log先推到redis存储，然后再由redis推到logstash。配置filebeat.yml的具体信息如下: 1234567891011[root@iZbp10hw6wezxmrvrcjyhlZ filebeat]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /usr/local/nginx/logs/*.log #这里是nginx的日志文件夹 output.redis: #以下这部分都是新加的 enabled: true hosts: ["127.0.0.1:6379"] key: logindexer_list #与redis配置文件里的key遥相呼应 password: 『YOURPASSWORD』 #跟上面的密码遥相呼应 配置完毕之后，启动filebeat，命令语句：/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml。 配置logstash由于这台logstash已经开启了一个logstash进程，那么再收集nginx的日志需要新开一个logstash进程，也需要新写一个conf文件，假设新的conf文件是nginx-logstash.conf，它的写法如下： 1234567891011121314151617181920212223input &#123; redis &#123; host =&gt; "10.168.173.181" type =&gt; "redis-input" data_type =&gt; "list" key =&gt; "logindexer_list" port =&gt; 6379 password =&gt; "ChenRedi$" &#125;&#125;# filter configration hereoutput &#123; elasticsearch &#123; hosts =&gt; [ "10.162.80.192:9200" ] user =&gt; elastic password =&gt; changeme index =&gt; "nginxlogstash-%&#123;+YYYY.MM.dd&#125;" #这个是新的索引 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 现在logstash不支持多个实例共享一个path.data，所以要在在启动不同实例的时候，命令行里增加--path.data PATH，为不同实例指定不同的路径。启动logstash之后，看到显示如下： 再到nginx的日志看一下，因为logstash里没有做日志的切割，所以是整个一个类似字符串的形式发送了过来： 果然有这样的日志，可见logstash与nginx的redis已经正确连接。在elasticsearch里，使用curl -u 账号密码 &#39;localhost:9200/_cat/indices?v&#39;查询索引的时候，就会看到那个nginxlogstash，如图： 参考资料https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/input/redis.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>大数据分析</tag>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-Atlas从库始终没有建立连接怎么办]]></title>
    <url>%2F2018%2F02%2F09%2FMysql-Atlas%E4%BB%8E%E5%BA%93%E5%A7%8B%E7%BB%88%E6%B2%A1%E6%9C%89%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E6%80%8E%E4%B9%88%E5%8A%9E%2F</url>
    <content type="text"><![CDATA[最近发现阿里云线上环境有一台hls模块的数据库从库一直没有连接，而主库却一直连接不断。在阿里云控制后台看到连接情况如下图： 上图是主库的，下面那个是从库的，两者差距很大，可见这样的配置是错误的，因为读库根本没有使用，也就是说读库的那份钱是在浪费！ 来到对应的atlas服务器查看配置，看到atlas 的配置里规定管理接口的用户名和密码是默认的原始套餐，端口被改成了2346，如下面， 于是我们就在模块服务器（也就是图里的online-hls-001)上登录这个atlas服务器的管理端口，看一下效果： 发现mysql根本没有反应，可当我们telnet去atlas的2346端口的时候，发现端口是通的： 于是我们返回到atlas 的配置文件，把这台hls模块服务器的ip地址添加到clients-ips这个字段里。 然后再用hls服务器去测试一下atlas的管理端口，mysql -hatlas服务器ip地址 -uuser -ppwd，然后使用select * from backends;,发现里面的两个库一个连接成功，另一个是失败的： 两个库都可以ping通，state却有这样的差别。由此可见这台atlas根本没有连接到从库，导致从库的连接数始终为0。这个时候我们就要检查从库配置的账号密码是否正确，而且在阿里云控制后台给从库开启这个atlas的白名单，然后重新启动这个mysql-proxy进程，再登录atlas管理端口查看，发现从库由down转up了： 但是此时的atlas日志里却出现了很多forbidden的warning的提示： 这时候我们返回atlas的配置文件，把之前的修改过的client-ips这个字段注释掉，让所有合法ip都连接，然后重启atlas，这样这种forbidden ip的警告日志就会消失。 稍等一会，就会看到从库上也会出现连接数了，至此一切恢复到正常状态，故障排除！ 本次故障排除感谢https://highdb.com/?s=atlas这位大神的帮助！ 文末补充数据库访问使用了事务的话，从库也会建立连接，只是连接量要小于“非事务访问”，而不是一点连接都没有。 一般来说，在atlas配置文件里，主库写一个，而从库最好把主库和从库都写进去，如果希望从库承担读的任务多一点的话，可以把权重调高，比如我想从库与主库的读任务比是2：1，那么就可以这么写： 1234#Atlas后端连接的MySQL主库的IP和端口，可设置多项，用逗号分隔proxy-backend-addresses = 主库地址:3306#Atlas后端连接的MySQL从库的IP和端口，@后面的数字代表权重，用来作负载均衡，若省略则默认为1，可设置多项，用逗号分隔proxy-read-only-backend-addresses = 从库地址:3306@2,主库地址:3306@1]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>读写分离中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[脚本里添加crontab的方法]]></title>
    <url>%2F2018%2F02%2F08%2F%E8%84%9A%E6%9C%AC%E9%87%8C%E6%B7%BB%E5%8A%A0crontab%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一般来说，增加计划任务都是crontab -e，然后在里面添加内容。但是在一些脚本里，需要自动添加，那么这种情况怎么办？ 第一种方法重定向crontab到其他文件： 123crontab -l &gt; crontab.bakecho "*/1 * * * * ./yourscript &gt; /dev/null 2&gt;&amp;1" &gt;&gt; crontab.bakcrontab crontab.bak 如果想删除某个计划任务，就进去crontab -e删除就好，crontab.bak不用管，不用担心内容会自动变成crontab.bak的样子。 第二种方法如果你觉得使用crontab 文件这种方法心里没有底的话，就选择最妥善的方式，也就是下面这样： 1echo "*/1 * * * * ./yourscript &gt; /dev/null 2&gt;&amp;1" &gt;&gt; /var/spool/cron/root 当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在百花之中干掉一个杂草连接...]]></title>
    <url>%2F2018%2F02%2F08%2F%E5%9C%A8%E7%99%BE%E8%8A%B1%E4%B9%8B%E4%B8%AD%E5%B9%B2%E6%8E%89%E4%B8%80%E4%B8%AA%E6%9D%82%E8%8D%89%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[正文早上接到阿里云的服务器报警，说有一台服务器的流量超标，这个服务器的外网带宽是5M，但是登陆进去使用iftop -i eth1发现里面的流量已经几乎跑满，如图： 我这个服务器的名称叫online-mts-001，为啥会有一个mail25.u.tsender.com，这个是什么鬼？莫非是通过我的服务器去连接这个“邮箱”域名？于是我就ping了一下这个mail25.u.tsender.com，结果如图： 看到这个域名对应的ip地址是115.29.177.8，嗯，115.29.177.8，哎？这个ip地址好熟悉啊，卧槽，这特么不是这个online-mts-001的外网ip么？ 也就是说我这个机器在我不知道的情况下被人绑定了一个域名！但是我这个服务器不是网页服务器，上面那个tsender.com的域名打不开，我检查了服务器一番，发现这个机器没有被人入侵的痕迹，只能说是被人有意/无意（无意的可能性更大，比如看错了阿拉伯数字）绑定了域名。 被人绑定了域名就好比被人起了外号一样，一旦非本人操作就不太好往下摘了，查了很多资料都没有办法，毕竟主动权不在我这里了。 但是回头过来，我们的重心是要解决那个占据了3M带宽的连接，netstat看了一下，发现这个连接的具体信息如下： 仅仅是干掉连接的话，方法有很多，关闭网卡再重开或者关闭相应的服务都可以，但是现在的问题是这台服务器是生产环境的服务器，它主要是给用户提供视频拉流，通过抓包分析得知，这位183.228.128.188的用户合法通过外网连接到了这台视频服务器，而且拉取的是高清视频，所以才占据了这么大的带宽。不过我们还是决定先断开这位用户的连接同时不动其他用户的连接，这位183.228.128.188的用户在客户端虽然会发觉视频断开，但是有缓存和人为刷新的客观因素，实际的体验不会差太多，至少不会投诉400… 那么如何干掉一个established连接同时保证其他连接呢？请使用tcpkill。 tcpkill的下载比较有说法，下面是安装步骤： 1234567wget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/libnids-1.24-1.el6.x86_64.rpmwget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/libnet-1.1.5-1.el6.x86_64.rpmwget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/dsniff-2.4-0.14.b1.el6.x86_64.rpmyum install libICE libSM libXmu -yrpm -ivh libnet-1.1.5-1.el6.x86_64.rpmrpm -ivh libnids-1.24-1.el6.x86_64.rpm rpm -ivh dsniff-2.4-0.14.b1.el6.x86_64.rpm 请按顺序操作，不然的话dsniff就会报错： 1234warning: dsniff-2.4-0.14.b1.el6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 0608b895: NOKEYerror: Failed dependencies:libnet.so.1()(64bit) is needed by dsniff-2.4-0.14.b1.el6.x86_64libnids.so.1.24()(64bit) is needed by dsniff-2.4-0.14.b1.el6.x86_64 安装完毕之后，就会生成tcpkill命令，如图： 然后断开上面那个大带宽连接的命令是：./tcpkill -i eth0 src port 9132 and dst port 9595 and src host 115.29.177.8 dst host 183.228.128.188或者./tcpkill -s 115.29.177.8:9132 -d 183.228.128.188:9595。 但是要注意一下！tcpkill一定要运行在能接收到应答包的主机上在，最好运行在连接或半连接存在的一端主机上，因为tcpkill会发现这个连接里有数据传输进而感知并且干掉。而且tcpkill默认情况下是只能干掉established状态的连接，对于假死连接（连接在，但是数据不传输）或者半连接（由于tcp keeplive没打开而又没有数据向对端发送，导致一直无法感知次连接其实已经断开）是无法断开的。 如果遇到上述所说的假死连接和半连接就需要手动更改tcpkill的源码，更改原理在https://yq.aliyun.com/articles/59308。 如果使用的系统是ubuntu or debian，还可以使用cutter命令，apt-get install cutter下载即可。使用方法：http://www.cyberciti.biz/tips/cutting-the-tcpip-network-connection-with-cutter.html。 至于第一个问题，怎么把这台服务器上的域名撤除，我倒要好好想想了… 参考资料http://www.cyberciti.biz/howto/question/linux/kill-tcp-connection-using-linux-netstat.phphttp://www.gnutoolbox.com/tcpkill-command/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix里item取值超时怎么办？]]></title>
    <url>%2F2018%2F02%2F08%2FZabbix%E9%87%8Citem%E5%8F%96%E5%80%BC%E8%B6%85%E6%97%B6%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[正文开发同学新开发了一个模块，需要运维监控一下8683\8682\9002这三个端口，于是我就在zabbix里把这三个端口进行了监控，但是却无法返回值，如图： 可见其他的自定义监控项是好使的，偏偏三个监控端口的项都是not-supported。我就进去到item里看看，type of information和data type都是正常的，而且每三十秒一次更新，应该是没有什么问题的。 于是我就去zabbix的server使用zabbix-get去试试，到底是怎么回事儿，使用结果如图： 可见使用zabbix_get是可以取到值的，而且取值都正确，三个正常的端口反馈都是1，而不存在的端口（9002）的反馈是0。可是,我发现使用zabbix_get取值pid是结果秒出，而取值net.tcp.listen则是等了几乎5秒钟才获得结果。那么问题就出在这里了。 调整zabbix_agentd.conf里的Timeout值，把其设定为10，然后重启zabbix进程就OK了。 补充1）https://www.xiaomastack.com/2015/07/03/zabbix_net-tcp-listen/comment-page-1/#comment-319，很多时候端口监听会出错，于是就用自定义键值的方法，但是小马哥博客里的这个方法在centos里是无法启动，zabbix会报语法错误。由于公司的zabbix是2.2版本，等我有时间需要细化一下这个语法。 2）调整unsupport items检查时间的方法是：在Adiministration里选择General然后在右侧下拉菜单里选择Other，然后修改Refresh unsupported items (in sec)的值，这个值得意思是“每多少秒去重新检查一下那些not_supported的值”。 3)这种长时间获取key的行为，很容易导致zabbix unreachable poller processes more than 75 busy这个错误，所以尽可能的不要添加这样的监控，而换用其它的方式。导致zabbix unreachable poller processes more than 75 busy这个错误的另一个原因就是可能有某台zabbix-agent死机了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>运维监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十六年，九个队，一份爱]]></title>
    <url>%2F2018%2F02%2F07%2F%E5%8D%81%E5%85%AD%E5%B9%B4%EF%BC%8C%E4%B9%9D%E4%B8%AA%E9%98%9F%E4%BC%8D%EF%BC%8C%E4%B8%80%E4%BB%BD%E7%88%B1%2F</url>
    <content type="text"><![CDATA[原文地址：https://www.theplayerstribune.com/caron-butler-retiring/ 我妈第一次坐飞机的时候可真心把她吓得不行，我想她那时候肯定对Pat Riley有一些悄悄的不满。 那是2002年NBA选秀后的一天，我们乘Pat Riley派来的球队机飞翔在30000英尺的高空，从威斯康辛出发到佛罗里达的迈阿密热火队报到。我现在一闭上眼也能想起当时我妈妈Mattie坐在一个宽敞的椅子里，时而看看我时而看看窗外，前后张望的样子。她的脸上交织出坐飞机的恐惧，但又很自豪的复杂表情。 “这整个飞机只为我们几个服务的么?”她简直难以置信，要知道整个飞机上的乘客只有我、我的家人和两个热火队的工作代表。 我其实也是觉得如此的不可思议，但是我要管理好自己的神态，让自己显得比较酷。我坐在的位置上，平复自己的心情，保持正常的呼吸。球队代表给我展示了属于Alonzo Mourning和LaPhonso Ellis的专位，这看上去太梦幻了。 我对我母亲说“这一切太梦幻了”。 我一直在告诉我自己，现在我已经是热火队的一份子了。不是我吹牛，我也曾经在康大的时候也坐过飞机去打比赛，但是从来没做过头等舱，这在那个时刻我就坐在这架专机比头等舱还要牛逼的地方。那是Pat Riley级别的仓位。我一直让自己尝试冷静，“Caron，冷静，你很棒，你是个爷们，你要表现的就像以前那样从容。” 当我回忆起来当时的情景，觉得实在太滑稽了。我一直试图去安抚我那位紧张的老妈，而其实我内心的紧张不比她少多少。 这就是16年前我去迈阿密热火队报到的情景，从此开始了我的NBA生涯。如果那时候你跟我说我要在十多年的职业生涯里为9个队伍打球，我想我的表情会跟当时飞机上我的老妈一样。 但是事情就这么发生了，顺其自然，这16年真是一段棒极了的旅行。而今天，我宣布正式从NBA退役。 你知道，我其实很想写一封信给年轻时候的自己，不过我想12岁的我应该压根不会理会这封穿越时空的信。如果他发现信封里没有钞票，可能就会直接把它扔进垃圾桶里。然后会嘲笑我现在的光头并且补上一刀“哥们，你真老”。 但我现在就想告诉你那些让我NBA梦成真的人和故事。而这一切的一切都要从当时热火队总裁Pat Riley开始。 我出生在威斯康星州的拉辛，在18岁之前我没有踏出过那里半步，不过我有听说过芝加哥，也见过有人在迈阿密的海滩上放风筝。除了康涅狄格州那两年，拉辛就是我的全部。大城市？我只有在电影和电视里看到他们的样子。 然后就是参加NBA选秀，不久我就接到Pat Riley总裁的电话，然后我成了迈阿密的一份子，那一切的一切彷佛是发生在我身体之外的。我觉得我可牛逼了，你知道么？我那时候简直是全世界最幸福的人，我准备把人生最好的青春时光投身于职业篮球，我要让家族骄傲，要让整个拉辛骄傲。 但我第一天踏进热火队训练馆的时候迎接我的不是派对，生活也不想在海边抽雪茄那么潇洒，迎接我的是“你的更衣间在这里，你迟到了，你应该早来一个小时的，明天开始训练，对了，你叫啥来着？” 这就是我到训练馆听到的第一句话，这就是热火给我的第一感觉。它让我停止了“从专机到专车，全家在迈阿密的豪华旅行，每个人都以我为豪”的感觉，开始了真刀真枪的训练—-我看到Pat Riley就站在训练场场边，他手上带着总冠军戒指，他很正经的跟你说，马上去好好训练或者从训练馆出去。 迈阿密的纸醉金迷让很多年轻人迷失，不过那种夜生活对我没有什么侵蚀力。我14岁的时候就有了我第一个儿子，我年少的时候可没少蹲过号子，记得我16岁的时候，警察曾经在我学校的储物柜里搜出来了毒品和手枪，我也被拘留了一段时间。我出自黑人街头，小时候经历了很多哥们朋友死掉。所以我没有期待过什么幸福温暖的日子，那时候，篮球是我唯一守护的东西。我尽力的不让那些声色犬马去分散我的注意力。 不过那时候我毕竟还是一个小孩，虽然我心态还算端正，但是我却不知道如何百分百的把精力都投入到训练里去。 最开始的几个月对于我整个职业生涯来说是非常重要的，热火队从一开始培养我的比赛观和胜负观，你把它想像成是一个称之为愿望也好，意志力也好，反正就是一个坚定的信念，我想正是这个信念让我能在NBA待这么久。我们为热火队打球，为Pat Riley总裁和Stan Van教练卖命。他俩教会了我如何正确的身体训练，正确的战术训练，叮嘱我们正确的去准备比赛，告诫我们细节决定成败。而这些都是你每晚在TNT直播中看那些NBA球员时所看不见的。 幸运的是，我很早就领悟到“天赋并没有你想象的那么重要”这个道理，当然，有天赋肯定很赞，但是如果你在比赛里倾尽所有、全力以赴，哪怕你的对手比你能跳能跑，但是你也有很大的几率赢球。钻研，不断地打磨技术，这才是赢球的不二法则。如果有人说“在NBA这么高水平的比赛里，基本功并不是重要”，这话简直就是痴人说梦。 Pat Riley教练会以各种不同的方式教我事情，我永远不会忘记他会在我的更衣柜上留下字条，我会在训练前看到这些字条，上面有些写的是我技术上缺陷和需要进步的地方，有些写的是励志的话语。那虽然只是简单的一两句话的便条，但是每一句话都对我有着绝大的影响，这就是我跟我篮球教父之前所建的秘密联系通道—用我们自己的语言去彼此沟通，正是这每一张字条让我成为了一个更好的篮球选手。多年之后，我转会去了雷霆队。我开始效仿当年Pat Riley给我留字条那样的给Kevin Durant留字条，KD是我的小兄弟。我很惊讶和感激在他的MVP的获奖演讲里他特别提到了这个事儿。但是我看来，我只是做了我的篮球恩师Pat Riley做的事情。 第二年，当我得知被交易去湖人队的时候，我很受伤，我以为Pat Riley跟我在篮球层面的之间是有特殊关系的。我的意思是说，如果我当时在Pat Riley的位置上也会把自己拿去交易Shaq的。如果你看着镜子中自己，然后说你比Shaq对这个队伍更有价值，那我无话可说，因为我实在不想打击你的自尊心。 不过那种失落并没有持续很久啦，这就是在联盟里生存的学费。就像我前面说的，我在拉辛住了十多年，我也希望终老迈阿密。我还记得跟D-Wade、Brian Grant、Eddie Jones、Alonzo这些家伙一起打球的日子，那是一段令人难以置信的学习经历，我会永远记得和那些家伙一起玩的开心时光。但是这就是生意，不久后我就动身出发去洛杉矶报到，身边的人从Dwyane Wade变成了Kobe Bryant，Dwyane Wade是我的铁哥们，但是这个世界也没几个人会拒绝跟Kobe联手。当我到了洛杉矶也就大约一周的时间吧，当初到迈阿密的紧张感觉被我忘个干净。 我仅仅在湖人效力了一个球季就被交易去了华盛顿奇才，有趣的是，那个交易对我来说没什么伤害。我认为那是一个很好的决定，当时的奇才队有很多年轻的充满天赋的选手，我很高兴有机会成为他们的一员。 华盛顿的六年是我一生中最棒的时光，在奇才队我两次入选全明星赛。我和Antawn Jamison、Brendan Haywood、以及当时还没有称呼自己是“Hibachi”的Gilbert Arenas在东部打出了一片天,我永远记得华盛顿人民是多么的热爱那支奇才队。纵然迈阿密和洛杉矶都是超级大城市，但是华盛顿却是我职业生涯效力时间最长的地方，那是我第二个篮球之家。 交易帮助我学习到了篮球生意的真相，我不论到哪个球队，都试图在训练里做一个榜样，就用当初在迈阿密学到的那套。我在健身房里专注训练，总是要求自己做的更好，总是要求自己记住细节。在每一支队伍里我都与队友们打成一片，我的意思是，换做是你整天跟这帮队友们泡在一起，如果你不是太拘谨的话，会很容易融入这个集体的。 不过我毕竟辗转了九个城市，这漂泊的生活对我的家庭来说是很困难的。要知道，我那时仅仅在菲尼克斯就待了一个月左右的时间，我的妻子Andrea又不得不收拾行李搬家去下一站，所以我的孩子们总是在不停的转学转学。我妈–她一直以我为荣，即使我不是比赛中的MVP，但是只要我命中投篮但是没有拿下比赛最佳球员她都会在场边不爽（谢谢你，老妈）。但我也深知，为了我的篮球生涯，其实我的家庭牺牲了很多。 我现在感谢上苍，我依旧活着，这简直是一个奇迹。我现在想谈谈生与死，上周，我回拉辛去参加一个葬礼，那是一个26岁的小伙子，从他的车上逃离的时候被警察连开数枪。我本人不认识他，但是我理解那种感觉。因为我和那些在拉辛长大的朋友，我们都知道死亡随时都降临的恐惧感。我深深地理解被困在那里是一种什么滋味，我很幸运我走出来了。我知道那些被杀或者误入歧途的人没有离开那座城市。我参加过很多个葬礼，那很难受。不过很奇怪，在生活中你会像我一样已经达到了一定的高度，当周围人告诉你你已经挺过来了，你也会想“我真的做到了”，就是这样，但是并不是那么简单。我想我还是回回到家乡来看看的，以后也常回来。 对于现在的我来说那些拉辛的孩子就跟曾经的我一样，我也出生在这里，我也曾经是拉辛的孩子，我也做过各式各样的蠢事。但是我从中交了学费，要知道从教训里学习的确不是一个容易的事儿，我花的时间比我母亲期望的时间要长，但是我最终还收获了经验。一旦我有一个目标，就要付出全部，我不想让那些相信我的人失望。我能拥有如此多的东西，我已经很知足了。 文章的最后我想说几个人，这可能会像是一连串名单，毕竟我在联盟里摸爬滚打了这么多年，肯定有很多人要去感谢，如果我忘记了提到某人，那请准许我提前道歉。 在我开始第一场NBA比赛之前，我的妻子就对我说无论我去哪里她都会跟着，这么些年，她一直信守当初的承诺。这辈子讨到她做老婆真是我的福气，无论是现在还是将来她都会是我生命里最棒的那部分。 感谢BJ Evans、Rob Wilson、Tim Donovan、Andy Elisberg、Jay Sabol、Marjie Kates、Shivani Desai、Tim Grover 和整个Arison家族在我职业生涯初期给我的帮助。 我要感谢Buss 家族、Mitch Kupchak、Magic Johnson、Alison Bogli和Eugenia Chow在洛杉矶给我的支持。 感谢Ernie Grunfeld、Milt Newton、Tommy Amaker、Sashia Jones、Candace、Susan O’Malley在华盛顿给我的帮助。 感谢老板Mark Cuban和主教练Rick Carlisle在达拉斯给我的帮助。 还有我在快船队的队友们：Blake Griffin、DeAndre Jordan、CP3–正是你们让我从重伤中走出来，重获新生。 Matt Barnes、Lamar Odom、Chauncey Billups还有我的偶像Grant Hill，我不会忘记跟你们一起的那段日子。 我一直都梦想能穿着雄鹿队的队服打球，感谢John Hammond和Senator Kohl，你们圆了我的梦，说实话在家乡打球的感觉真好！谢谢你们。 在雷霆队，我要感谢总经理Sam Presti、KD和Russell Westbrook。 在活塞队，我要感谢Tom Gores，而且在底特律能跟Stan Van重聚，并且与我的哥们Andre Drummond、Reggie Jackson和Caldwell-Pope一起打球。 Vlade Divac，是你在2016年给那个躺在沙发里以为生涯到此结束了的我打了电话，让我再去国王队跟Rajon Rondo和DeMarcus Cousins打了一年球。 还有一个需要特别说的，那就是刚刚去世的我永远的哥们Rasual Butler，我俩同一年进入联盟。像我一样，Rasual Butler也是一个辗转多队的浪人，但他身上有我敬佩的一切特征—勤奋、专业、积极、体育精神。他是一个人民交口称赞的好队友。哥们，NBA的家人们会想你的。 我的粉丝们，你永远不会知道你们曾经带给我的快乐。谢谢你们的支持!我希望每当你想到Caron Butler这个名字的时候，你会记得我曾经是多么的热爱和尊重比赛，我也希望你们会记住我付出所有时的那个形象。我知道这是一个陈词滥调，但那个形象对我来说要比比赛还要重要–这让我可以去面对一个严峻的未来。 我现在仍然会深深地回想起2002年那次飞往迈阿密的情景，当时我和我的家人在热火队的飞机上—不是因为昂贵或奢侈，也不是因为我第一次去海边。而是因为那是我一生中第一次真的感觉要去某个地方。 在NBA打球是我的梦想，我和所有这些伟大的教练和队友们一起度过了这16年，那是一段比我想象的要好的时光。我虽然身体已经不适合打NBA的比赛，但是篮球依旧在我的生活里，我会以另外的一种形式继续跟它在一起。 我只想让你们都知道我拥有我自己的生命，但正是有了你们的帮助，这个生命才活的如此多姿多彩。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>NBA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录Uwsgi与Django成功勾搭的始末]]></title>
    <url>%2F2018%2F02%2F07%2F%E8%AE%B0%E5%BD%95Uwsgi%E4%B8%8EDjango%E6%88%90%E5%8A%9F%E5%8B%BE%E6%90%AD%E7%9A%84%E5%A7%8B%E6%9C%AB%2F</url>
    <content type="text"><![CDATA[环境说明Uwsgi版本：2.0.14(yum install安装）django版本：1.10.6（pip install安装）python版本：2.7.5(阿里云 centos 7自带）nginx版本：1.10.2（yum install安装） 正文在https://rorschachchan.github.io/2018/02/02/Uwsgi的安装和简单使用/里面，我们已经实现了网页打开出现”good bye,logan”的效果，可见Web Client &lt;===&gt; uWSGI &lt;===&gt; Python是通畅的，现在我们要调整看看django与uwsgi是否是通畅的。 首先，我们在/django这个目录下，django-admin.py startproject logan，建立了一个叫logan的project，然后在/django/logan/logan里会有一个自动生成的wsgi.py，打开一看，里面的内容如下： 12345678910"""WSGI config for logan project.It exposes the WSGI callable as a module-level variable named ``application``.For more information on this file, seehttps://docs.djangoproject.com/en/1.10/howto/deployment/wsgi/"""import osfrom django.core.wsgi import get_wsgi_applicationos.environ.setdefault("DJANGO_SETTINGS_MODULE", "logan.settings")application = get_wsgi_application() 我们原来的目标就是测试django跟uwsgi的链接是否正常，那么返回到/django/logan，使用python manage.py runserver 0.0.0.0:8000启动django，然后打开浏览器，在地址栏里输入外网ip:8000，看到了如下的界面： 可见django已经启动成功，但是前面说过了，这种方法只能测试环境里小规模的玩玩，完全不推荐拿去生产化境里。所以现在我们用uwsgi在8000来启动一下django。 首先，先停止了原来我们启动的django。 然后，使用命令uwsgi --http :8000 --wsgi-file logan.py,反馈错误信息如下： 出现这个错误，那就yum install uwsgi-plugin-python，同时使用uwsgi --plugin python --http-socket :8001 --wsgi-file /django/logan/logan/wsgi.py，这样却又出了一个新错误： 提示说：ImportError: No module named logan.settings。可是当我使用python客户端单独测试的时候，这个语句是可以使用的，如图： 很多人都卡在了这种情况，这个时候我们需要换一个命令：uwsgi --plugin python --http-socket :8001 --chdir /django/logan/ --wsgi-file /django/logan/logan/wsgi.py。然后我们在浏览器地址栏里输入外网地址：8001就可以看到如下网页： 可见，我们已经通过uwsgi启动了原本已经关闭了的django，这样就达到了Web Client &lt;===&gt; uWSGI &lt;===&gt; Django的目的。 如果过程中出现了端口被占用的情况，比如8002端口已经被使用了： 12probably another instance of uWSGI is running on the same address (:8002).bind(): Address already in use [core/socket.c line 764] 那么就可以使用lsof -i:8002，然后把对应的进程干掉就好了。 最后附赠python脚本一个，这个脚本可以显示python的path，内容如下： 12345import osprint '===== sys.path / PYTHONPATH ====='for k in sorted(os.environ.keys()): v = os.environ[k] print ('%-30s %s' % (k,v[:70])) 参考资料http://www.python88.com/topic/101/http://www.nowamagic.net/academy/detail/1330334]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>uwsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins与钉钉机器人实现手机端获取当前服务日志]]></title>
    <url>%2F2018%2F02%2F06%2FJenkins%E4%B8%8E%E9%92%89%E9%92%89%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%90%AD%E9%85%8D%E6%89%8B%E6%9C%BA%E7%AB%AF%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E6%9C%8D%E5%8A%A1%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[马上要过年了，各位运维们除了因为买不到回家的火车票而嚎嚎大哭之外也开始扩容服务器和提前调整监控值，目的就是为了过一个消停的春节。可是这毕竟十天左右不在公司，要是模块真出了什么意外肯定没法第一找到日志分析问题，毕竟这几天都在串门拜年和醉生梦死中度过，走到哪都要再背一个笔记本实在太不方便了。 那么这个时候，我就琢磨使用手机端来启动服务器里脚本，让这个脚本可以去获取当前的日志，然后再把结果返回到手机端。这样就不用到哪里都带那个一看就很扫兴的公司笔记本电脑了。 使用手机端启动服务器里脚本？我又不会开发android和ios，那么肯定就要使用第三方工具，我条件反射的想到了jenkins，因为jenkins是用手机可以登录的，那么在手机端得到结果用什么呢？在微信公众号和钉钉机器人里，我选择了钉钉机器人。 创造钉钉机器人我的钉钉版本是4.2.6.37，首先在左上角头像的三角菜单有一个机器人管理，如图： 然后选择自定义机器人，给它起个名又换一个图标之后，添加到一个群聊里，如图： 添加的时候，这个机器人会生成一个webhook，它的结构应该是：https://oapi.dingtalk.com/robot/send?access_token=XXX，后面的XXX是标识符，不同的标识符代表不同的机器人，这个标识符如果丢了，可以在机器人头像点击一下然后选择机器人设置重新看到。 编写机器人脚本机器人的官方说明网址就是https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.zZIvnt&amp;treeId=257&amp;articleId=105735&amp;docType=1，这里面已经把使用方法写的够清楚了。我这里的这个python脚本是用json的格式，如下： 1234567891011121314151617181920212223242526272829303132#!/bin/python#coding: utf-8import json,urllib2#这里是机器人对应的Webhook地址url = "https://oapi.dingtalk.com/robot/send?access_token=这里输入你机器人的标识符#这里是头，原样复制就好header = &#123; "Content-Type": "application/json", "charset": "utf-8" &#125;#这里是传送的消息data = &#123; "msgtype": "text", "text": &#123; "content": "这里是消息正文！" &#125;, "at": &#123; "atMobiles": [ "A的手机号", "B的手机号" ]， "isAtAll":False #这里True代表要发给所有人，False的话，要代表消息只发给A和B这两个人 &#125; &#125;sendData = json.dumps(data)request = urllib2.Request(url,data = sendData,headers = header)urlopen = urllib2.urlopen(request)print urlopen.read() 直接执行这个脚本，就会看到我刚新建的钉钉机器人在群聊里说话了。 机器人搭配nginx上面那个脚本已经可以初步实现我们的目的，但是有一个缺点，就是正文内容不能过长。但是我想多打印一点日志，至少50行，怎么办？我想了想，可以把日志放进nginx的一个网页里，然后用钉钉机器人反馈这个网页地址啊，这样内容想写多少就可以写多少了。 假设我现在获取到的日志的文件写进一个叫chairmanmao.html里，在浏览器打开看是这样的： 那么上面那个机器人的python脚本就要改成这样： 1234567891011121314151617181920212223242526272829303132#!/bin/python#coding: utf-8import json,urllib2,commandscommands.getstatusoutput('echo -e "THIS IS TEST MESSAGE！ \n" &gt; /路径/chairmantail.html') #这里可以给网页加一个标题commands.getstatusoutput('cat /路径/chairmanmao.txt &gt;&gt; /路径/chairmanmao.html') #这里就是把诗词写进html文件里#这里是机器人的webhook地址url = "https://oapi.dingtalk.com/robot/send?access_token=这里输入你机器人的标识符"header = &#123; "Content-Type": "application/json", "charset": "utf-8" &#125;data = &#123; "msgtype": "link", "link": &#123; "text": "点击网址就可获取到本次日志查询的结果", "title": "日志查询结果已经生成！", "picUrl": "http://p1x3hd2at.bkt.clouddn.com/nanshen.jpg", #这里可以加一个缩略图片 "messageUrl": "http://服务器外网IP地址/chairmanmao.html" &#125;, "at": &#123; "isAtAll":True # at为非必须 &#125; &#125;sendData = json.dumps(data)request = urllib2.Request(url,data = sendData,headers = header)urlopen = urllib2.urlopen(request)print urlopen.read() 执行这个脚本可以看到机器人发送的信息如下： 然后打开这个网址，就看到完整的网页信息： 到时候把毛主席诗词换成实际的日志文件就好了，不用一口气打印所有的日志出来，tail -n 50 日志文件名，50行足够用了。 配置Jenkins脚本写完了，机器人也写完了，这个时候就要添加“启动端”。安装Jenkins的步骤我这里就不写了，直接可以去看https://rorschachchan.github.io/2018/02/05/Jenkins安装与创建简单任务/。现在去登录Jenkins的网页，去添加一个新的Job，比如我这个Job就叫“获取模块日志”，如图： 如果是要在Jenkins上去读取其他服务器的日志，就可以在构建project的时候选择参数化构建过程，然后配置参数ip，到时候把这些ip传递给目标脚本。如果觉得这样hold不住，可以不用jenkins的这个功能，把ip写到脚本里去，一了百了： 在构建那一步，选择Execute Shell，然后里面写上具体的shell命令，如果在上面使用了参数，那么参数就可以在这里使用，我的脚本里是没有ip这个参数的，在图里写$ip就是做一个例子讲解一下用法而已： 在构建后操作这一步可以选择E-mail Notification，这样如果失败了会发送邮件通知。如果用不着就什么都不用选。然后就是保存好这个project，点击左侧菜单栏的立即构建，就会看到下面Build History会多一个#1出来，同时钉钉机器人也在群里发消息，这个#1就是构建的记录，这个纪录多了的话，新纪录会覆盖掉老的记录。 点击这个#1，选择控制台输出，就能看到具体的操作结果了，跟在shell界面里执行的效果差不多的。可见操作成功，目的已经达到了！ 以后需要调用脚本，就在手机端浏览器里登陆jenkins，然后构建一下这个project，同时就可以看到钉钉里机器人有反馈了。 参考资料https://xu3352.github.io/linux/2017/05/01/jenkins-restart-remote-server-tomcathttps://github.com/typ431127/zabbix_dingding]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>钉钉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次官网打不开的经历]]></title>
    <url>%2F2018%2F02%2F06%2F%E4%B8%80%E6%AC%A1%E5%AE%98%E7%BD%91%E6%89%93%E4%B8%8D%E5%BC%80%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[今天有人反映官网在登陆的时候，chrome浏览器不能正常打开页面，反而会出现一个下载框。我使用IE浏览器尝试登录官网，页面也不是正常的页面，而是下面的内容： 由于官网的域名跳转是在阿里云的域名解析的地方配置的，于是就登陆到阿里云的域名解析地方，查看了一下发现，这里的配置是www.lechange.com会302跳转到home.lechange.com，而ping一下home.lechange.com得到的ip地址是一个负载均衡的地址，然后在阿里云的控制台查询这个负载均衡的情况，发现这个负载均衡后面挂载的是两台服务器A和B。 于是我在浏览器里面直接输入负载均衡的ip地址，发现还是像上面那样错误的php界面，而浏览器地址栏使用两个服务器的外网ip却是正常可以打开的。这个时候初步怀疑是SLB的问题，而我当时就觉得就凭上面这一点就去跟阿里撕逼不太妥当，但是事实告诉我们事情不是那么简单的。 我检查一下slb的端口配置情况，分别是http 80转8080和https 443转80，可见这个网站有两个协议，一个是http的而一个是https的，我们刚才虽然在浏览器里直接使用A和B的外网ip访问是可以正常打开页面，只能说明http协议是OK的，我们还要测试一下https协议访问的效果。 我就在浏览器地址栏里进一步尝试，发现使用A外网ip：8080访问是OK的，而使用B外网ip：8080访问就是PHP的文字界面。于是基本问题定位到B服务器里有文件的配置错误。 登陆到B服务器里，在nginx的conf文件夹里发现一个多余的文件，打开内容如下： 12345678910111213141516server &#123; listen 8080; server_name www.lechange.com (file://www.lechange.com/) www.lechangebuy.com (file://www.lechangebuy.com/); index index.html index.htm index.php; root /data/www/ecstore; add_header pos 'web2'; # location / &#123; # rewrite ^/(.*)$ https://www.lechangebuy.com/$1; # &#125; location /public &#123; root /data/www/ecstore; &#125; access_log /data/logs/nginx/access.log; #access_log off; &#125; 而原来nginx是有正常的conf文件，现在又多余了一个这个文件，可见是因为没有无法正常解析.php的文件，两个文件都在占用8080端口时出现了冲突，所以就导致这样php download界面的情况。删除这个多余的文件后，重启nginx，清除浏览器缓存，再重新尝试就正常打开页面了。 为什么会多一个这样的文件，后来把各位运维人员严刑拷打一顿才知道，原来有一次某运维小弟在B服务器里面做跳转的测试，测试完毕之后忘记了把这个多余的文件删除，原本这一切是没有问题的，但是可能服务器nginx经历了重启，于是就加载了这两个conf文件，就把这个隐藏的问题暴露了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[往github里上传代码]]></title>
    <url>%2F2018%2F02%2F05%2F%E5%BE%80github%E9%87%8C%E4%B8%8A%E4%BC%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[说来惭愧，使用hexo博客这么久了，但是真正使用github保存代码却是第一次。因为要打算自己搞一个jenkins试试自动化部署，所以就打算把我那些不堪入目的代码放在github上，然后用jenkins去执行。今天这篇文章就是来记录如何把本地的代码文件上传到github上的过程，本次过程是在windows下操作的。 建立远端仓库首先登录github的界面，然后建立一个新的仓库（repository），如图： 在建立仓库的时候，要注意最好选择一下Initialize this repository with a README这个选项，这样可以省去一些麻烦，如图： 在这里就用我刚建立的仓库—chentest。 建立本地仓库首先我们先去http://windows.github.com/上下载git工具，在安装的时候你还可以顺便登陆，如果没有github账号的话这一步可以跳过的。 安装完毕你的鼠标右键应该多了一个功能Git Bash Here，此时，可以在电脑找一个文件夹，这个文件夹不推荐安装在C盘，假设我就在E盘根目录下叫chentest的文件夹，这个文件夹名称应该与我们刚刚建立的github仓库名称相同。不然的话，可能在git pull的时候爆fatal: refusing to merge unrelated histories这个错误。 在这个chentest的空文件夹空白处，右键鼠标，然后选择Git Bash Here，就会出现一个类似dos的命令行窗口，此时需要输入git init，这个时候发现chentest文件夹里多一个隐藏文件叫.git，这就代表本地仓库已经创建成功了。 配置公私钥然后就是建立一个SSH key，以后你上传任何东西到远端仓库的时候都要输入这个key，那么在命令窗口输入ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot;，此时会让你输入一个文件路径，这个路径就是存放SSH key公钥和私钥的地方，由于我这个电脑已经在默认的/c/user/33664/.git/id_rsa已经存放了hexo博客的上传密钥了，于是我就手动把路径改成了/c/user/33664/.git/id_rsa-github，如图： 这里注意！如果你也之前有一个git id_rsa密钥的话，我个人强烈推荐这个密钥跟之前的id_rsa密钥是一样的。 在浏览器里返回到github的settings主页，在SSH and GPG keys里点击New SSH key，然后就把刚刚生成密钥的pub版输入进去，这个公钥是可以告诉别人的，但是私钥要保密好。如图： 再命令行里输入ssh -T git@github.com，这时候会让你输入一下/c/user/33664/.git/id_rsa的密钥，由于我刚刚把id_rsa-github密钥和id_rsa密钥内容是一样的，所以就输入正确了。如图： 进一步配置此时，再在命令行里输入如下的语句： 12345git config --global user.name "your name"git config --global user.email "your_email@youremail.com"git remote add origin git@github.com:用户名/Git仓库名称.git #我这个例子里就是chentest.gitgit config branch.master.remote origin git config branch.master.merge refs/heads/master 一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。 加完之后进入.git，打开config，这里会多出一个remote “origin”内容，这就是刚才添加的远程地址，也可以直接修改config来配置远程地址。如图： 下载与上传由于这次是我们第一次上传，那么按照惯例，我们需要先下载一下，使用git pull origin master --allow-unrelated-histories，然后输入id_rsa密钥，看见chentest就多了那个README.md文件了。把这个README.md文件改成这样： 12# chentest这是一个做测试的仓库，做好了之后，就先尝试把代码传上去，然后结合Jenkins来搞！ 同时也写一个新的代码，比如这个文件就叫test1.md，里面内容是： 1234#/bin/bashecho "hello,chrisChan!"echo "this is your first git"ifconfig 这个shell脚本内容就是输出两个废话，然后打印ip地址。保存test1.md，然后在命令行里输入如下的内容： 123git add README.mdgit commit -m "提交注释" #这个注释内容是会在网站上体现出来的git push origin master git push命令会将本地仓库推送到远程服务器，而之前说过的git pull命令则相反。同样的输入id_rsa密钥，然后就会看到文件成功上传了！如图： 来到github网站里一看，果然刚刚写的那个test1.md出现了，如图： 结语通过刚才的操作，我想各位应该对github操作有一点初步的了解。其实Git命令行是一个版本控制工具，Github是一个用Git做版本控制的项目托管平台。形象解释的话Git相当于是弓，GitHub是靶，你的代码是箭，弓把箭射到靶上。 参考资料https://www.jianshu.com/p/0fce531dba31http://blog.csdn.net/zhangmingbao2016/article/details/73478899http://www.cnblogs.com/findingsea/archive/2012/08/27/2654549.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins与Github组合成持续集合环境]]></title>
    <url>%2F2018%2F02%2F05%2FJenkins%E4%B8%8EGithub%E7%BB%84%E5%90%88%E6%88%90%E6%8C%81%E7%BB%AD%E9%9B%86%E5%90%88%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[生成Token码首先登录github，在首页选择settings，如图： 然后点击最下面的Developer settings，点击Personal access tokens，最后点击Generate new token，如图： 输入名称和权限，权限选择repo和admin:repo_hook这俩，如图： 然后就会生成一个token密码，这个token密码请妥善保存，丢失或者删除就GG了。 将Token码配置到Jenkins浏览器返回到Jenkins界面，在首页里点击系统管理，然后选择系统配置，在系统配置里面添加一个GitHub Servers，在Add Credentials这一步的时候，要把kind改成Secret text，如图： 这里Secret的地方就是填写刚刚生成的Token码。 保存之后，点击一下test connection，如果出现Credentials verified for user xxx, rate limit: xxx的字样就是成功了，如图： 设置webhooks在github里找一个源码库，选择settings，然后点击小菜单栏里的Webhooks，再点击右边的Add Webhook即可，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins的安装与创建简单任务]]></title>
    <url>%2F2018%2F02%2F05%2FJenkins%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%9B%E5%BB%BA%E7%AE%80%E5%8D%95%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[安装与启动环境：CentOS 7.0 + java 1.8 安装方式： 12345yum install yum-fastestmirror -y #安装自动选择最快源的插件#添加Jenkins源:sudo wget -O /etc/yum.repos.d/jenkins.repo http://jenkins-ci.org/redhat/jenkins.reposudo rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.keyyum install jenkins #安装jenkins 启动方式：sudo service jenkins start，如果没有java是无法启动的。 Jenkins默认端口是8080，如果要更改端口，需要先vim /etc/sysconfig/jenkins，然后修改JENKINS_PORT=&quot;8080&quot;为自己想要的端口号即可。 访问方式：浏览器输入http://your server ip:8080/，然后会看到这样的一个界面，打开这个文件，输入里面的key就可以访问jenkins了。 然后就是让你安装插件，如果是新手的话，可以安装系统推荐的插件，如果插件安装失败不要怕，可以日后手动补上。 插件安装完毕之后，就是自己创建一个管理员账号和密码，输入之后，点击右下角保存并完成。 然后就可以看到Jenkins初始化的首页。 创建任务假设现在要创建一个Job(任务)，这个任务就是输出当前服务器的外网IP地址，那么就点击首页里的新建任务，然后输入任务名，补充一句，生产环境里的Job名最好不用中文，不做死就不会死，然后选择构建一个自由风格的软件项目，如图： 在源码管理的地方，我们暂时选择None，待日后把jenkins与github相关联之后，就可以通过github来配置源码了。在构建触发器的地方，我们选择Poll SCM，这里说一下这几个触发器选项的意思： 1234Build after other projects are built： Build periodically ： 周期进行项目构建（它不关心源码是否发生变化），可以配置如下：0 2 * * *（每天2:00 必须build一次源码）Build when a change is pushed to GitHub： 只要github上有提交了，jenkins没有自动检测到并构建，这设置之后在github中也需要设置才能生效Poll SCM：定时检查源码变更（根据SCM软件的版本号），如果有更新就checkout最新code下来，然后执行构建动作。可以配置如下：*/10 * * * * （每5分钟检查一次源码变化） 构建步骤这里有很多的选项，我们选择Execute Shell，里面可以写shell命令也可以写shell脚本，这里我就写入一个很简单的ifconfig命令去查看一下IP地址，如图： 构建后操作这里也有很多的选项，这里我选择E-mail Notification，然后输入自己的邮箱地址，这样如果构建失败了，就可以发邮件提醒。如图： 配置完毕之后，点击左下角保存即可。 查看任务效果返回到Jenkins的首页，我们看到多了那个刚才新建的任务，然后点击任务名旁边的小三角，选择立即构建，如图： 然后就会看到构建的历史，点击任意历史记录的控制台输出，就会看到效果，的确是操作了ifconfig命令的效果：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群的搭建与配置]]></title>
    <url>%2F2018%2F02%2F05%2FZookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Zookeeper的下载地址：https://github.com/apache/zookeeper/archive/master.zipzkclient的下载地址：https://github.com/sgroschupf/zkclient 至于zookeeper的作用和原理我这里就不多赘述了，大家有兴趣可以去查查，这里主要就是动手操作。 搭建集群首先先看一下本次zk实验服务器的名称和IP情况，这里我们选择了三台服务器作zkserver，因为三台是标配，一台的话就只有leader没有follower，不是很稳定的结构，当然啦如果你的公司土豪的话是可以玩三十台： 123dvl-mrszk-001 10.117.0.125dvl-mrszk-002 10.117.1.158dvl-mrszk-003 10.168.152.227 对这三台服务器都要进行如下的步骤: 1)先把zookeeper.zip传到linux里，然后解压到/usr文件夹下； 2)进入/usr/zookeeper/conf文件夹，vim zoo.cfg，在最下面补充上面的三个zkserver，见图： 3)再来到/usr/zookeeper/data文件夹，如果里面有文件就清空所有文件，如果是1号zkserver就echo 1 &gt; myid，如果当前机器是2号zkserver就echo 2 &gt; myid，依次类推，这里一定要注意，不可以都写一样。 4)vim /etc/hosts，还要把这三台机器的ip地址和名字都写进去，如下： 12345127.0.0.1 localhost::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.117.0.125 dvl-mrszk-00110.117.1.158 dvl-mrszk-00210.168.152.227 dvl-mrszk-003 5)再来/usr/zookeeper/bin文件夹，./zkServer.sh start启动zk，然后再./zkServer.sh status查看进程情况，如图看见第一台和第三台zkserver的身份是follower，第二台是leader： 至此整个zk集群就搭建并且启动完成了。注意：zookeeper集群时，zookeeper要求半数以上的机器可用，zookeeper才能提供服务。 故障排除如果这里有启动失败的情况，比如Error contacting service. It is probably not running.这样的字样，那么有这么几种可能：1）data文件夹下的myid有数字重复或者是数字漏写的情况；2）zoo.cfg里的指定日志文件夹没有手动创建；3）/etc/hosts下的名字与zoo.cfg里的server字段不相符，注意一下，/etc/hosts里的127.0.0.1的名字不要与本ip后面的名字一模一样，不然zk也无法识别！4）/etc/hosts名字使用了中文，java系对中文是很不友好的。 如果出现的Cannot open channel to X at election address /A.B.C.D:3888的日志报错，检查一下zoo.cfg里的123与myid的123是否一致。 配置文件详解1.tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。2.dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。3.clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。4.initLimit：这个配置项是用来配置 Zookeeper 接受 客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 52000=10秒。5.syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是22000=4秒。6.server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。 验证成果Zookeeper的配置工具叫Zooinspector，下载地址是：https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip，下载完直接解压缩就可以在windows里使用。 我们实验的这三台服务器只有内网，但是如果要连接zooinspector，还是需要通过外网权限连接的，这里可以配一个iptables转发规则，配iptables的步骤在这里：http://chenx1242.blog.51cto.com/10430133/1875950 ，照葫芦画瓢即可，但是要注意，zk的端口是2181。 当然，如果不想费事的话，就直接给zkserver配一个外网IP，直接连接。 成功连接到zooinspector，就会看到这样的内容，这里的lcconfig是手动添加的，右击鼠标，选择add node，然后直接写上lcconfig就行，这个名字是根据实际需要填写的： 上面我们已经配置了zkserver集群而且还启动zkserver进程，现在还需要zkclient，zkclient就是请求发起的一方，然后我们可以在各个的模块服务器上部署zkclient服务，通过启动zkclient服务，来让这些模块统一从zooinspector里取值，这样就达到了批量配置，同时保证一致性的效果。 zk的模板文件是_tpl.properties为结尾的文件，我这里模块的名字叫mrs，那么在实验里这个模板文件就是mrs_tpl.properties，这个mrs_tpl.properties里有这样的一个字段，如图： 而我们在zooinspector里对应就这么填写： 保存zooinspector，然后从windows返回到linux，启动zkclient服务和对应的模块进程，如果配置都正常的话，那么程序就会正常启动，ps -ef|grep java就会看到一个叫lczk.AppServerDaemon的进程。这个时候在去看一下mrs的配置文件： 可以看到areaAk取得值就是zk里面data_center里面access_key里面的ak的值，其他的几个值也是同理。可见整个zk已经配置成功，模块都进行了统一配置，而且这些配置既然能被一个接受，同时也会被其他相同的模块服务器所接受。这样就达到了批量配置的效果。 拓展阅读http://ibruce.info/2014/10/23/zookeeper/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Uwsgi的安装和简单使用]]></title>
    <url>%2F2018%2F02%2F02%2FUwsgi%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[正文运维平台的搭建已经提上日程，而我选用了大家比较常用的Uwsgi+nginx+django的架构，这里先记录一下安装Uwsgi的过程。 这里解释一下Uwsgi+nginx+django，我们整个流程如下图： 这里我们可以看出，web server是无法与我们的app（django等等）进行直接对话，他需要通过uwsgi这个桥梁，这个桥梁很重要，虽然我们使用django的runserver功能也会打开一个页面，但是这个页面是很脆弱的，小规模使用还好，要是放在网络上供很多人点击的话，根本就是脆不经风。 uwsgi是啥，请查看文末的参考资料，写的已经非常好了。我这里就简单说下： uwsgi 实际上也是一个http服务器，只不过它只面向python网络应用程序。虽然uwsgi也是http服务器，但是却不能直接使用它部署python web应用程序，否则会出错。 在本文中，uwsgi所扮演的的角色是后端http服务器，nginx扮演的角色是前端http服务器，hello.py是客户端应用程序。用户从网页浏览器中发出请求，nginx服务器收到请求后，会通过它的uwsgi模块将用户的请求转发给uwsgi服务器，uwsgi服务器处理完毕后将结果返回给 nginx，浏览器将最终的结果展现给用户。 Uwsgi的安装比较简单，推荐使用yum install Uwsgi直接下载使用，而不推荐用pip install uwsgi，因为pip安装的话，虽然也能成功（如下图红框），是没有uwsgi.ini文件的，其实没有这个uwsgi.ini是无足轻重的，因为这个文件可以自己写，但是对于生手来说，没有这个文件可能会心里发毛，就无法按照攻略继续下去，所以我更推荐用yum安装，如图： 为了纪念我们的金刚狼同志，我们就写一个叫logan.py，里面的内容是这样的： 123def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return "good bye,Logan..." 然后我们就可以启动这个uwsgi看看效果，使用uwsgi --http :8001 --wsgi-file logan.py，把端口设定为8001，同时指定协议是http，然后加载的文件就是logan.py，启动之后，如图： 遇到这种情况，你就yum install uwsgi-plugin-python，然后把命令做一点点修改，改成：uwsgi --plugin python --http-socket :8001 --wsgi-file logan.py。 屏幕会出现一大堆文字，然后提示，uwsgi已经启动成功了。在浏览器输入服务器外网地址:8001看一下效果，如图： 我们在root目录下再写一个测试的文件，这次我们写一个比较老实的python脚本来测试，这个脚本就叫test.py，里面的内容如下： 12345678910#!/usr/bin/python#coding=utf-8import osimport sysdef application(environ, start_response): status = '200' output = 'this is a test for uwsgi,HOHO~' response_headers = [('Content-type', 'text/plain'),('Content-Length', str(len(output)))] start_response(status, response_headers) return output 还是用刚才的方法，依旧可以打开网页，其实上面这个简单的uWSGI程序更好理解整个套路，只需要实现一个名为application的函数就可以了，该函数有两个参数，environ为包含有http请求的环境变量，start_response为一个函数，用来设置http头。在这个函数里，我们只需要调用一次start_response函数，设置一下HTTP返回头，再return一个HTTP body即可。 至此，整个uwsgi就安装成功了。 参考资料http://xiaorui.cc/2017/02/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3uwsgi%E5%92%8Cgunicorn%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8A/http://uwsgi-docs.readthedocs.io/en/latest/tutorials/Django_and_nginx.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
        <tag>uwsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从excel的大单元格里快速提取内容]]></title>
    <url>%2F2018%2F02%2F01%2F%E4%BB%8Eexcel%E7%9A%84%E5%A4%A7%E5%8D%95%E5%85%83%E6%A0%BC%E9%87%8C%E5%BF%AB%E9%80%9F%E6%8F%90%E5%8F%96%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[我公司的服务器信息会保存在一份高加密的excel里，由于历史遗留问题，里面的格式节选一部分出来是这样的： 注意看，ip地址不分内网外网是放在一个大的单元格里，中间是用空格隔开的，造成了这样的视觉效果。 现在公司需要把所有的服务器重新更换到新的zookeeper，那么使用ansible在批量处理的时候，就需要提取这些服务器的内网ip地址录入到/etc/hosts文件里，但是由于服务器实在太多不可能一个一个手动从excel的单元格挑选出“内网IP地址”复制粘贴，那么就需要进行一下批量挑选内网IP地址的操作。 首先我们先把整个IP的单元列里的”（公）””（内）”的字样去掉，然后把整列全部拷贝，粘贴到notepad里，看到它们变成了这样的样子： 在notepad里，双引号之间的内容会被认为同一行，所以这里我们需要使用“替换”功能把所有的双引号去掉，让它变成下面这样： 这样就可以把上面的内容复制到一个新的excel去，发现每一个内容对应了一行，即一个小单元格： 然后我们把第一行染成黄色，第二行染成绿色，当然颜色你可以选择自己的口味，然后使用excel的“格式刷”功能，一拉到底，让他们变成条纹状： 然后在excel里找到“筛选”功能，先选择住这一条纹块，然后选择“按颜色筛选“，由于我们需要内网IP，那么我们就留下绿色内容即可，如图： 得到效果如下： 这样就可以把整个内容拷贝进ansible的hosts文件里，然后搭配ansible批处理这些内网IP，双管齐下，大大的提升了提取数据的效率。 如果遇到偶尔三行（即中间有空格行）的情况，那么就在notepad那一步的时候，把空格行干掉，不如下图的情况里，第五行和第八行是空格行，可能是当初记录人员复制的时候自带了空格： 如果是空格很多的情况，那么就需要批处理一次性的把所有空格都干掉。干掉的方法，还是使用notepad的“替换功能”，选择“正则表达式”，然后把\n[\s|]*\r替换成空值就可以了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再见，魔兽世界]]></title>
    <url>%2F2018%2F02%2F01%2F%E5%86%8D%E8%A7%81%EF%BC%8C%E9%AD%94%E5%85%BD%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer0"), narrow: false, autoplay: false, showlrc: 0, music: { title: "暴风城主题音乐", author: "World of Warcaft", url: "http://p1x3hd2at.bkt.clouddn.com/stormwind.mp3", pic: "http://p1x3hd2at.bkt.clouddn.com/wow.jpg", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 这张月卡马上就要用完了，我想我的《魔兽世界》生涯也要到头了。 地球时代我是从大学的时候就开始接触《魔兽世界》，当时是在同寝的xur同学的推荐下，注册账号买了CDKey，然后跟着他在六区黑翼之巢创建了角色，那是一个留着武士头和山羊胡的暗夜精灵德鲁伊，起了个带有劲舞团性质的ID叫“删除过去”。记得德鲁伊刚出生是人形态，泰达希尔里背着一个木棒棒，靠着“愤怒”这个技能打人。于是乎，我就搓出了一个又一个原谅色的冲击波，波遍了泰达希尔的每一个角落，波倒了一个又一个萨特和野熊。当时我作为一个萌新，什么都不懂，后来在一个另外的德鲁伊的帮助下，开始做任务升级，顺便粗略的了解了魔兽最基本的操作。这个德鲁伊是我在游戏里认识的第一个朋友，是一个萌妹子，ID叫什么我忘了，不过后来她游戏上的很少了，依稀记得后来某一个半夜我在西瘟疫之地变成小豹子一个一个挠亡灵的时候，她上过一次线，等级好像是20~30级的样子，我俩说了一会话，具体说的是什么我已经记不清了，那就是我俩最后一次说话。 从泰达希尔港出来，我就开始了艾泽拉斯的冒险之路：去月光林地学变熊变豹子，拖尸到血色修道院，打过那么一两次诺莫瑞根，在荆棘谷的森林里穿梭，长期蹲在塔纳利斯刷“XD求组祖尔法拉克”。 当时寝室里没有电脑装wow，总去学府三和学府四那两条街的网吧玩，就这样我成了被盗号的重灾户。记得最过分的那次上号发现角色干脆消失了，还有一回上号发现，角色被扒的就剩下一个裤衩、一个披风和一个狼头样子的皮甲头，还别说，这造型跑出去比较拉风。后来九城推出了密保卡，就是充值卡后面的8x8的数字卡，虽然有一小段时间遏制了盗号，不过缺点就是要随身带着密保卡。在网吧开机坐下了发现没带密保卡，又跑回寝室取卡的事情，我当初可没少干。 这个德鲁伊就这样摸爬滚打到了六十级满级的时候，开始刷三大本（前后斯坦索姆，通灵学院，黑石塔上层），那时候的黑下是一个冷门本，黑石深渊更不要说了，打一次就花费了几乎一下午的时光。那段反复的刷斯坦索姆和通灵学院的日子给银色十字军捐过不少亡灵印记。后来加入了工会跟工会开始打熔火之心，记得公会团长叫火枪队长，一个男人类战士，其他的一团的队员我现在还能记住名字的有：京乐春水（德鲁伊）、Hater（女人类牧师），魂之血杀（暗夜大元帅战士）。那时候的MC已经没有DOT限制了，但是还要做水元素任务，带着圣水去灭火。接触的第一个G团是祖尔格拉布，当时德鲁伊是一个稀缺职业，我就开始去打工兼消费挣俩小钱，用那点G去买拍爪子的材料。在祖格G团认识了同大学的一个哥们，叫阿尔萨斯之心，是一个女人类圣骑士，他那个时候就有祖格龙了，但是没玩太久，60级没完事就把号给卖了…MC通了后，公会团开始打黑翼之巢，我记得当时的BWL老1还有BUG，远程和治疗可以跳在窗户上。到了老2就卡的死去活来，好不容易过了老2，接下来的三个就一片通途。然后又花了一个晚上打掉了克洛玛古斯。我那时候奈法利安和克洛玛古斯打得不多，仅有的几次击杀也没有掉落怒风胸和怒风肩，这成了我60级的一个怨念。 在打BWL的时候，安其拉版本已经开始了。G团也开始做安其拉废墟的生意，我也在其中一次无疤者奥斯利安的身上得到了废墟法杖，换掉了之前埃克索图斯的挖掘锤，为了这个废墟法杖我还卖了一张卡，那时候一张卡是300G，那次好像是我唯一的一次卖卡。说到卖卡我想起来，我人生的第一只千金虎是一个暗夜盗贼赞助的，ID好像叫小什么哥，当时的G真的很值钱，非常非常感谢他。 我在地球时代RAID的最高纪录就是安其拉神殿到公主、NAXX打了蜘蛛区前二、DK区到了老1、憎恶区的帕奇维克好像是没过，反正就是一个很一般的进度啦。然后公会团就有了一些动荡，我个人总觉得德鲁伊打人不爽，还是拿起大刀砍人过瘾，于是就开始了玩战士小号的生涯，ID叫燕小鱼。战士满级后不久就开了“远征前夕”，也就是那个全民刷战场换大元帅的时代。我那时候也在YY里加入了联盟军校，开始了没日没夜刷大奥的日子，先换了猪头锤，又换了雷矛羊，最后拿着一堆牌子去换一身漂亮的大元帅，直到现在我的YY名称依旧是以“联盟军校”开头。 我玩战士的时候还认识了一个男矮人牧师，叫赤红丹朱，这个哥们手法很骚，以前是玩部落的，记得有一次我俩要去荒芜之地，在莫高雷的高原上，他说这里曾经是他玩部落开始的地方，然后看着脚下这片大草原心潮澎湃，我俩一起战斗过不少副本，从斯坦索姆到祖尔格拉布，他没有坚持到70级就不玩了，账号也给我了…我后来去他的新浪博客看过，背景音乐是王若琳的《有你的快乐》，后来的某一天，发现他的新浪博客内容就被全删光了。 燃烧的远征记得那是7月份，大二刚开学没多久，我就穿过黑暗之门开始了燃烧的远征。那时候我先升的是战士，在地狱火堡垒里面拿大砍刀砍来砍去。七十级的raid就是先从卡拉赞开始，当时我的小战士就当主t，当时跟的团团长ID是叫小豆宝宝，一个侏儒术士。那时候卡拉赞的bug很多，埃兰可以卡门，马克扎尔王子也可以卡地点。我个人对于卡拉赞比较有印象的是虚空龙，那是这个十人小团队一个比较有成就感的boss。 往后就是打格鲁尔，那个时候我记得隔壁寝室的老朱已经开始练他的女暗夜盗贼了，那个时候我俩开始比较频繁的厮混在一起，肩并肩的不上课跑去网吧打魔兽，我印象最深的一次就是他当时为了刷一个午夜护腿在沙塔斯找了一个猎人，但是这个猎人不是很靠谱，在奴里围栏一个人忙乎从早上八点到晚上八点，结果还没出，给老朱气得牙痒痒。 TBC的时候，就有了日常任务的概念，每天早上要做奥格瑞拉和虚空龙任务，后来又有了奎岛日常，日复一日的刷声望。玛瑟里顿这个副本公会团当时没有正经打，直接就开始打风暴要塞，当时打掉了凤凰和奥术师和机器人。而毒蛇神殿我跟公会打得不多，记得有打过瞎子外加鱼斯拉。这个时候，邪神禁地祖阿曼上线了，开始了有事没事冲箱子的新征程。我印象里整个70级就是一个很多bug的版本，祖阿曼体现的尤为明显，里面BUG有术士副本拉人以及祖尔金跳柱子。但是即使这样我也只冲成功过一次四箱，那一次是t6级别队伍带队，完全没用bug。除了那一次剩下的基本就是两箱，三箱屈指可数。 然后我现实的一个的哥们由于学业的问题不能继续跟团队RAID无奈只能把账号暂给我打理，于是我改玩了他的暗夜女精灵牧师，ID叫外面下雨了（后面简称下雨）。我开始跟《荣耀》公会活动，会长就是鼎鼎有名的震撼。荣耀公会最早是桑德兰服务器的，后来由于想当联通区的第一工会，就集体转服到泰拉尔。当时我也是第一次接触牧师，完全是抱大腿的姿势跟他们一团打掉阿克和伊利丹。他们打阿克因为要录视频所以是不用bug的，真真的要考验跑火的功力。第一次打伊利丹我印象很深，当时寝室里有电脑了，由于很多人当时进度很慢，所以打伊利丹的时候，全楼道的wower都来看，然后啧啧惊叹。 跟着震撼一边打进度团也一边打公会的G团，记得当时t5一套是五万金，t6一套是十五万金。再加上卖武器饰品，一趟下来也分到不少，而且还能直接跟老板换卡，据说公会当时用的付费ts语音也是用老板的钱买的。 那时候打进度团主要就是开荒太阳井，我用那个牧师号拿了全服第一个t6鞋，首down双子的战报也上了nga，地址在：http://nga.178.com/read.php?tid=1644774 ，视频也被传上了优酷，但是现在那个视频找不到了，不过记得BGM还是很好听的。当时进度团活动时间是晚上七点到早上五点，真的很累人，最后击杀基尔加丹我并没有参与。但是震撼的指挥和语音口头禅给我留下了很深的记忆，他的确是一个很赞的指挥。 燃烧的远征也是我寝室山哥沉迷魔兽并且活跃的日子，当时山哥投奔了部落玩德鲁伊。我记得他们团第一次过血沸很惊险，当时血沸还有大约5%的血，T都躺光了，就在BOSS准备大肆屠杀的时候，结果血沸那时候点名，好巧不巧的点名了一个盗贼，那贼开着闪避上去顶掉了最后5%的血。其实FD就是这样，需要实力的同时也需要那么一点运气。 巫妖王之怒当时由于大陆魔兽推迟开巫妖王，那时候我跟老朱、涛哥、永森、老刘、阿俊、小勇几个寝室的哥们还有那个下雨一起转战去了台服，改玩部落。当时我是防骑，老朱改玩牧师，涛哥是法师，老刘是盗贼兼指挥，小勇是术士、阿俊是德鲁伊、永森是萨满，下雨依旧是牧师，不过老朱主要玩的是神牧，下雨主要是暗牧，必要的时候会切奶。 老朱的魔兽之路开始于60级，当时他第一个职业是法师，最开始的时候他跟xur打赌会尽快的把等级练到骑小马的等级，话说老朱练号的速度是很快的，他也是我们几个人里玩职业好象最多的。从法师到萨满，然后还有盗贼，但是直到这次玩上了牧师，他终于找到了灵魂的归属，发现原来牧师才是他的本命。 除了老朱我多说说老刘，老刘原名刘义超，是我们年级的一个牛人，很瘦，戴个眼镜，走路有点发飘。用他话说从小身体就不好，所以不是很喜欢运动，除了打魔兽打dota就是看漫画再不然就是用psp打麻将，老刘的经典语录就是“对于我来说，每一把DOTA都是一把新的DOTA”。老刘是一个很聪明的人，打游戏思路很清晰，很少反重复的错误。他为了游戏也肯砸钱，那时候都是老刘给我们搞代理。老刘巅峰的时候在第七天堂打主力牧师，我也亲眼见过他那时候打便当二十五人英雄十字军，后来由于要带我们几个就放弃了第七天堂，转来跟我们一起组团队。当时我们几个人一边小团队打十人icc，一边也跟个工会活动。 不过后来老刘觉得公会团打得不爽，揭竿而起，自立门户开起了25人H ICC金团。每周四，都会看到一个叫德意忘形的德鲁伊在达拉然喊人刷屏，喊满了就向冰冠堡垒浩浩荡荡的出发，由老刘带队指挥，当然我们也会偷偷摸摸的黑下几件装备和一点金。老刘指挥虽然不如震撼激情，但是思路很有条理，基本上战斗力不算很差的团一个下午就打掉2到3个区。当时我已经大四下半学期了，由于有驾校考试，所以当时老刘的金团我参与了也就一半，不过在金团里我得到了大盾冰冠冰川之墙，当时好像是花了4万金。最可惜的一次就是他们有一次开出了英雄的异物逐除，卖了17万金，按当时的物价换算是二千多块人民币!那次的金团真是赚翻了。 我们十人团的进度是“十人十字军试炼最高差两次就大十字军”、“ICC普通全通”、“h我记得没过冰龙”，因为不久就要毕业了，就没有很全力的去开荒。毕业后从此我们几个战友就四散天涯：老刘回齐齐哈尔，永森和阿俊回佳木斯，涛哥留在哈尔滨，我、小勇和老朱回大庆上班，而下雨就一直在国外，直到现在也没有回来。 现在除了涛哥和老朱，我还有联系之外，其他人我已经联系不上了，也不知道他们过得好不好。 魔兽的八十级之前的版本可以说陪伴了我在大学的大多数时光，那也是我魔兽生涯唯一玩部落的时光。 大地的裂变到了八十五级我又回归国服了，重返联盟命。由于大学里各位同学都开始了新的生活，我也开始直到现在的魔兽独行侠之路，独自练级独自打战场。 也从此之后，我就再也没有正经的跟过公会团，要么是打随机本看看剧情，要么就是打金团。其实我对八十五级的印象不多了。不过要说一下，八十五刚开始的5h真的很难，经常小怪的治疗一个打断不到就满血了，记得那时候打一个影牙城堡就累的死去活来。硬要说大裂变里印象比较深的，也就是打托尔巴拉德和打巨龙之魂，比如很多战士一起开剑刃风暴一起命令怒吼，场面非常壮观。那个时候我也把战士的种族转成了狼人，也背上了触手剑爬在地上跑来跑去。最后没事干，就趁此机会又练起来一个牧师和一个女人类圣骑士，开始了我的圣光追寻之旅。 熊猫人之谜到了九十级，朋友也多了起来。主要是跟单位里的磊哥、建哥、亮哥和迪哥一起在奥拉基尔服务器玩。磊哥原先是亡灵贼，后来投奔了联盟转了女人类，但是一直都纠结女人类的动作不如男亡灵飘逸。磊哥自封外号“阿拉希小王子”，长期在农场神出鬼没，也善于在战歌抗旗。迪哥是男德莱尼萨满，满地插柱子，他是一个个性男人，死活不去网吧，坚持就在家里玩。不过迪哥玩魔兽的时间并不长，也就几个月的时间他就投奔去三国杀和单机游戏了。健哥是一个猎人，单刷无敌，他那时候是我们几个里最有G的，输出也最为残暴，不过后来他由于工作原因也忍痛割爱了。亮哥是血DK，号称“通信公司第一DK”，不过我们四个很少玩在一起，毕竟上线时间其实是错开的。 熊猫人的本我印象比较深的就是“攻打奥格瑞玛”，至于之前的恐惧之心、永春台神马的我压根就没参与过。当时我的小牧师也算练的不错了，主要得益于我下班没事经常混迹在NGA看帖子，再加上那个版本对戒律牧也特别的友好，偶尔在金团也能拿到治疗第一的补助。而磊哥一直想要箱子BOSS的马刀，最后他也算圆梦了。至于建哥一直眼馋的火鹰，好像一直都是没有达成。 这里我要感谢磊哥，当时我俩在祖尔格拉布翻新之前去刷过祖格虎，结果出虎的时候，磊哥高风亮节让给我了，满足了我开上“红色法拉利”的梦想。 德拉诺之王一百级给我的游戏感觉就是高开低走，尤其是要塞，从最开始新鲜成了后期的累赘。虽然它给了我很多战火装备，但是也让我越来越少出去。整个德拉诺之王我最喜欢的副本就是黑石铸造厂，很有六十级副本的味道，容错率很低。那个时候也认识了以骄傲纹身为首的几个朋友，也打了金团攒了不少钱，这些钱后来也都被我换成了点卡。 至于地狱火堡垒这个副本我印象不多，翻来覆去就打了两三遍h，还都是跟G团，最后过了h的阿克蒙德，m难度我压根没尝试，后来由于公司里各个朋友们由于现实各种情况AFK，我也开始改玩单机游戏，上号就是刷刷阿什兰和四本刷金，消磨时间休闲娱乐。 军团再临到了一百一十级，几乎整个一百级都没玩的老朱重返魔兽，一口气练了牧师、死骑和恶魔猎手三个职业，我俩也配合打了几个高层大秘境，没有老朱的日子就是我自己慢慢肝神器，每周争取打一次低保，再混一次世界BOSS。也就是这张点卡玩完，我觉得魔兽已经对于我来说没有什么留恋的了，该体验的我差不多都体验过了，没体验到了我也不在乎了。我把牧师停在暴风大教堂，把战士停在暴风要塞，把圣骑士停在激流堡，下线。 至此，我整个魔兽的生涯就算总结完了。 PVP有关地球时代的野德不算很强，除了战歌抗旗好像就是补刀了。那时候我看过一个叫dazeroth的暗夜德鲁伊Unstoppable系列视频，觉得很吊，他的视频不算很多，但是打得很棒，然后再看德鲁伊就是一个中国风很浓的暗夜德鲁伊视频，但是我忘了他的名字了。改玩了战士之后，就看Swifty的视频和苹果牛的视频，看直播就看太极龙。牧师的话，看Hydra是最多的。 我个人认为PVP是魔兽的一个重要的玩法，不过这种玩法随着玩家属性暴涨而变得不再公平（不过有几个乱斗还是挺好玩的）。我竞技场打得不算多，从70年代组织55战队去每周去混10场到现在，加起来不超过200场的JJC实战经验。不过战场混得经验丰富，打一些战场也有自己的心得，比如征服之岛要上来抢车间，大奥如果速推不成功就要抢冰雪墓地耐心打平推，打战歌中场压制住了等于赢了8成，风暴之眼先抢墓地再抢骑，控制了地盘后第一时间去墓地堵人等等等等。但是战场毕竟各位玩家PK水平参差不齐，打战场其实更多就是一个图个乐。 至于搏击俱乐部，我没玩太多，不过金牌挑战我还是很喜欢的。 结束语魔兽世界陪伴了我12年的时光，现在回首来看，我个人最喜欢的是WLK，因为那个版本装备比较好看，其次相对来说各个职业的能力都比较平均，最重要的就是身边有一堆战友并肩作战；其次就是TBC，他在一定程度上弥补了很多60级的缺陷，而且极大地提升了惩戒骑、野德、元素萨等混合职业的存在感，不过TBC的BUG实在太多（我重复几次了？），光一个阿克我就见识过不下4种BUG打法，这一点是TBC的败笔；再其次就是90级和地球时代；大灾变和军团再临他们俩并列再后面一点。 我爱魔兽，他是我的另一个世界，因为我觉得在现实世界里能做的事情，在魔兽世界能做的更多。不可否认，我曾经在魔兽世界上投入了大量的时间，这耽误了我很多现实中的事儿，不过我还是认可它给我带来了不少的快乐。我还记得在06年的路边书摊会买魔兽世界带副本地图和掉落的攻略的那个宅男；我也记得当初那个小德鲁伊在灰谷，一边看着新浪魔兽任务详解，一边在地图上费劲的查找线索；我也记得当初圣骑士到了查索拉盆地的时候，被那种仙剑风的音乐陶醉；我也记得在阿什兰和奥特兰克山谷，战士那一身部落血的豪爽。但是一切缘分都有到头的时候（或许我将来会有机会到网易的魔兽世界部门上班，不过这个暂且不提），虽然我不能亲眼看见联盟一统艾泽拉斯，但是我还是要说，谢谢暴雪做的这款精良的游戏，感谢你陪我走过的这12年，谢谢跟我并肩作战过的战友，没有你们，我也无法享受这段丰富而美好的时光。 最后，我要用《军团再临》里面伊利丹的那个口信内容作为我整个魔兽世界生涯的结尾： 我留下的水晶里其实有三条口信 最后一条是给你的，勇士 你证明了你对艾泽拉斯的忠诚 你的奉献和牺牲都足以与我媲美 但你还得付出许多，更多! 此刻敌人正在集结，阴云正在汇聚 从今天起，守护我们的世界和亲人的重任 就交给你了 再见了，那些一路陪伴我的NPC们，我要离开你们了，去开始新的征程。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>魔兽世界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈raid0,raid1,raid10,raid01等等硬盘阵列搭配]]></title>
    <url>%2F2018%2F01%2F31%2F%E7%AE%80%E6%9E%90raid0-raid1-raid10-raid01%E7%AD%89%E7%AD%89%E7%A1%AC%E7%9B%98%E6%90%AD%E9%85%8D%2F</url>
    <content type="text"><![CDATA[RAID 0RAID 0可用于两个或更多硬盘或SSD。目标是提高读的性能。 数据以特定大小（通常为64KB）的块写入，并在可用驱动器中平均分配。下图显示了带有三个硬盘的RAID 0阵列的示意图。RAID控制器将第一个数据块写入硬盘1，第二个数据块写入硬盘2，第三个数据块写入硬盘3，第四个数据块再次写入硬盘1,以此类推，RAID 0中的三个1TB硬盘提供3TB的存储空间。 由于数据分布均匀，所以在访问的时候会从硬盘1~硬盘3提取数据，然后拼接在一起就是一个完整的数据。理论上从3个硬盘的RAID 0阵列读取数据比从一个硬盘读取要快3倍，换言之，使用RAID 0读数据的能力跟磁盘数量成正比。 RAID 0也有缺点：如果其中一个磁盘出现故障，从其他磁盘上的数据拼起来就不再是一个完整的数据了。另外，磁盘越多，则发生磁盘故障的可能性也越高。所以如果磁盘阵列里包含着对您来说很重要的数据，则最好创建频繁的备份。 RAID 1RAID 1用于创建数据的自动副本。RAID 1会将同一份数据写入两个单独的磁盘，如果A盘出现故障，仍然可以在B磁盘上读取所有数据，当然这是比较壕的，毕竟做一件事用了两块盘。这里要注意！镜像和备份可不是一样！！！如果你不小心从一个磁盘A上删除了一个文件，或者某个文件被病毒侵蚀了，那它再另一个磁盘B上也是一样的待遇。只有真正的备份才能使所有文件保持其保存状态。因此，如果想不让宝贵数据陷入灾难，创建频繁的备份是必须的。 RAID 1中的读性能通常与单独的硬盘差不多—-从A和B里一起读数据，谁出数据快就采用谁的，写的话就是要同时写到两个盘里去。因此，使用RAID 1来获得额外更多的读写性能是不太可能的。以下是RAID 1的工作原理图，如果HDD1坏了，那么HDD2直接上任，若HDD1里的东西被删除了，那么HDD2也会被删除，即使它上任了也是坏的。 RAID 10和RAID 01所谓RAID 10,其实就是磁盘阵列先RAID 1,后RAID 0,同理，RAID 01也是先RAID 0,后RAID 1。无论是1+0还是0+1，都至少需要4个硬盘。 这里先看一下RAID 10和RAID 01的效果图： 就像图里说的“在六个硬盘列里，RAID 10比RAID 01更安全”。的确，RAID 10也凭借很棒的容错能力和恢复能力当选了大多数的RAID配置，为什么不要RAID 01呢？那就是如果在RAID 0那一步磁盘就坏了，那RAID 1那步就没有意义了，因为生成的镜像全是坏镜像。 RAID 3RAID 3是这样的：若有n块盘，其中拿出1块盘作为校验盘，剩余n-1块盘相当于作RAID 0同时读写，当n-1那里的其中一块盘坏掉时，可以通过校验码还原出坏掉盘的原始数据。这个校验方式比较特别，事奇偶检验，1 XOR 0 XOR 1=0，0 XOR 1 XOR 0=1，最后的数据是校验数据，当中间缺了一个数据时，可以通过其他盘的数据和校验数据推算出来。但是这存在了问题，由于n-1块盘做了RAID 0，每一次读写都要牵动所有盘来服务，而且万一校验盘坏掉就完蛋了。 RAID 5 and 6上面说了RAID 10是一个很棒的方案，但是它的实现至少需要4个硬盘，这一点太伤钱了，于是就出现了RAID 5。与RAID 0一样，数据被分成块并执行写入处理，同时把RAID 3的“校验盘”也分成块分散到所有的盘里。同时，产生并写入称为“奇偶校验”的冗余代码。因此，即使其中的一个硬盘出现故障，也可以根据剩余的数据和奇偶校验来计算出丢失的数据，然后生成完整的状态数据。由于无论需要配置多少个硬盘，保存校验只使用一台设备的容量，容量效率随着待配置硬盘数量的增加而提高。RAID 5模式下硬盘读取数据的速度很快，因为它是从多个驱动器同时处理的。预计速度将与要配置的驱动器的数量成比例地增加。但是，数据的写入/更新涉及奇偶校验的创建/更新，所以写入性能不高。 RAID 5已经提供了一定程度的可靠性,然而也牺牲了一定的读取速度。RAID 5的局限性还表现在RAID 5仅能在一块硬盘发生故障的情况下修复数据,如果2块硬盘同时发生故障,RAID 5则无能为力。于是RAID 6应需诞生了，RAID 6同RAID 5最大的区别就是在RAID 5的基础上除了具有P校验位以外,还加入了第2个校验位Q位。当一块磁盘出现数据错误或者丢失的时候,恢复方法同RAID 5,无须使用Q校验位。当两块磁盘上的数据出现错误或者丢失的时候,恢复方法为:利用上边给出的P,Q的生成公式,联立方程组,无论受损的数据是否包括P或者Q,总是能够解出损失的两位的数据。 RAID 50 and 60在硬盘数量较少的情况下，RAID 5是极好的选择，如7-8块硬盘组成的RAID。但是，当硬盘的数量更多的时候，如10块、20块甚至100块，那么RAID 5就无法胜任了。RAID 50是在RAID 5的基础上，将多个RAID 5组以RAID 0的形式组成在一起。可以这么认为，一个RAID 5组在这里就是一个“大硬盘”，再把这些“大硬盘”以RAID 0的形式组成在一起。而RAID 60的组成就是在RAID 6组的上面组成一个RAID 0。理论上说在写入性能方面，RAID 50相比RAID 5要好太多，而RAID 50相比性能冠军RAID 10要差一点，考虑到RAID 5在一些负载面前的平庸性能，RAID 50是个不错的中间选择。和RAID 5和RAID 10一样，RAID 50也提供极好的读性能，同时RAID 50即使使用最低配置，也需要六个硬盘，所以安装成本很高。 如果担心一个RAID组里面同时有2块硬盘发生故障，导致数据丢失，那么可以选择使用RAID 60。RAID 60提供更高的安全性，相应的其可用容量会比RAID 50少点，RAID 60即使使用最少的配置，也需要8个硬盘，所以安装成本相当高。 结语以上几个磁盘阵列，从读的能力来说：RAID 5 ≈ RAID 6 ≈ RAID 60 &gt; RAID 0 ≈ RAID 10 &gt; RAID 3 ≈ RAID 1从写的能力来说:RAID 10 &gt; RAID 50 &gt; RAID 1 &gt; RAID 3 &gt; RAID 5 ≈ RAID 6 ≈ RAID 60如果将来有一天你对这篇文章记得不是很清晰了，那么但愿你可以记住下面这张图，这几幅图虽然对于RAID 上不是完全的准确，但是已经很大的表达清楚了各种RAID的特点了。 参考资料https://us.hardware.info/reviews/4123/raid-0-raid-1-raid-10-and-raid-5-how-do-they-actually-workhttp://support.huawei.com/enterprise/zh/knowledge/KB1000149118/https://zh.wikipedia.org/wiki/RAIDhttp://www.hpc.co.jp/raid_kaisetsu.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>raid</tag>
        <tag>磁盘阵列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-playbook如何获取ip]]></title>
    <url>%2F2018%2F01%2F31%2FAnsible-playbook%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96ip%2F</url>
    <content type="text"><![CDATA[公司的模块都新加了加密算法，现在就是需要把约100台机器的/etc/hosts文件里的zookeeper server的ip调整成新的ip 地址，目前在ansible控制机上已经写好了带有新的zookeeper server的ip的/etc/hosts文件，然后计划是把这个新文件下发到大约100台具体模块的服务器里，然后这100台机器的文件中把他们各自的ip和hostname添加到这个新的/etc/hosts文件上。 于是就写了一个ansible-playbook: 123456789101112---- hosts: all tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0544 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line="`ansible_all_ipv4_addresses` `ansible_hostname`" 但是写完之后执行出来，却是这样的效果： 而我想要的是这样的效果： 遇到这种情况怎么办？ 后来调整了一下，变量用IP: ““，而不是ansible_all_ipv4_addresses。 修改了之后的playbook 如下： 1234567891011121314---- hosts: all vars: IP: "&#123;&#123; ansible_eth0['ipv4']['address'] &#125;&#125;" tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0644 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line="`IP` `ansible_hostname`" 这样就达到目的了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql查看实时语句和慢sql]]></title>
    <url>%2F2018%2F01%2F30%2Fmysql%E6%9F%A5%E7%9C%8B%E5%AE%9E%E6%97%B6%E8%AF%AD%E5%8F%A5%E5%92%8C%E6%85%A2sql%2F</url>
    <content type="text"><![CDATA[查看实时语句Mysql除了手动执行的语句，还有很多在后台由其他模块执行的语句，按理来说，那些由其他模块执行的语句是不能实时查看的，因为这个资源消耗特别的大，但是当我们实在需要查看实时sql语句的时候也不是做不到，需要手动开启一个日志开关general_log。 首先登陆mysql，然后执行show variables like &quot;general_log%&quot;;，看一下反馈的结果，如下： 12345678mysql&gt; show variables like "general_log%";+------------------+-------+| Variable_name | Value |+------------------+-------+| general_log | OFF || general_log_file | |+------------------+-------+2 rows in set (0.04 sec) 发现这个Value是off，那么就说明实时记录general_log没有开启，如果我们要开启它很简单，如下： 123mysql&gt; set global log_output = file;mysql&gt; set global general_log = 'ON';mysql&gt; set global general_log_file = '/tmp/mysql/general_log.log'; 可见我们不仅打开了general_log的开关，而且设置日志输出方式为文件（如果设置log_output=table的话，则日志结果会记录到名为gengera_log的表中，这表的默认引擎都是CSV）。同时规定它的保存位置是/tmp/mysql/general_log.log。 但是这个是临时方法，如果mysql重启了那么就会失效，如果想要永久有效的话，就要编辑my.cnf，添加下面两句话： 12general_log = 1general_log_file = /tmp/mysql/general_sql.log 这里要注意！开启general_log会影响性能，谨慎使用!正式系统用完要关闭!!!关闭的语句SET GLOBAL general_log = &#39;OFF&#39;;。 查看慢sql慢sql的意思就是那些执行很慢的sql，这些sql拖慢进程的执行效率而且有很大的优化空间。默认的来说，执行时间超过1秒就算慢sql了，在mysql里输入show variables like &#39;long%&#39;，就会看到如下的内容： 1234567mysql&gt; show variables like 'long%';+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 1.000000 |+-----------------+----------+1 row in set (0.00 sec) 这个long_query_time是可以更改的，这里是1，那就是代表查询时间大于(不是大于等于)1秒的都是记录到日志，最大值是10。如果写的是0，那么就是输出所有的语句。 这里多说一句，使用命令set global long_query_time=4修改慢查询阈值为4秒后，需要重新连接或新开一个会话才能看到修改值。你用show variables like &#39;long_query_time&#39;查看是当前会话的变量值，你也可以不用重新连接会话，而是用show global variables like &#39;long_query_time&#39;;。 那么记录这些慢日志的地方在哪呢？使用show variables like &#39;%slow_query_log%&#39;;看看： 12345678mysql&gt; show variables like '%slow_query_log%';+---------------------+-----------------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------------+| slow_query_log | OFF || slow_query_log_file | /tmp/mysql/DB-Server-slow.log |+---------------------+-----------------------------------------------+2 rows in set (0.00 sec) 这里说明慢日志的地址是/tmp/mysql/DB-Server-slow.log，但是慢日志记录的功能没有启动。如果要启动，语句是：set global slow_query_log=1;，跟上面开启实时日志general_log一样，这个方法仅仅是一个临时方法，重启了mysql就会失效，如果要长期生效，还是在my.cnf文件里添加如下两句话： 12slow_query_log =1slow_query_log_file=/tmp/mysql/DB-Server-slow.log 慢日志还有一个系统变量叫log-queries-not-using-indexes，它的意思是未使用索引的查询也被记录到慢查询日志中，哪怕他可能执行的非常快（可选项）。如果调优的话，建议开启这个选项。另外，开启了这个参数，其实使用full index scan的sql也会被记录到慢查询日志。如下： 12345678910mysql&gt; show variables like 'log_queries_not_using_indexes';+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| log_queries_not_using_indexes | OFF |+-------------------------------+-------+1 row in set (0.00 sec)mysql&gt; set global log_queries_not_using_indexes=1;Query OK, 0 rows affected (0.00 sec) 如果你想自己试试慢sql是否被记录，那么可以使用select sleep(5);这样的语句，执行效果如下： 123456789101112131415mysql&gt; select sleep(5) ;+----------+| sleep(5) |+----------+| 0 |+----------+1 row in set (5.00 sec)mysql&gt; select * from mysql.slow_log;+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+| start_time | user_host | query_time | lock_time | rows_sent | rows_examined | db | last_insert_id | insert_id | server_id | sql_text | thread_id |+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+| 2018-01-30 21:45:23 | root[root] @ localhost [] | 00:00:05 | 00:00:00 | 1 | 0 | | 0 | 0 | 1 | select sleep(5) | 2 |+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+1 rows in set (0.00 sec) 参考资料http://www.cnblogs.com/kerrycode/p/5593204.htmlhttps://www.cnblogs.com/qmfsun/p/4844472.htmlhttp://www.cnblogs.com/jasondan/p/3491258.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Goaccess---良心nginx日志分析工具]]></title>
    <url>%2F2018%2F01%2F30%2FGoaccess-%E8%89%AF%E5%BF%83nginx%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[Goaccess是一个非常良心的开源软件，它的良心之处体现在如下方面： 安装简单； 操作容易； 界面酷炫； 安装安装Goaccess十分的简单，在centos里直接yum install goaccess，如果yum源里没有goaccess，可以先安装epel。安装epel的方法如下： 123wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmwget http://rpms.famillecollet.com/enterprise/remi-release-6.rpmrpm -Uvh remi-release-6*.rpm epel-release-6*.rpm 配置和使用安装完goaccess之后，我们需要在/etc/goaccess.conf里添加如下几句话： 123time-format %Tdate-format %d/%b/%Ylog-format %h %^[%d:%t %^] “%r” %s %b “%R” “%u” 保存退出之后，我们就可以通过goaccess来分析nginx日志了，语句格式也很简单：goaccess -f nginx日志的绝对路径。比如我的nginx日志是access-chen.log，查看一下里面的内容： 虽然有规律，但是看上去很乱，需要在分析日志之前喝两瓶静心口服液。 然后我就goaccess -f access-chen.log，就会看到如下的界面： 这一下，整个日志看起来更加友好，更加直白，更加高大上。足以吸引周围人的羡慕目光。 但是这里面还是有一个注意点：goaccess默认支持的日志格式是nginx默认的日志格式，也就是nginx.conf里的如下格式： 如果你的日志格式是有过更改的，而且还不想改回来，那么就需要去/etc/goaccess.conf里对应的log-format进行更改。 这还没有完，goaccess还可以生成html，这里goaccess -f access-chen.log -a &gt; /nginx安装路径/html/chen.html。然后在浏览器里登陆到这个服务器的chen.html，就会看到整个日志情况的网页排版，如图： 这样的话，我们可以每一天都发一份当天的日志html去运维人员的信箱里，这样更加方便我们分析日志。 缺点虽然前面说了那么多goaccess的优点，但是缺点也是有的，比如goaccess的粒度太粗，只能按天分割，如果要按小时分割，需要先grep出来，这个做法比较挫我懂… 还有一个缺点，就是访问人的来源只能定位到国家，无法具体定位到省市县村屯… 参考资料http://blog.maxhemby.se/determine-the-apache-traffic-load/#respond]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>日志统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[处理掉积压过多的activemq持久化消息]]></title>
    <url>%2F2018%2F01%2F29%2F%E5%A4%84%E7%90%86%E6%8E%89%E7%A7%AF%E5%8E%8B%E8%BF%87%E5%A4%9A%E7%9A%84activemq%E6%8C%81%E4%B9%85%E5%8C%96%E6%B6%88%E6%81%AF%2F</url>
    <content type="text"><![CDATA[问题描述在项目使用activemq 5.14时，客户端发送消息而没有得到回复（在不考虑消费者是什么问题的情况下），导致持久化消息不断积压而得不到释放，最后造成队列堵塞而嗝屁。 一般来说遇到这样的情况，可以在配置文件中配置消息的过期时间和死信处理来防止消息的积压，配置如下： 1234&lt;plugins&gt; &lt;!-- 86,400,000ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling="10000" zeroExpirationOverride="10000"/&gt; &lt;/plugins&gt; 配置消息过期时间使用timeStampingBrokerPlugin插件,ttlCeiling：表示过期时间上限（模块程序写的过期时间不能超过此时间，超过则以此时间为准），zeroExpirationOverride：表示过期时间（给未分配过期时间的消息分配过期时间），一般来说这两个值是一样的。执行之后，message过期则客户端不能接收，那些已经过期的message将会保存在data/kahadb目录下。 但是最近发现了一个问题，就是data/kahadb这个目录最近越来越大，越积越多。但是这个topic和quere又依旧是“持续订阅”的，它的消费者还在。遇到这样的情况，如何在activemq里配置呢？ 解决办法 配置message过期自动丢弃策略 12345678910111213 &lt;borker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry topic="&gt;" expireMessagesPeriod="60000"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processExpired="false" /&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt;&lt;/borker&gt; 标签processExpired=&quot;false&quot;表示不保存过期消息到死信队列，处理手段为删除，为true则是保留。标签expireMessagesPeriod=&quot;60000&quot;属性表示每隔60秒钟检查message是否过期。topic=&quot;&gt;&quot;表示该策略对所有topic都生效。而topic=&quot;active.&gt;&quot;就表示该策略对以active.开头的所有topic生效，注意有个点号.。 message过期时间设置上面那步搞定了之后，再修改timeStampingBrokerPlugin标签里ttlCeiling=&quot;360000&quot; zeroExpirationOverride=&quot;360000&quot;表示过期时间为360000ms（1小时）。 123456&lt;borker&gt; &lt;plugins&gt; &lt;!-- 86,400,000ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling="360000" zeroExpirationOverride="360000" /&gt; &lt;/plugins&gt;&lt;/borker&gt; 解决“空队列”的方法如果不是那种“持续订阅”的topic，那就简单了，配置如下： 123456789&lt;broker xmlns="http://activemq.apache.org/schema/core" schedulePeriodForDestinationPurge="10000"&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry queue="&gt;" gcInactiveDestinations="true" inactiveTimoutBeforeGC="30000"/&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; schedulePeriodForDestinationPurge执行清理任务的周期，gcInactiveDestinations=&quot;true&quot;表示启用清理功能，inactiveTimoutBeforeGC=&quot;30000&quot;这个是Topic或Queue超时时间,在规定的时间内，无有效订阅，没有入队记录，超时后就会被清理。 参考资料http://activemq.apache.org/timestampplugin.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python里调用redis的方法]]></title>
    <url>%2F2018%2F01%2F29%2FPython%E9%87%8C%E8%B0%83%E7%94%A8redis%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[正文Python 2.7里不是自带redis模块的，那么在调用redis的时候自然也会报错，比如： 遇到这种情况怎么办？ 第一种方法： 1pip install redis 第二种方法： 1easy_install redis 第三种方法：去登录https://github.com/andymccurdy/redis-py，下载包上传到linux里之后，python setup.py install。 flask模块的安装也是同理。 注意！这里只有Redis，如果使用StrictRedis会报错：AttributeError: &#39;Redis&#39; object has no attribute &#39;StrictRedis&#39;。这个是版本的问题。见https://github.com/andymccurdy/redis-py/issues/188 参考资料http://debugo.com/python-redis/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ssh连接port 22: Connection refused]]></title>
    <url>%2F2018%2F01%2F29%2FSsh%E8%BF%9E%E6%8E%A5port-22-Connection-refused%2F</url>
    <content type="text"><![CDATA[金山云有一个服务器需要连接到数据库但是总是失败，检查之后发现它的VPC配错了，更改VPC之后，这台服务器也会更换一个新的内网IP地址，但是问题来了，更换了内网IP之后，从跳板机连接，提示port 22: Connection refused。 ssh -v 新的ip地址发现根本没有到Connection established。直接就提示port 22: Connection refused。这基本可以断定不是跳板机的问题了，那么就需要在远程机器里看配置。 但是远程机器是无法连接的啊，怎么办？从金山控制台“连接实例”。 然后键盘随便按一下，就会看到linux界面，输入账号名和密码，这里密码不支持复制粘贴，需要手动输入。然后就会看到如下界面。 这样，我们就可以登陆这台机器了，然后vim /etc/ssh/sshd_config，看到最上面有这样的内容。 这个listenaddress后面就是跳板机ssh的地址，但是这个地址还是老的，而不是更改过后的内网ip地址，所以ssh的连接自然就是refuse。所以我们只需要手动更改成新的内网ip地址就好了。 更改完之后，重启一下服务器或者/etc/init.d/sshd restart就可以从跳板机上正常连接了。 如果在/etc/init.d/sshd restart的时候爆出“address family must be specified before ListenAddress”的错误，那么就把AddressFamily移到ListenAddress上面就可以了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SFTP不能连接服务器怎么办？]]></title>
    <url>%2F2018%2F01%2F27%2FSFTP%E4%B8%8D%E8%83%BD%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[今天在跳板机上传送文件，发现使用SFTP连接的时候，出现了这样的一个拒绝情况： 登陆到这个跳板机里，使用tail /var/log/secure，看到了拒绝的具体信息，如下： 这个时候，我就需要locate sftp-server，用locate定位一下sftp文件，但是发现服务器竟然回答我-bash: locate: command not found。 于是就yum -y install mlocate，安装mlocate之后执行updatedb，需要等待一小会，然后再次执行locate sftp-server，就可以得到sftp-server的文件路径了，如下图： 打开sshd的配置文件，vi /etc/ssh/sshd_config，把Subsystem这一行前面的#去掉： 然后重启启动ssh服务，语句是/etc/init.d/sshd reload，重新连接一下，发现就恢复正常了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible部署模块的时候出现中文乱码的问题]]></title>
    <url>%2F2018%2F01%2F27%2FAnsible%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9D%97%E7%9A%84%E6%97%B6%E5%80%99%E5%87%BA%E7%8E%B0%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天在部署服务的时候遇到了一个很罕见的现象，线上有15台服务器是手机推送消息的服务，新来的小运维使用ansible批量跑部署脚本的时候，发现手机端接收到来的消息全是乱码，然后登陆到服务器，查看日志发现，日志里面就是乱码，如图： 由于这个问题用户是有感知的，所以属于“事故”级别了，于是小boss大怒，叫运维赶快回滚，然后让开发赶紧重新检查代码，然后开骂测试都是吃屎的么这么大的一个问题都看不出来真是一群猪伤不起啊。 开发看了半天自己的代码，发现没有任何问题，战战兢兢跑来跟新来的小运维窃窃私语，结果我发现这个模块用手动单独部署，日志却是正常的，中文显示十分OK。 这一下开发就腰杆硬了，说这不是我的锅啊我是无辜的啊老子天天辛苦加班没有功劳也有苦劳没有苦劳也有疲劳老子的代码经得住考验这一切就是部署的问题。 于是我就查看了一下ansible的配置文件，vim /etc/ansible/ansible.cfg，发现了问题所在： 这里最后三行需要改成下面的样子，这样就解决了乱码问题。 1234#module_lang = C#module_set_locale = Falsemodule_lang = zh_CN.UTF-8module_set_locale = True]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>自动化部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6.x安装php 5.6和redis扩展的全过程]]></title>
    <url>%2F2018%2F01%2F26%2FCentOS-6-x%E5%AE%89%E8%A3%85php-5-6%E5%92%8Credis%E6%89%A9%E5%B1%95%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装PHP 5.6123456789101112yum clean allyum update 整体升级一下yum包yum install -y epel-releaseyum list installed | grep php 检查时候安装过PHPrpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpm yum -y install php56w.x86_64yum -y --enablerepo=webtatic install php56w-develyum -y install php56w-xml.x86_64 php56w-gd.x86_64 php56w-ldap.x86_64 php56w-mbstring.x86_64 php56w-mcrypt.x86_64 php56w-mysql.x86_64 php56w-pdo.x86_64 php56w-opcache.x86_64yum -y install php56w-fpmchkconfig php-fpm on 开机自启动/etc/init.d/php-fpm start 启动进程php -v 查看是否安装成功 注1：如果想更换到php5.5或5.4版本, 直接把上面的56w换成55w或者54w就可以了；注2：php-opcache和php-xcache会有效的提高php执行速度； 装php的扩展其实不是很麻烦，主要的步骤如下：1）在扩展模块的客户端文件夹里面使用phpize，这样会生成一个configure文件；2）执行configure文件，后面要加上php的路径；3）将“模块.so”文件名添加到php.ini文件里，重启php-fpm进程；4）通过so文件去调用扩展模块的客户端，实现连接对应的模块； 安装redis扩展123456redis-cli -v 检查是否安装了redisredis-server -vwget http://pecl.php.net/get/redis-2.2.8.tgz tar -zxvf redis-2.2.8.tgzcd redis-2.2.8 phpize 一个专门挂接php扩展的工具，该命令一定要使用在php的模块文件夹主目录下，这里报错Cannot find config.m4。因为phpize要根据模块生成模块的配置文件放在模块文件夹下面 12345./configure --with-php-config=/usr/bin/php-configmake &amp;&amp; make installmake testvim /etc/php.ini 在php.ini里添加一句“extension="redis.so"”service php-fpm restart]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>php</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个连接两个文件的python脚本]]></title>
    <url>%2F2018%2F01%2F26%2F%E4%B8%80%E4%B8%AA%E8%BF%9E%E6%8E%A5%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[背景交代公司在阿里云上有一个模块叫mrs，一共120台，它是跟云录像有关的，这个服务一直都是云服务器里没有公网但是购买了公网SLB，然后20个为一组配置到一个SLB里，这个SLB是按流量收费的。但是最近到了年末，各种账目审核，领导发现这个SLB的费用太惊人了，这么搞不够挣的。但是实在没办法，因为云录像嘛，肯定流量很大，如图： 纵然流量大，但是开源节流也是必须的，于是领导就责令开发赶快想出一个办法，减少SLB的费用。于是开发们拉上运维就吭哧吭哧的开始算经济账，最后确定每一个云服务器买7M带宽，然后流量全部走公网，把SLB的架构舍弃掉。 但是开发在这个模块V2.0里有一个变化，就是Zookeeper需要读取到每一台设备的外网IP，同时这个外网IP必须跟机器是一一对应的，这样模块才能正常工作。 原来的zookeeper在servermap是长这样的： 1234["内网IP"] = &#123;app = "mrs", weight = 100&#125;,["内网IP"] = &#123;app = "mrs", weight = 100&#125;,["内网IP"] = &#123;app = "mrs", weight = 100&#125;,剩下略 而现在开发要求改成这样： 1234["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,剩下略 那么这就要把两个文件合并起来了，而且是在合并后做到一对一，不能把IP搭配串了。 准备工作首先，阿里云的网页控制台是无法做到“包年包月的服务器批量永久升级基础带宽”的，只能通过API实现。那么开启了外网IP之后，服务器就会有一个对应的外网IP地址，然后在控制台里，点击“导出资源列表”，只选择服务器名称、内网IP和外网IP。 然后在生成的excel表格里，剪除掉不需要的服务器以及服务器名称，然后保证“内网IP”在前，“外网IP”在后的样式，而且不要服务器名只保留IP,然后把这个文件复制到linux里，起个名，比如叫IP.txt,如图： 12345[root@paas-online-crs-001 tmp]# cat IP.txt10.161.236.231 3.3.3.310.161.235.150 2.2.2.210.51.10.182 4.4.4.410.117.219.72 1.1.1.1 再把已经使用的zookeeper复制一下，放到一个叫mingdan.txt的文件里，如图： 12345[root@paas-online-crs-001 tmp]# cat mingdan.txt["10.117.219.72"] = &#123;app = "mrs", weight = 100&#125;,["10.161.235.150"] = &#123;app = "mrs", weight = 100&#125;,["10.161.236.231"] = &#123;app = "mrs", weight = 100&#125;,["10.51.10.182"] = &#123;app = "mrs", weight = 100&#125;, 脚本思路我最开始打算用awk的NR、FNR去写，但是发现由于我这个文本的结构太过复杂。awk对付这样的力不从心，稍不好就把人搞得无法自拔，于是就考虑使用python的字典。 各位都知道，字典里key是不能重复的，而我又不想把这个脚本搞得太复杂，就想在mingdan.txt里的每一行加上序号，用这个序号去当key，而后面的内网IP就作为value，这样保证一一对应。加序号的方法很多，你可以在vim状态下:set number，然后手动复制粘贴。不过我是用的是如下两个命令： 12sed -i 's/^[ \t]*//g' mingdan.txt #这一步是添加每一行序号sed -i 's/\t/ /g' mingdan.txt #添加序号之后，会生成一个ta 然后mingdan.txt就成了这样： 12345[root@paas-online-crs-001 tmp]# cat mingdan.txt 1 ["10.117.219.72"] = &#123;app = "mrs", weight = 100&#125;,2 ["10.161.235.150"] = &#123;app = "mrs", weight = 100&#125;,3 ["10.161.236.231"] = &#123;app = "mrs", weight = 100&#125;,4 ["10.51.10.182"] = &#123;app = "mrs", weight = 100&#125;, 万事俱备，现在就要把IP.txt和mingdan.txt按照相同的内网IP整合成一个文件！ 脚本正文这个脚本是不怕mingdan.txt和IP.txt的IP顺序的。 1234567891011121314151617181920212223#!/usr/bin/env python#coding=utf-8import refd = &#123;&#125; #先设置一个新的空字典叫fd#以下都是最后拼字符串用的aaa = '["'bbb = '"] = &#123;app = "mrs",mrsReportIp = "'ccc = '",weight = 100&#125;,' #首先先判断mingdan.txt里是否存在for l in open('mingdan.txt', 'r'): ar = re.split(r'[ ""]',l) #做分割，把内网IP切出来 print "ip is :" + ar[2] #确认是否分割出来的是内网IP地址 fd[ar[0]] = ar[2] #把这个内网IP地址当作value，前面的序号就是key with open('out.txt', 'w') as fw: for l in open('IP.txt', 'r'): ar = l.split() if ar[0] in fd.values(): #如果IP.txt里面的内网IP与字典fd里的value相符合 fw.write(aaa + ar[0] + bbb + ar[1] + ccc) #拼成一个完整的字符串 fw.write('\n') #保存文件print('文件整合完毕，请查看out.txt的结果！') 执行结果123456[root@paas-online-crs-001 tmp]# cat out.txt ["10.117.219.72"] = &#123;app = "mrs",mrsReportIp = "1.1.1.1",weight = 100&#125;,["10.161.235.150"] = &#123;app = "mrs",mrsReportIp = "2.2.2.2",weight = 100&#125;,["10.161.236.231"] = &#123;app = "mrs",mrsReportIp = "3.3.3.3",weight = 100&#125;,["10.51.10.182"] = &#123;app = "mrs",mrsReportIp = "4.4.4.4",weight = 100&#125;,[root@paas-online-crs-001 tmp]#]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix-proxy的搭建和配置全过程]]></title>
    <url>%2F2018%2F01%2F26%2FZabbix-proxy%E7%9A%84%E6%90%AD%E5%BB%BA%E5%92%8C%E9%85%8D%E7%BD%AE%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Zabbix-proxy的用途和构建图Zabbix-server是建立在金山云的，现在需要监控阿里云的redis，但是阿里云跟金山云之间通信是无法走内网的，如果直接让zabbix-server与redis直接联系，一旦公网的信息被截获的话，整个金山区的zabbix可能都会遭殃，那么既然有这种“远程监控+当监控的位置通信不便”的需求，就搭建一个zabbix-proxy来解决问题。 Zabbix-proxy是一个监控代理服务器，它收集监控到的数据，先存放在缓冲区，保存的时间可以通过配置文件设定，然后再传送到zabbix-server，这样也大大减缓了zabbix-server的压力，注意！监控代理需要一个单独的数据库，因为它的数据库表名与zabbix-server的数据库表名是一样的，如果不单独分开，后果就是数据错乱。 有人看到这里可能问了，说来说去你的zabbix-proxy跟阿里的redis依旧是走公网的啊！虽然这样也是走公网，我现在只需要配置一个防火墙规则来让他俩保证通信即可，通过防火墙来提升安全系数。架构如图： 安装Mysql 5.5Zabbix-proxy机器情况：金山云centos 6.5，安装zabbix版本：3.0.8 1234567891011[root@js-online-cjhmq-002 opt]yum list installed | grep mysql #列出已经安装过的mysql情况[root@js-online-cjhmq-002 opt]yum -y remove mysql-libs.x86_64 #把之前的mysql连根拔起[root@js-online-cjhmq-002 opt]# rpm -ivh http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmRetrieving http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmPreparing... ########################################### [100%] 1:mysql-community-release########################################### [100%][root@js-online-cjhmq-002 opt]groupadd zabbix #新建用户组zabbix[root@js-online-cjhmq-002 opt]useradd -g zabbix -u 808 -m zabbix#-g：指定用户所属的群组；#-u：指定用户id。#-m：自动建立用户的登入目录； 现在要修改一下/etc/yum.repos.d/mysql-community.repo这个文件，将5.5的enabled改为1,5.6的enabled改为0： 123456789101112131415# Enable to use MySQL 5.5[mysql55-community]name=MySQL 5.5 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.5-community/el/6/$basearch/enabled=1 #这里改成1gpgcheck=1 gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/6/$basearch/enabled=0 #这里改成0gpgcheck=1gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 然后执行yum install mysql-community-client mysql-community-devel mysql-community-server php-mysql， 安装服务端和客户端，安装完毕之后可以mysql -h127.0.0.1看一下。 安装完毕之后，修改一下/etc/my.cnf，如图： 12innodb_buffer_pool_size = 512M #这个根据服务器性能填写，这个机器是2核2G的，所以我拿出半个G给mysqlinnodb_file_per_table=1 #这个是新增的字段，设置InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据目录 mysql安装完毕之后，我们还要导表进去，如图： 123456service mysqld startmysqladmin -uroot password '123456'mysql -uroot -p123456 -e 'create database zabbix_proxy character set utf8;'mysql -uroot -p123456 -e "grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'zabbix';"mysql -uroot -p123456 -e "flush privileges;"mysql -uzabbix -pzabbix zabbix_proxy &lt;/解压路径/zabbix-3.0.8/database/mysql/schema.sql 至此，mysql部分已经全部搞定。 安装Zabbix-proxy先去https://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/3.0.8/下载zabbix-3.0.8.tar.gz，上传到proxy服务器里。 12tar -zxvf zabbix-3.0.8.tar.gz./configure --prefix=/usr/local/zabbix-3.0.8 --sysconfdir=/etc/zabbix --enable-proxy --enable-agent --enable-ipv6 --with-mysql=/usr/bin/mysql_config --with-net-snmp --with-libcurl --with-openipmi --with-unixodbc --with-ldap --with-ssh2 --enable-java 如果出现了configure: error: Invalid LDAP directory - unable to find ldap.h，解决方法就是： 1yum -y install openldap* Zabbix-proxy的配置打开/etc/zabbix/zabbix_proxy.conf，需要修改几个地方： 123456789101112ProxyMode=0 #0是主动模式，1是被动模式Server=A.B.C.D #这里填写zabbix-server的内网IPHostname=J.Q.K.A #这里要与/etc/hosts下的名字一模一样LogFile=/tmp/zabbix_proxy.logDBHost=localhostDBName=zabbix_proxyDBUser=zabbixDBPassword=zabbixConfigFrequency=120 #主动去server端去拉去配置更新的频率120秒一次DataSenderFrequency=60 #发送采集的监控数据到服务器端，默认是1秒，我们一分钟发送一次#ProxyLocalBuffer=0 #ProxyLocalBuffer表示数据传递给server之后还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。#ProxyOfflineBuffer=1 #ProxyOfflineBuffer表示数据没有传递给server的话还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。 然后就是启动proxy: 1# /usr/local/zabbix_proxy/sbin/zabbix_proxy 用netstat查看一下端口和进程是否都OK： Zabbix-server端的配置登入zabbix-server的网页，如图添加proxy： 点击“create proxy”之后，就对应填写资料吧： 这里对上面的几个选项多说几句： 12345678Connections to proxy：服务器如何连接到被动代理：无加密（默认），使用PSK（预共享密钥）或证书。Connections from proxy：从活动代理中选择允许的连接类型。 可以同时选择几种连接类型（用于测试和切换到其他连接类型）。 默认为“无加密”。#点击Certificate之后又两个参数：Issuer：允许颁发证书。 证书首先通过CA（认证机构）验证。 如果CA有效，则由CA签名，则可以使用Issuer字段来进一步限制允许的CA。 该字段是可选的，如果您的Zabbix安装使用多个CA的证书，则使用该字段。Subject：允许的证书。 证书首先通过CA验证。 如果它有效，由CA签名，则主题字段可用于仅允许Subject字符串的一个值。 如果此字段为空，则接受由配置的CA签名的任何有效证书。 #点击PSK之后又两个参数：PSK identity：预共享密钥身份字符串。PSK ： 预共享密钥（hex-string）。 如果Zabbix使用mbed TLS（PolarSSL）库，Zabbix将使用GnuTLS或OpenSSL库，64位十六进制（32字节PSK），最大长度为512位十六进制数（256字节PSK）。 示例：1f87b595725ac58dd977beef14b97461a7c1045b9a1c963065002c5473194952 保存之后，就在zabbix-server用zabbix-get去ping一下proxy，看看返回值是否是1，如果是zabbix_get [18290]: Check access restrictions in Zabbix agent configuration，就检查一下刚才的hostname等值是否正确。 被监控机器的配置在被监控的阿里云redis里安装zabbix-agent，在agentd.conf里把hostname写成自己在/etc/hosts里的hostname，Server地址和ServerActive的地址都要写成proxy的外网IP地址。保存之后启动agent进程，这个时候在proxy端是可以通过zabbix_get得到这台被监控机器的值，如图： 在Zabbix-Server的WEB界面里，为阿里云的redis新建一个host，Agent interface那里填写被监控的机器IP，端口是10050，Monitored by proxy的地方要写成刚刚添加的proxy。如图： 上面已经提到过，用proxy模式并且zabbix的客户端也是主动模式提交数据，这样能大大提高采集效率，降低zabbix服务器端和proxy端的压力。现在我们希望添加的还是使用zabbix_agent的方式，新加到zabbix_proxy里面的主机使用zabbix_agent（active）的方式。注意在模板的克隆要选择full clone，不要选“clone”，那样的话就仅仅是把iterm的名字克隆过去而已，如图： 然后在items选择具体的类型，根据需要，想改那个改哪个，如图，注意！我图里写的是Zabbix agent，但是type这里选择Zabbix agent (active)。 改完之后，保存一下，就会看到type都是zabbix agent（active）了。 最后在host里把这个机器添加到proxy的模板里，如图： 在Administration的Proxies也看到效果了，如果server与proxy没有正确连接的话，last seen的地方会是--，如果连接的话就会显示具体时间，如图: 返回到hosts里，查看那个被监控的redis机器也成功被监控到了，ZBX已经变绿。如图： 因为我们线上环境基本都是用的zabbix_proxy方式是active方式，然后客户端也是active方式，既然都是active方式，那么zabbix_agent的Hostname就很重要，打个比方如果再zabbix_server端把一个主机的Hostname改了，然后客户端那边也改了，服务端和客户端的Hostname是统一的，但是proxy那里还记录的是旧Hostname，然后就会在proxy日志里面看到下面一条： 1cannot send list of active checks to "proxy内网IP地址": host [virt_proxy内网IP地址] not found proxy主动模式下，ConfigFrequency默认的是3600秒一小时，显然有点大了，可以适当的调低一下，如10分钟或者几分钟什么的。然后出现问题多看看zabbix服务端和proxy的日志，对症下药。 参考资料http://www.51niux.com/?id=156http://www.cnblogs.com/wangxiaoqiangs/p/5336630.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云服务器更改时区为utc]]></title>
    <url>%2F2018%2F01%2F25%2F%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9B%B4%E6%94%B9%E6%97%B6%E5%8C%BA%E4%B8%BAutc%2F</url>
    <content type="text"><![CDATA[开发提出需求说，某个模块是给洋人使用，于是把服务器里的时间改成UTC时间。我登陆到服务器里使用date查看了一下，发现目前使用的是东八区时间，如图： 首先先开启UTC，方法就是在/etc/sysconfig/clock的文件里修改这样一处：UTC=true。这样即使机器重启，UTC时间依旧会“BIOS ▶ UTC时区转换 ▶ 系统时间”的顺序正常使用。 在Centos 6.5里，各时区的时间是在一个叫/usr/share/zoneinfo/的文件夹下，在里面我们发现了我们的目标—-UTC，如图： 然后就是修改，方法如下： 12mv /etc/localtime /etc/localtime-bakln -s /usr/share/zoneinfo/UTC /etc/localtime 先把老的时间文件备份，然后把UTC文件做一个软连接过来即可。我们所熟悉的date命令就是/etc/localtime的输出结果。 现在去date一下，看看结果，果然改成了UTC： 这个时候，如果你服务器里装的是nginx的话，就会发现nginx日志里的时间也会变成UTC而不会再是CST了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云购买、启动、停止ecs等等操作的python脚本]]></title>
    <url>%2F2018%2F01%2F24%2F%E9%98%BF%E9%87%8C%E4%BA%91%E8%B4%AD%E4%B9%B0%E3%80%81%E5%90%AF%E5%8A%A8%E3%80%81%E5%81%9C%E6%AD%A2ecs%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[以下所有脚本都是在python 2.7的环境亲自测试的。阿里云的ak/sk是没有地域概念的，在任何地域都可以使用。 购买服务器以在新加坡购买服务器为例子： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#注意！服务器创建完毕之后，状态是关机的。from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionfrom aliyunsdkecs.request.v20140526 import CreateInstanceRequest# 创建 Client 实例clt = client.AcsClient('阿里云ak','阿里云sk','新加坡的地域') #各地域的缩写请看：https://help.aliyun.com/document_detail/40654.html?spm=5176.doc25499.2.14.yh6n8c# 创建 request，并设置参数request = CreateInstanceRequest.CreateInstanceRequest()# 设置ECS细节request.set_ImageId("centos_7_04_64_20G_alibase_201701015.vhd") #这里是镜像request.set_InstanceName("xjp-test-001") #这里写名称request.set_SecurityGroupId("sg-23t6c6mjw") #这里是安全组request.set_Password("W2.bi7FX1dyb)T3Wh^,[") #这里是密码，推荐使用https传输，安全request.set_InstanceChargeType("PrePaid") #确定是包年包月request.set_Period("2") #先买两个月的request.set_SystemDiskCategory("cloud_efficiency") #注意，如果是海外的机器的话，要额外说明，海外的机器只有高速云盘和SSD盘# 设置实例规格request.set_InstanceType("ecs.s2.large")# 发起 API 请求并打印返回response = clt.do_action_with_exception(request)print response 服务器停机1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StopInstanceRequestlist1 = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list1: shutdown = StopInstanceRequest.StopInstanceRequest() shutdown.set_InstanceId(i) action = clt.do_action_with_exception(shutdown) print "现在停机:" + i print action 服务器启动1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StartInstanceRequestlist = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list: start = StartInstanceRequest.StartInstanceRequest() start.set_InstanceId(i) action = clt.do_action_with_exception(start) print "现在启动:" + i print action 查询阿里云镜像123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeImagesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeImagesRequest.DescribeImagesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 查询服务器规格123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeInstanceTypesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeInstanceTypesRequest.DescribeInstanceTypesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 参考资料https://help.aliyun.com/document_detail/25499.html?spm=5176.doc25501.6.857.wR0MHP]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>阿里云api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Crontab里解决脚本时间重叠的问题]]></title>
    <url>%2F2018%2F01%2F24%2FCrontab%E9%87%8C%E8%A7%A3%E5%86%B3%E8%84%9A%E6%9C%AC%E6%97%B6%E9%97%B4%E9%87%8D%E5%8F%A0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[正文Linux里的Crontab是一个好东西，但是它的默认最小执行频率是1分钟，但是我们在实际生产环境里有的时候遇到的脚本执行时间是大于1分钟的，这样就会出现一个很尴尬的情况，就是在1分钟过后，系统进程会出现多个脚本，neck and neck式的在后台运行，比如这样： 从上面的图可以看到，10点36分log499.sh没有执行完毕，10点37又开始了执行了一个新的log499.sh脚本。这种脚本冲突肯定不是我们所希望的，那么如何才能保证后台只是在一段时间里只执行一个脚本呢？ 这个时候我们就要使用文件锁，flock，这种方法要比判断pid高大上的多。 首先假设我们的脚本名字叫abc.sh，这个脚本文件的执行时间是要大于1分钟的，同时我们再设定一个锁文件，位置就叫/tmp/abc.lock,这个文件可以是空的，然后crontab -e，添加一句命令如下： 1* * * * * flock -xn /tmp/abc.lock -c 'sh /路径/abc.sh &gt;&gt; /记录日志的路径 2&gt;&amp;1' 这个时候静候crontab启动abc.sh，通过ps -ef|grep abc，发现在后台始终只有一个abc进程。 但是有的时候会有这样的一个问题，就是abc执行一次之后，在下一次该执行的时候却没有执行，好像crontab失效了一样，对于这样的情况，就需要添加下面的语句到abc.sh末尾： 123rm -rf /tmp/abc.lock #删除掉原有的锁文件sleep n #睡n秒touch /tmp/abc.lock #再新建一个锁文件 这样不断地更新lock锁文件，就会保证crontab每次都会按期执行。 这里要注意一下，里面我加了一句sleep n，这里的n是为了跨分钟的存在，这是为了防止没有走到下一个分钟又会生成一个新的lock锁文件，这样还是会出现重复启动脚本的情况。 这里就涉及到flock的一个原理：在每一次执行任务的时候都会先去尝试取到锁文件，如果取到了锁文件，那么就会下一步，反之就会放弃执行。A任务在运行的时候已经占据了lock文件，那么B任务来了，发现没有lock了，就不会执行任务。 这里我们使用了flock的三个参数： 123-x, --exclusive: 获得一个独占锁-n, --nonblock: 如果没有立即获得锁，直接失败而不是等待-c, --command: 在shell中运行一个单独的命令 当然，flock还是有很多丰富的参数可以供各位使用，大家就各自去google一下吧。 参考资料http://blog.csdn.net/fdipzone/article/details/38284009http://chuansong.me/n/285635151949https://segmentfault.com/q/1010000008039907]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>crontab</tag>
        <tag>运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum提示Error: rpmdb open failed]]></title>
    <url>%2F2018%2F01%2F24%2Fyum%E6%8F%90%E7%A4%BAError-rpmdb-open-failed%2F</url>
    <content type="text"><![CDATA[今天在一台机器里，使用yum安装的时候，出现了如下的故障： 这种情况就是RPM数据库被破坏了，这个时候就需要我们重建数据库，于是就输入如下的命令： 1234cd / var / lib / rpm /for i in ` ls | grep 'db.' ` ; do mv $i $i .bak ; donerpm -- rebuilddbyum clean all 重新cleanup就正常了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由一个实例浅析sed用法]]></title>
    <url>%2F2018%2F01%2F23%2F%E7%94%B1%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B%E6%B5%85%E6%9E%90sed%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[首先，假设我们有一个文件，叫123.txt，cat一下看到里面的内容是这样的： 12345678[root@func-lms-001 ~]# cat 123.txt jamescurry durantwadeyaoming messi[root@func-lms-001 ~]# 如果我们想在james前面加上lebron，那么采用的sed语句就是：sed -i &#39;/^james/s/^/lebron /&#39; 123.txt，如果要在curry后面加上champion，那么采用的语句就是：sed -i &#39;/^curry/s/$/ champion!/&#39; 123.txt。 使用完上面两句话之后，再#cat一下，看下效果： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion! durantwadeyaoming messi[root@func-lms-001 ~]# 现在我们要把durant前面加上FMVP这几个字母，按照上面的语句找葫芦画瓢的话，应该是：sed -i &#39;/^durant/s/^/FMVP /&#39; 123.txt。但是很抱歉，这个语句是错误的！因为^是匹配开头durant的意思，而我们再看一下durant那一行的开头是空格。 那么就要用liunx的正则来匹配空格，于是这句话就变成了：sed -i &#39;/^\s\+durant/s/^/FMVP/&#39; 123.txt，^\s\+这个就是正则里匹配空格的意思 。 cat一下： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion!FMVP durantwadeyaoming messi[root@func-lms-001 ~]# 那么现在要在messi后面加上”GOAL !!!”，就很简单了。语句是：sed -i &#39;/^\s\+messi/s/$/ GOAL !!!/&#39; 123.txt。 以上我们把有/无空格情况下的首尾添加字符都练习了一遍，下面我们要看看如果要在中间添加怎么办？ 比如说，有一天苦逼的运维接到开发PL的邮件，说”由于安全基线要求，现在需要监听内网端口“，具体的需求就是把所有含tomcat的模块里的server.xml的文件里添加上内网IP。 原有的server.xml的节选如下： 12345678910&lt;Service name="LMS"&gt; &lt;Connector port="8080" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8088" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8099" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine defaultHost="localhost" name="Catalina"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase" /&gt; &lt;/Realm&gt; 现在要把&lt;Connector port=&quot;8099&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;这一句里面加上内网IP:1.2.3.4，改成这样： 12345678910&lt;Service name="LMS"&gt; &lt;Connector port="8080" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8088" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8099" address="1.2.3.4" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine defaultHost="localhost" name="Catalina"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase" /&gt; &lt;/Realm&gt; 请问怎么做？ 答案1： 1sed -i '/&lt;Connector port="8099"/s/port="8099"/port="8099" address="1.2.3.4"/g' server.xml 答案2： 1sed -i 's@Connector port="8099"@&amp; address="1.2.3.4"@' server.xml]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix添加网卡内外流量监控]]></title>
    <url>%2F2018%2F01%2F23%2FZabbix%E6%B7%BB%E5%8A%A0%E7%BD%91%E5%8D%A1%E5%86%85%E5%A4%96%E6%B5%81%E9%87%8F%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[现在笔者想对host名单里面的zabbix_server进行网卡的内外流量情况的一个监控，首先登录zabbix之后，configuration—hosts，出现如下的菜单： 现在可以看到这个zabbix_server后面link了很多个模板，正是因为link了很多的模板，所以导致它的items非常多，42个。现在是要在zabbix_server里添加两个新的监控项，这一步跟模板其实没有什么关系，只需要在items里直接添加items即可。 我们先添加网卡外流量的items，整个配置如图所示： 里面具体的数值可以自己更换，比如Applications什么的，key\units\Use custom multiplier这些是固定的，全部写完之后就可以save。 找葫芦画瓢，我们可以再添加一个网卡的内流量监控，也是一样的套路，如图所示： 有了items，就要有trigger，有了items里的key，那么trigger也很简单，这里的expression多时候各位都是从网上ctrl+c下来，却不能ctrl+v，因为会红字报错—-Incorrect item key &quot;net.if.in[eth0,bytes]&quot; provided for trigger expression on &quot;服务器名称&quot;，于是就有很多不明真相的吃瓜群众就走“add”路线，然后发现要走add路线还要先把服务器添加到对应的模板上去。其实大可不必，这个expression是可以自己写的，但是一定要确定trigger跟items是配对的。以外网流量所示： 在这里我添加成了1K，这样是为了方便监控，具体数值因情况而异，而且重要性我选择了无。 最后就是要形成图表来糊弄领导，让领导感受一下什么叫做高大上，在graph的界面里选择create graph，然后就如图所示的填写： 一个是红色线，一个是绿色线，双龙戏珠，save。 最后来到Monitoring—Graphs里，找到正确的host,group和graph，就会看到激动人心的图表了： 这里要注意几点，有时候zabbix反应较慢，可能写好的key会出现not support的情况，这个时候可以先登录zabbix_server去zabbix_get一下，zabbix_get的方法之前有讲过，请见http://chenx1242.blog.51cto.com/10430133/1738820 ，如果zabbix_get是成功返回值的，先检查对应的单位（结果是浮点值，但是units设定是一个整数值肯定会not support）,如果单位检查正确，就修改zabbix重新check的时间，实在不行就重新建立一个items。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>服务器监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Nessus进行漏洞扫描的过程]]></title>
    <url>%2F2018%2F01%2F23%2F%E4%BD%BF%E7%94%A8Nessus%E8%BF%9B%E8%A1%8C%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[对于一个服务器运维工作者，掌握和运用一门漏洞扫描的工具也是行走江湖的必备项，Nessus就是漏洞扫描的强力武器。Nessus为一款当下比较流行的系统弱点扫描与分析软件，他的优点是操作简单（配置几乎全web化），而且页面精美、扫描项广泛；缺点就是目前不支持中文… 下载与安装要安装Nessus，需要登陆https://www.tenable.com/products/nessus/select-your-operating-system,选择对应的系统，我这个服务器是centos 7，那么就选择下图里红色的那个rpm包： 点击之后，出来一个同意条款，同意之后就开始自动下载。但是要安装nessus仅仅有程序是不够的，还需要一个对应的验证码，在上面那个界面里，下拉一点有一个get an activation code的check，点击之后跳转到https://www.tenable.com/products/nessus/nessus-plugins/obtain-an-activation-code，里选择家用free版，点击下面的register now： 注册是很简单的，填写名称和电邮就可以了。不久后就会在电子邮件里面获得一个校验码。 把下载的那个Nessus-6.11.1-es7.x86_64.rpm包上传到centos之后，rpm -ivh Nessus-6.11.1-es7.x86_64.rpm进行安装，安装完成之后，service nessusd start启动进程，启动完毕之后，使用netstat -lnpt|grep 8834，来检查一下8834端口是否被监听，如图： 端口监听OK，那么在浏览器里输入https://服务器外网IP地址:8834打开控制web界面，如果有提示当前连接不安全，无视掉就可以。nessus的欢迎界面如下： 注册一个账号之后，在这个界面里面选择home那一条，输入邮箱里面获得的那个注册码： 整个的配置就完事了，继而就是nessus自动安装的过程，大约需要几分钟： 整个安装完毕之后，就会看到nessus的主界面，简单明了的风格： 至此整个nessus的安装过程结束。 配置扫描策略以及启动扫描任务nessus扫描漏洞的流程很简单：需要先”制定策略”，然后在这个策略的基础上建立”扫描任务”，然后执行任务。首先，我们先建立一个policy，如图： 点击New Policy之后，就会出现很多种扫描策略，这里我们选择Advanced Scan(高级扫描)： 我给这个测试的扫描策略，起名叫”chenchenchen”，如图： 对于上面这个图，Permissions是权限管理，是否可以准许其他的nessus用户来使用你这个策略；Discovery里面有主机发现、端口扫描和服务发现等功能；assessment里面有对于暴力攻击的一些设定；Report里面是报告的一些设定；Advanced里面是一些超时、每秒扫描多少项等基础设定，一般来说这里默认就好。我们主要来看看那个plugins。 Plugins里面就是具体的策略，里面有父策略，具体的父策略下面还有子策略，把这些策略制定得体的话，使用者可以更加有针对性的进行扫描。比如我这个策略是针对于centos系统的扫描策略，那么一些冗余的项目大可以完全不要，举个例子： 在上面这个图里面，我不需要amazon linux local security checks这个“亚马逊linux本地安全检查”父策略，那就把它disabled掉，而对于centos local security checks这个父策略呢，我又不需要那几个关于bind的子策略，那我就单独把那些子策略disabled掉，这样等等操作，就搭配成为了一个用时不长但是又包含了所有制定的检查项的策略，然后点击save保存。 保存完后，我们就发现policy里多了一条chenchenchen的记录： 既然策略有了，现在我们就来制定一个任务。在主界面里选择My Scans,点击New Scans,这个时候还是有很多个图标，但是我们选择后面的User defined，如图： 这里我们就看到了我们已经制定好的那个chenchenchen策略，点击这个chenchenchen之后，就要给这个依赖chenchenchen策略的任务起名字以及需要扫描的网络段，由于我这个测试机的内网ip段是10.132.27.0，于是我就写了“10.132.27.0/24”，任务名字叫chentest： 启动扫描任务点击save保存之后，就会看到My Scans里多了这个chentest的任务，点击三角播放箭头，那么这个任务就开始执行了！如图： 从该界面可以看到扫描任务的状态为Running（正在运行），表示chentest扫描任务添加成功。如果想要停止扫描，可以单击方块（停止一下）按钮。如果暂停扫描任务，单击暂停按钮。 扫描完毕之后，我们就会看到一个结果反馈，如图： 具体的颜色代表，在旁边有描述，例子里这些蓝色的info代表没有重大漏洞，点击一下蓝色，还会出现更加详细的信息，包括IP地址、操作系统类型、扫描的起始时间和结束时间： 同时，nessus还支持pdf、web、csv等多种方式汇报扫描结果，至此，整个nessus漏洞扫描的全过程就结束了。 Nessus配置smtpNessus漏洞扫描是提供邮件服务，可以将扫描的结果发送给指定的邮箱。配置它的方法很简单，先登陆Nessus的界面，点击左上角的settings，然后选择左侧菜单栏里的Smtp server，如图： 再就是填写对应的项目，我这里发送邮件的地址是：chenx3314@sina.com，接受的地址是124208739@qq.com，由于发送邮件使用的是新浪的邮箱，那么host就填写新浪的smtp服务器，即smtp.sina.com，如果是要SSL加密的话，端口写465，同时在Encryption那里选择Force SSL，在Auth Method那里选择login的鉴权方式，然后输入chenx3314@sina.com的账号密码，如图： 点击Send Test Email，然后输入接收的邮箱，如果是多个邮箱那么就用英文逗号隔开。看到成功的提示就是OK了： 然后就可以到邮箱里面看到那个测试的邮件内容：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>nessus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql清除磁盘碎片]]></title>
    <url>%2F2018%2F01%2F23%2Fmysql%E6%B8%85%E9%99%A4%E7%A3%81%E7%9B%98%E7%A2%8E%E7%89%87%2F</url>
    <content type="text"><![CDATA[任务背景接到金山云报警短信，说某数据库的容量已经达到了90%的水位线，于是登陆控制台查看详细情况。 在控制台首先发现，每一天的磁盘容量的确有所波动，那么就证明开发人员写的“资源回收”模块是在正常运行的，如图： 那么就说明没有什么数据是可以删的，既然删不掉多余的数据又不想多掏钱扩磁盘容量，只能从“磁盘碎片”下手了。而InnoDB引擎清理磁盘碎片的命令就是OPTIMIZE。 具体操作首先我先查询一下所有的“磁盘碎片情况”，使用语句如下： 1select CONCAT(TABLE_SCHEMA,'.',TABLE_NAME) as 数据表名,concat(truncate(sum(DATA_LENGTH+DATA_FREE+INDEX_LENGTH)/1024/1024,2),' MB') as total_size, concat(truncate(sum(DATA_LENGTH)/1024/1024,2),' MB') as data_size,concat(truncate(sum(DATA_FREE)/1024/1024,2),' MB') as data_free, concat(truncate(sum(INDEX_LENGTH)/1024/1024,2),'MB') as index_size from information_schema.tables group by TABLE_NAME order by data_length desc; 或者使用select table_schema, table_name, data_free, engine from information_schema.tables where table_schema not in (&#39;information_schema&#39;, &#39;mysql&#39;) and data_free &gt; 0;也可以，这个是查询data_free大于0的所有表。 然后看到我这个叫history_device_flow_day的表里情况如下： 表里的data_free就是磁盘碎片的量，比如我现在要干掉history_device_flow_day里所有的磁盘碎片，是975MB，于是先查询一下这个history_device_flow_day的存储引擎，使用语句如下： 1show table status from jsonlinefssrds where name='history_device_flow_day'; 上面语句里的jsonlinefssrds是对应的数据库，看到的效果如下： 存储引擎是InnoDB，那么就可以启动清除碎片的语句了：OPTIMIZE TABLE 数据表表名;，因为OPTIMIZE TABLE只对MyISAM、BDB和InnoDB表起作用。 再执行了OPTIMIZE TABLE history_device_flow_day;之后，大约9分钟，就会看到“OK”的字样： 估计有的朋友会问，那上面不是明明写了“Table does not support optimize, doing recreate + analyze instead”吗？这个其实无妨，实际上磁盘碎片已经被清除掉了。我们可以再用一次查询磁盘碎片的命令看一下，如图： 的确释放了900多M。 或者使用ALTER TABLE 表名 ENGINE = Innodb;（只是InnoDB的表可以这么做，而且据说这么做更友好）来达到清理磁盘碎片的目的，这个命令表面上看什么也不做,实际上是重新整理碎片了。当执行优化操作时,实际执行的是一个空的ALTER命令,但是这个命令也会起到优化的作用,它会重建整个表,删掉未使用的空白空间。 补充为什么会产生磁盘碎片？那是因为某一个表如果经常插入数据和删除数据，必然会产生很多未使用的空白空间，这些空白空间就是不连续的碎片，这样久而久之，这个表就会占用很大空间，但实际上表里面的记录数却很少，这样不但会浪费空间，并且查询速度也更慢。 注意！OPTIMIZE操作会暂时锁住表,而且数据量越大,耗费的时间也越长,它毕竟不是简单查询操作。所以把OPTIMIZE命令放在程序中是不妥当的,不管设置的命中率多低,当访问量增大的时候,整体命中率也会上升,这样肯定会对程序的运行效率造成很大影响。比较好的方式就是做个shell,定期检查mysql中 information_schema.TABLES字段,查看DATA_FREE字段,大于0的话,就表示有碎片，然后启动脚本。 参考资料http://pengbotao.cn/mysql-suipian-youhua.htmlhttp://irfen.me/mysql-data-fragmentation-appear-and-optimization/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一道传说中是百度面试的shell试题]]></title>
    <url>%2F2018%2F01%2F23%2F%E4%B8%80%E9%81%93%E4%BC%A0%E8%AF%B4%E4%B8%AD%E6%98%AF%E7%99%BE%E5%BA%A6%E9%9D%A2%E8%AF%95%E7%9A%84shell%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[【问题】写脚本实现，可以用shell、perl等。把文件b中有的，但是文件a中没有的所有行，保存为文件c，并统计c的行数。翻译成人话就是，假设有一个文件a是:abcd 文件b是:1234ab 现在要求输出“b有a没有”的行，即1 2 3 4，然后wc -l一下。 【思路】两个文件比较，第一想法就是diff，但是diff无论是-c还是-y会牵扯进大量的&gt; &lt; + -不说，而且diff命令是直白对比，即使字母相同但所在行不同，也会被diff记录。如果再用for in语句然后一项一项对比也不会很清晰的解决这个问题，所以要换个方法。 第二个方法就是comm命令，但是这个命令有一个前提，就是要sort排序，comm比diff高明之处在于它只比较内容而不在意是否同一行，但是要注意对比文件的先后。comm -12 a b是找”a和b都有”的项，comm -23 a b就是找”a有而b没有”。 【解答】perl我不会，我就用shell写： 123456#!/bin/bash#written by ChrisChan @ 2016-4-21sort a.txt&gt;a1.txt #排序，不然会有提示sort b.txt&gt;b1.txtcomm -23 b1.txt a1.txt &gt;c.txt #由于是要找b有a没有的,就要b写在前，a写在后echo $(cat c.txt|wc -l) 其实还有一个更简单的，只用一句话: 1grep -v -x b.txt -f a.txt|wc -l 很多书上不写grep -x -f的意思，这里补一下：-f:指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。-x:只显示全列符合的列。 从一个题就能轻松看出shell的能力级别，用diff死纠缠就是初级，用comm就是中级，而grep就是高级。的确是一个好题。 【补充】如果考python，求这种类似“你有我没有”的东西，用set里面的差集算法。 12345678910&gt;&gt;&gt;A=&#123;1，2，3，4&#125;&gt;&gt;&gt;B=&#123;3，4，5，6&#125;&gt;&gt;&gt;print(A-B)set([1,2]) #A有B没有&gt;&gt;&gt;print(A ^ B)set([1,2,5,6]) #差集的补集&gt;&gt;&gt; A&amp;B&#123;3, 4&#125; #交集&gt;&gt;&gt; A|B&#123;1, 2, 3, 4, 5, 6&#125; #全集]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>面试经验</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Zabbix在web界面中文显示的问题]]></title>
    <url>%2F2018%2F01%2F22%2F%E8%A7%A3%E5%86%B3Zabbix%E5%9C%A8web%E7%95%8C%E9%9D%A2%E4%B8%AD%E6%96%87%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[注意！这个是解决web界面中文显示乱码的问题，不是zabbix web界面全中文汉化的问题。 2.2版本的处理方法zabbix里给host或者item等项目起中文名字的时候，可能在graph上无法正确显示中文字符，如图： 那么遇到这样的情况其实很简单，就是zabbix的web界面没有安装中文字库的问题，那就对症下药，下载中文字库。 中文字库的下载地址在这里：http://linux.linuxidc.com/2012%E5%B9%B4%E8%B5%84%E6%96%99/11%E6%9C%88/22%E6%97%A5/Zabbix%E4%B8%AD%E6%96%87%E4%B8%8D%E8%83%BD%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98/ ，下载“LinuxIDC.com下载-kaiti.tar.gz”。 后把这个文件改一下名，可能很多linux不识别那个中文字“下载”,mv LinuxIDC.com下载-kaiti.tar.gz kaiti.tar.gz，tar -zxvf kaiti.tar.gz 然后就会发现当前路径里生成了一个叫kaiti.ttf，这个就是我们所需要的中文“楷体”字体文件。 来到zabbix的web字体路径，在我的机器里，这个负责字体的文件夹叫/usr/local/nginx/html/zabbix/fonts/。虽然各位安装zabbix的路径各有差别，但是这个文件夹一般都是在nginx or apache的html下，所以很好找的。 在这个fonts文件夹里默认已经有一个叫DejaVuSans.ttf的文件了，于是就把这个kaiti.tff也放到这个文件夹下。 光有字体文件没有用，还需要在配置文件里使用这个字体文件，于是就vim一下同样在nginx or apache/html/zabbix/include的defines.inc.php。把里面所有的DejaVuSans替换成kaiti，.tff这个后缀是不用加的。然后保存退出，重新刷一下界面就看到效果了。 vim的替换语句 :%s/DejaVuSans/kaiti/g 3.x版本的处理方法现在zabbix已经升级到3.x了，上述的方法已经失效了，这里记录一下新的中文配置方法。 首先从windows里，拷贝一个中文字体的文件到zabbix的服务器的/usr/share/zabbix/fonts文件夹里，比如我先择了“楷体”，这个文件叫simkai.ttf，chmod +x simkai.ttf 给予可执行权限。 然后vim /usr/share/zabbix/include/defines.inc.php，修改两处地方，分别是第四十五行，把原来的改成simkai，如图： 还有一处就是第九十三行，也是改成SIMKAI： 保存文件之后，刷新一下zabbix界面即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>运维与监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防盗链的等等相关]]></title>
    <url>%2F2018%2F01%2F22%2F%E9%98%B2%E7%9B%97%E9%93%BE%E7%9A%84%E7%AD%89%E7%AD%89%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[为什么网站们都要限制流量？无论是网站服务器亦或是游戏服务器还是邮件服务器，说穿了也是一台电脑，也有CPU和内存。只不过服务器的CPU功能比个人电脑的CPU功能强大，比如个人电脑的CPU一秒钟能算1亿个数，那么服务器的CPU一秒钟就能算十亿个数。毕竟个人电脑只针对个人，但是服务器是要“接客”的，有了强大的硬件做后盾，网页/游戏/邮箱才不会那么轻易的Down掉。 但是CPU不是人类大脑，人脑是越用越聪明，CPU是越用越磨损，毕竟始终在连电的环境下。于是乎，没有必要的运算能省就省，一个人省一次，十万个人就省十万次，一千万个人就省一千万次，这样达到积少成多的目的。 CPU计算的是各种数据，而这些数据也叫作流量。有用的流量、有价值的流量通过CPU计算无可厚非，但是出现了没有用的流量或者是别人盗用我们的资源，那么这种情况能避免都要避免。什么叫盗用我们的资源，比如自己网站（网站A）上的图片或者视频，被其他人直接复制网站然后粘贴到他们的主页（网站B）上，其他用户登录了B网站，然后点击了那个图片和视频，由于是网址重链接，里外里提供数据的还是我们的服务器。也就是说B网站就是一个中介，而真正提供服务的是网站A，但是广告费和点击率都要网站B赚走了，这事儿实在是叔可忍婶不可忍。 什么是盗链？如何发现被盗链？什么叫盗链，上面已经说的差不多了，如果上面的文字没有看懂的话，举个例子，如果您看到了这两个图片，证明这个网站就是在盗链。 这两个就是一个盗取的是QQ空间的图片，另一个就是百度的图片。用其他网站的图片这事儿本身是无所谓的，只要不涉及版权问题，都希望自己的作品能广泛传播，但是请不要直接通过网址重定向，厚道一点的行为应该是：“图片另存为”，然后到目标网站上去重新上传一下。 这里再多说一点网站的基础知识。 PV值：PV=page view，网站是有少则一个网页多则N多网页组成的一个整体，PV值就是统计用户访问网站的总页数。比如www.JQK.com这个网站，今天有100个用户登录，平均每个用户翻阅了里面5个网页。那么这个网站的PV值就是500。若一个IP地址，对一个页面刷新10000次，PV值也是1.要查询网站的PV值登陆http://www.alexa.cn就行。 Hit值：这个就是对网页里每个元素的点击量，一个网页里的图片就是一个元素，一个flv文件也是一个元素，一首歌曲也是一个元素。这些的总量就是hit值，hit值越高就证明这个网站被人查看的情况越高，那么也证明网站的高人气，那么自然广告也会卖出去很多钱。 因为建网站这事儿关心到了金钱利益，网站越被人关注，自然价值也越大。于是会有一个公式来评判网站的“每日贡献”：总流量=访问流量+下载流量= Page view值 x 页面大小+下载文件大小 x 下载次数 作为管理者，每天观察一下自己一亩三分地儿的网站数据情况是本职工作。但是有时候也会遇到网站流量很惊人的情况，一般来说，网站流量过大（CPU运转很多）的原因如下： 1）网站是一个很大的网站：比如说淘宝，京东，网易，youtube,facebook那种大网站，里面成万上亿的网页，而且每天又有那么多人登陆，自然浏览量很大。虽然这些大集团的服务器也是少则几千，多则上万，甚至在不同地区也会有不少的服务器集群，但是这几万台服务器需要提供的数据会很多也是不争的事实。这种现象是正常的。 2）网页内容太大：可能本身网站是一个小网站，加起来也就十页二十页的内容，但是每一天的流量依旧很惊人，那么很有可能是单页或者某几页的字节太大。比如网页里有太多的图片，太多的视频，太多的其他链接，也有可能是前端码农们给这个网页的规划不合理。导致这个网页每一次被点击都要大费周折（hit值和PV值不高，但是日流量很高），长此以往不仅会耽误用户的整体体验，对服务器也是一个重大伤害。 3）搜索引擎产生了大量的数据流量：网站需要推广，于是就在各种搜索引擎上打广告，也有自己网站的很多图片用于外部调用。这样的结果就是本身来观摩网站的人很少，但是“借着引擎经过”的人很多，所以就会有PV值不高，但是Hit值和日流量很高的现象出现。 4）图片或者其他元素被盗链：第一部分就说过了，别人拿我们的图片去吸引别人关注，然后别人想要深入了解，还要来使用我们的服务器去提供详细数据。这种“用我们的牌子住我们的房，吃我们的饭却不给我们钱”的现象实在应该被弄死。这种现象的特征也是PV值不高（没人真正点击网站），但是Hit值和日流量很大（自己服务器的数据都给别的网站提供了）。 5）网站被DDos攻击了：被一些恶意的IP地址频繁登陆，来回的刷流量。这样迫使CPU做出运算的行为其实就是在远程的破坏服务器的硬件CPU，遇到这种现象，之前Nginx文章里有写，要么通过access.log找到这些IP封掉，要么就在配置文件里加上限制limit-rate。 服务器是如何知道图片是从站外而来的呢？在http协议里有一个重要的选项叫refer，这个选项的内容就是该元素的来源地址。如果这个元素是服务器自己提供的，那么头文件里是没有refer这个选项的。通过refer这个信息，我们也可以知道登陆网站的客户是从哪个网站点击链接而来的。这样方便进行一个统计和规划。 假如，我在QQ空间里面发现一个图，然后右键图片，选择”在新标签栏里打开图片”，这时候通过浏览器“审查元素”的功能，能查查看请求头信息和响应头信息，发现响应头信息里多了一个refer，里面的内容就是图片的源地址： 我在QQ空间里看腾讯的照片自然是可以的，但是如果我在别的网站里看腾讯的照片，加重了腾讯服务器的负担，自然腾讯公司会不满意。于是腾讯服务器发现当前要引用这个图片的地址与refer头信息不是一个来源之后，就不会把这个图片的数据传送过来，于是就看到那个“此图片来自QQ空间，未经准许不可饮用”的警告图片。 既然知道了服务器是如何判断文件是否盗链，那么只要伪装一个refer就可以欺骗服务器达到“反防盗链”的目的了。至于这部分，可以自己单独研究。如何使用Nginx反盗链？ 同样的使用Nginx.conf，在http的大括号下面，新建一个location，加入如下信息： 12345678910111213141516location ~ .*\.(wma|wmv|asf|mp3|mmf|zip|rar|jpg|gif|png|swf|flv)$ &#123;#指定对以上几种类型的文件建立防盗链 valid_referers none blocked *.alala.com alala.com;#盗链的范围不包括alala.com和alala.com下的二级网站， if($invalid_referer) &#123; #rewrite ^/ http://www.alala.com/error.html; return403;#如果发现有引用以上文件的地址与refer头信息不符的情况，直接重定向成error.html这个网页，服务器返回403，forbidden。 &#125;&#125; 使用第三方模块ngx_http_accesskey_module实现Nginx防盗链实现方法如下： 下载NginxHttpAccessKeyModule模块文件：http://wiki.nginx.org/File:Nginx-accesskey-2.0.3.tar.gz； 解压此文件后，找到nginx-accesskey-2.0.3下的config文件。编辑此文件：替换其中的$HTTP_ACCESSKEY_MODULE为ngx_http_accesskey_module； 用一下参数重新编译nginx： ./configure –add-module=Nginx目录/to/nginx-accesskey然后执行: make &amp;&amp; make install 修改nginx的conf文件，添加以下几行： 123456location /download &#123; accesskey on; accesskey_hashmethod md5; accesskey_arg "key"; accesskey_signature "mypass$remote_addr";&#125; 其中：1.accesskey为模块开关；2.accesskey_hashmethod为加密方式MD5或者SHA-1；3.accesskey_arg为url中的关键字参数；4.accesskey_signature为加密值，此处为mypass和访问IP构成的字符串。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>网络相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次配置http跳转https的过程]]></title>
    <url>%2F2018%2F01%2F18%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E9%85%8D%E7%BD%AEhttp%E8%B7%B3%E8%BD%AChttps%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[公司最近搞了一个数据运营平台，这个平台会以web界面的形式把各个数据展示出来，这个项目是我们一个经理的重点关照项目。把平台模块部署完毕并且启动之后，又把这个平台服务器的外网IP绑定到alkaid.lechange.com这个域名上，在浏览器里输入https://alkaid.lechange.com,就看到了前端同行们写的网页。 但是我们的霸气经理说这样不行，说要更多要求更高标准更好体验，于是乎提出一个需求就是：在输入alkaid.lechange.com的时候会自动跳转到https://alkaid.lechange.com。 既然如此，我们就在nginx上原有的nginx.conf里补充几个配置文件： 12345#include upstreaminclude upstream.conf;# include serversinclude alkaid.conf;include alkaid-https.conf; 这样在执行nginx.conf的时候，就会调用upstream.conf、alkaid.conf和alkaid-https.conf，我们主要看一下这三个文件。 alkaid.conf文件如下： 123456789server &#123; listen 80; server_name *.lechange.com; proxy_buffering off; location / &#123; rewrite ^/ https://alkaid.lechange.com permanent; client_max_body_size 100m; &#125;&#125; 这里我们监听了80端口，下面那个client_max_body_size 100m是用来设定nginx+php上传文件的大小，这里规定是100m，这个可以写进nginx.conf里，如果有对上传文件方面感兴趣，可以看http://www.cnblogs.com/zhwl/archive/2012/09/18/2690714.html 。 再来看看alkaid-https.conf，如下： 1234567891011server &#123; listen 10000; server_name *.lechange.com; proxy_buffering off; location / &#123; proxy_pass http://alkaid_backend; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; &#125;&#125; 这里监听了10000端口，location写的是http://alkaid_backend,这个alkaid_backend是啥东西? 这个时候我们就需要看一下upstream.conf，里面内容是: 1234upstream alkaid_backend &#123; server X.X.X.X:JQK; check interval=5000 rise=2 fall=5 timeout=1000 type=tcp default_down=false;&#125; X.X.X.X是模块服务器的内网IP地址，而JQK是模块服务器的模块端口，这里要根据实际的情况来写。可见alkaid_backend对应的就是模块服务器和它的端口，下面是检查间隔等等数值。 现在我们启动nginx，然后把nginx的外网地址绑定去alkaid.lechange.com这个域名，在浏览器里输入alkaid.lechange.com，就会达到自动跳转的目的了！ 这里要额外多说一下，我们这里设定了80的配置文件也设置了443的文件，但是这俩文件的转发过程却不同：alkaid-https.conf文件把443的请求转向了平台模块服务器的服务，而alkaid.conf文件把凡是从80端口进来的请求直接全部永久重定向到https://alkaid.lechange.com ，但是这个alkaid.lechange.com还是会去访问平台模块服务器的服务，也就是说alkaid.conf文件多了一步重定向。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将电商平台测试环境添加了域名和https]]></title>
    <url>%2F2018%2F01%2F18%2F%E5%B0%86%E7%94%B5%E5%95%86%E5%B9%B3%E5%8F%B0%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E6%B7%BB%E5%8A%A0%E4%BA%86%E5%9F%9F%E5%90%8D%E5%92%8Chttps%2F</url>
    <content type="text"><![CDATA[情况描述今天电商平台来了新的产品经理。摸了一遍情况之后，提出了两个需求，第一个是要把测试环境也要上https，达到与线上一致；第二个就是测试环境要配上域名，不要再用IP地址登陆。 配置域名是很简单的，在阿里云的云解析上直接给测试环境新加一个域名，然后对应添加阿里云外网SLB的IP地址即可。进入页面也发现首页地址显示正常，但是再点点就发现了里面有点不对。 没错，现象就是“只有首页是域名，其他网站都是IP”， 遇到这个情况，我就跑去nginx.conf里，看一下server_name的配置，看到的确写得是func.lechange.com，如图： 于是就在页面上使用ctrl+shift+c查看具体情况，发现里面的代码是这个样的： 这就人赃俱获了，开发已经在html里把地址写死了，使用了绝对路径而不是相对路径，于是就打回让开发自己慢慢改。 然后又回到SLB界面，新增新的https监听，前端端口443，后端是80，搭配正确的证书，SLB保存之后，在浏览器输入测试环境的https://网址之后，发现整个界面全乱了，如图： 但是使用http://网址去访问还是正常的，如图： 很明显，这是因为https下跨协议调用http的是不行的，所以那些css、js如果不支持https的话就无法正常显示。使用ctrl+shift+c看错误更加明显。 遇到这个问题，就有如下几种方法： 第一种：将所有的访问路径都写死https，不过这个我们公司代码规范不准许;第二种：去掉URL中的http://或https://，将其替换为//，这样，浏览器就可以根据当前页面的请求方式来动态切换了；第三种：可以在&lt;head&gt;中添加&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;upgrade-insecure-requests&quot;&gt;,浏览器会在加载HTTP资源时自动替换成HTTPS请求；第四种：在nginx里写一个proxy_redirect跳转，这个就比较有技术含量了； 参考资料https://thehackernews.com/2015/04/disable-mixed-content-warning.htmlhttps://www.tuicool.com/articles/ARVVFjIhttps://developer.mozilla.org/en-US/docs/Web/Security/Mixed_content/How_to_fix_website_with_mixed_content]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师笔试题第十四套]]></title>
    <url>%2F2018%2F01%2F17%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98%E7%AC%AC%E5%8D%81%E5%9B%9B%E5%A5%97%2F</url>
    <content type="text"><![CDATA[前言这几天一边看着《nginx高性能WEB服务器详解》，一边看着基础知识。那么最容易入眼的基础知识是什么呢？当然是面试题了，于是乎就找出来一些阿里（含滴滴和蚂蚁金服）的运维面试题，以题带看。 看完之后觉得阿里真的不是盖的，面试题的质量比那些晚上乱七八糟的题质量好多了，细节抠的真是非常细。我记得曾经有一个前辈曾经说过，工作中我们经常注意一些奇淫技巧，但是忽视了基础知识的重要性，现在好多程序员不会认认真真地读本书，喜欢快餐文化，受了市面上很多培训机构的影响，这是要不得的。 最后再说一句，以下所有的题都属于“开放性”试题，可以根据基本点去发散，说出你的理解和认识。但是注意，不要避重就轻耍滑头，问A，可以发散到A1、A2…但是不要发散到X、Y、Z，然后大谈特谈XYZ，这种“小聪明”就是找死的行为。 废话到此为止，上题1）http一般是无状态的，怎么让它变成有状态的？[我的答案]http协议跟IP协议、UDP协议一样都是无状态的，http的无状态意思是“每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是无直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况”。补充一下，TCP是有状态的，它的请求并不独立，它通过包头的一些控制字段来分别包的关系，这里可以自行脑补一下“三次握手”的图。 那么http是无状态的这一点是无法改变的，那么要变得“有状态”，就需要引入cookie和session，通过这两个机制去实现一个有状态的WEB应用。用一个表达式可以这么理解：Web应用=http协议+session、cookies等状态机制+其他辅助的机制。 2）解释一下cookie和session的区别[我的答案]session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中，session是一个抽象概念，开发者为了实现中断和继续等操作，抽象出来的一个“会话”，接上面那道题，session这个东西是有状态的，服务器要维护一个有状态的东西是很消耗资源的（比如内存和空间），我估计天猫京东那规模的电商，肯定有一个专门的session集群。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式，cookie是一个实际存在的东西，它是在http协议中定义在header中的字段。同一个域名给的cookie肯定是一样的，所以每一个cookie（key）对应的session（value）是唯一的。 session的常见实现要借助cookie来发送sessionID给客户端，如果浏览器禁用cookie，那么就要通过重写url来获取sessionid，各位可以联想一下电商的购物车，购物车可以实现在一个网站的不同页面把东西都放进一个购物车，这就是session的重点应用。现在也很流行一个token，其实token和sessionid是一个意思。 3）多进程和多线程的区别，自己喜欢用哪个？为什么？[我的答案]多进程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个子进程与客户端建立连接开始交互，每一个子进程之间互相独立不受干扰，完成任务就收回资源，内存等也会被回收；多线程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个线程与客户端建立连接开始交互,多个线程位于同一个进程内，可以互相访问同样的内存等资源，彼此之间会有影响；我个人更喜欢多进程，因为简单粗暴！ 关于多进程、多线程、同步、异步的原理，可以去看一下《nginx高性能WEB服务器详解》，第54页到56页的内容。 4) lvs脑裂如何解决，为什么会产生双master？双master时VIP通不通?[我的答案]产生双master的原因：1）服务器开启了iptables防火墙，阻碍了心跳信息传输；2）服务器心跳网卡等信息写错了，导致心跳信息发送失败；3）心跳方式不搭配，心跳广播冲突；4）软件出bug了； 额外补充一句，要排除脑裂问题，第一步是检查iptables,很可能是由于iptables把心跳信息隔断了，重要的话不说三遍也重要！ 其他两个问题不会了，我在实际工作里没有接触到。 5) 为什么TCP比UDP的信息更加可靠？详细说说tcp滑动窗口原理，窗口的大小如何确定。TCP可靠性由三个机制保证：1. 序号（TCP报文的序号）2. 确认（ACK机制）3. 重传（超时或者冗余的 ACK）tcp在传输的时候，因为接受方B能力有限，不可能一口气吃下所有发送方A所有的数据流信息，所以B要限制A每次发送的字节数量，并且一一确认，确认了之后A才可以继续发。这样的话，A的在发送数据流的时候就会有四种形态：1.已发送已确认；2.已发送但没被确认；3.未发送但是接受方已经准备好空间来接收；4.未发送但是接受方尚未准备好空间来接收；随着数据流的传输，这个形态是会时刻发生变化的，通过接受方B返回的确认信息来改变2的大小，同时B也会根据一次关于发送方A要发送多少字节确认自己的空间来改变3的大小。 6) 简单说说cdn的工作原理，如何评估一个cdn sp做的好不好。[我的答案]cdn的工作原理：通过权威dns服务器来实现优质节点的选择，通过缓存来减少源站的压力。 IT界有个很有名的比喻，正向代理是“找马云借钱”，反向代理是“给10086打电话”，而反向代理就是CDN的实现原理雏形的一部分。详情可以看：http://www.iweir.cn/zheng-xiang-dai-li-yu-fan-xiang-dai-li/ 。 7）dns查询的过程说一下，为什么要有cname而不是直接返回一个cdn边缘节点的ip。[我的答案]先说一句题外话，dns主要是基于udp的！dns查询的过程以www.taobao.com为例：1.在浏览器键入www.taobao.com,其实真正dns协议里用到的是www.taobao.com.最后还有一个点，可能是因为美观等原因，一般都不显示;2.查询本地缓存（host文件或者是浏览器的缓存）中有没有该域名对应的记录，有的话就直接用了;3.向运营商的DNS服务器发起dns解析的请求，一般称运营商的DNS服务器为local dns;4.local dns会查询本地的缓存，local dns设置的缓存时间是有讲究的，过长过短都不好。另外local dns的查询是运营商的事，这里面水很深，外部不可控(这也是天朝能搭建特色墙的根源的思想雏形)；5.local dns如果没有缓存，会把域名从右往左扫描，依次请求对应的服务器，例如对于域名www.taobao.com.，先去问负责.的根域名服务器，就是传说中全球只有几台的那些服务器，他们会答复.com是谁管理的，然后local dns又去找管理.com的服务器（假设名字为S1），去问问taobao.com是谁管，一般来说，在S1查到的记录是一条cname记录（阿里毕竟大公司，自己管理自己旗下的域名），然后就转到了阿里自己的DNS服务器上来了，一般称之为权威服务器；6.权威服务器是阿里自己建的，然后根据公司内部的一些配置啊，调整啊，查到www.taobao.com.对应的服务器是谁，返回一个IP地址；7.local dns缓存这个IP地址，并且回复浏览器；8.浏览器和对应的IP地址的服务器建立TCP连接，发送HTTP报文； 用图表示就是： 至于说为什么不返回cdn边缘节点IP，是因为使用CNAME记录可以很方便地变更IP地址，毕竟服务商掌握着IP的生杀大权，哪一天需要换IP了，在这方面很不方便。 8）举例说下正则表达式和扩展正则表达式、例如：url、ip、邮箱的正则表达式？[我的答案]这三个都是网上找的，正则这个东西还是要多练多写。url的正则表达式：([/w-]+/.)+[/w-]+.([^a-z])(/[/w- ./?%&amp;=]*)?|[a-zA-Z0-9/-/.][/w-]+.([^a-z])(/[/w- ./?%&amp;=]*)?ip的正则表达式：^(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|[1-9])\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)$邮箱的正则表达式：^[a-zA-Z0-9.!#$%&amp;’+\/=?^_`{|}~-]+@a-zA-Z0-9?(?:.a-zA-Z0-9?)$ 9）解释raid0、raid1、raid01、raid10、raid5、raid6，并分析各自读写性能？[我的答案]https://rorschachchan.github.io/2018/01/31/简析raid0-raid1-raid10-raid01等等硬盘搭配/ 10）raid为什么不搞个raid50、raid15，不能搞是因为有什么冲突还是什么等等?[我的答案]raid50是有的，但是用途不广泛。raid15我是没听说过，因为raid1的写本身就不强（一样的内容要写两个盘里），raid5的写入能力更烂，那么raid15的磁盘写能力简直就是灾难。而且花了硬盘的钱只能存实际一半的量，正常人都不会这么做的。 拓展阅读https://segmentfault.com/a/1190000007243675http://mertensming.github.io/2016/10/19/cookie-session/https://wizardforcel.gitbooks.io/network-basic/content/index.htmlhttps://coolshell.cn/articles/11564.htmlhttps://coolshell.cn/articles/11609.htmlhttp://blog.sina.com.cn/s/blog_93b45b0f0101a4ix.htmlhttp://www.cnblogs.com/549294286/p/5172435.htmlhttps://wizardforcel.gitbooks.io/network-basic/content/7.html（这个墙裂推荐，基础知识）http://blog.jobbole.com/105500/http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.failover.html]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实战Kibana的日志关键词搜索和日志可视化]]></title>
    <url>%2F2018%2F01%2F17%2F%E5%AE%9E%E6%88%98Kibana%E7%9A%84%E6%97%A5%E5%BF%97%E5%85%B3%E9%94%AE%E8%AF%8D%E6%90%9C%E7%B4%A2%E5%92%8C%E6%97%A5%E5%BF%97%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[准备工作首先，先下载一个elastic网站上下载一个它提供的demo—莎翁的《亨利四世》，下载地址是https://download.elastic.co/demos/kibana/gettingstarted/shakespeare.json 。 打开这个json字符串，里面就是《亨利四世》的话剧剧本，长得是这个样子： 可以看到里面有play_name、speaker、speech_number、line_id等等名称，每个名称后面都有一个对应的值。 然后启动elasticsearch，按照上面的文件格式生成索引。语句如下： 1234567891011121314curl -XPUT http://localhost:9200/shakespeare -d '&#123; "mappings" : &#123; "_default_" : &#123; "properties" : &#123; "speaker" : &#123;"type": "string", "index" : "not_analyzed" &#125;, #确定type是字符 "play_name" : &#123;"type": "string", "index" : "not_analyzed" &#125;, "line_id" : &#123; "type" : "integer" &#125;, #确定type是数字 "speech_number" : &#123; "type" : "integer" &#125; &#125; &#125; &#125;&#125;'; 导入刚刚下载的那个json：curl -XPOST &#39;localhost:9200/shakespeare/_bulk?pretty&#39; --data-binary @shakespeare.json 具体elasticsearch的增删改查语法可以参看阮大师的http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html ，个人建议将elasticsearch和mysql对比一下，这样更方便理解。 然后后台启动kibana，确认5601端口已经stand by，如图： 然后在浏览器地址栏输入服务器外网ip：5601打开kibana。 导入数据结束之后，使用curl &#39;localhost:9200/_cat/indices?v&#39;，去查看一下效果，如果看到index里有shakespeare那一栏就是导入成功了，如图： 在启动Kibana后，Kibana会自动在配置的es中创建一个名为.kibana的索引（上图第二个），这个索引用来存储数据，注意！不要删除了它。 Kibana的界面搜索如果此时的kibana里是第一次配置的话，那么第一步就是配置新索引，我们之前在生成索引的时候写的是shakespeare，那么现在也写shakespeare，然后点击create，如图： 然后在菜单栏左侧的discover里选择刚刚建立的shakespeare，就会看到这样的东西： 在Search上就可以进行搜寻，比如说我搜寻freedom，如图： 如果我搜寻KING HENRY IV，他不分大小写的把所有king、henry、iv都搜索出来。 如果我想搜寻line_id的第一行到第三行，那么语句就是line_id:[1 TO 3]，如图： 如果想在上面的基础上进一步细化，比如说要在line_id是从第一行到第三行，同时_type是scene的语句：line_id:[1 TO 3] AND _type:scene： 假如不想要scene，那么就把AND改成NOT。 如果这个时候只想关注一些指定的字段，那么可以将鼠标移动到索引下面的字段上，然后选在add即可，同样的移动上面已经选择的字段选择remove进行移除，比如我们试一下这个speaker： add之后在点击右侧的具体的speaker，就会看到里面的细节，比如这位westmoreland（威斯摩兰伯爵）： 这个时候就能看见这位伯爵大哥的台词细节，在第几场的第几节，说的是什么台词。再返回菜单左侧点击这个speaker，我们还会看到一个比重： 从这里就很清晰的看到，FALSTAFF（法斯塔夫）这个哥们的台词最多，也符合书里塑造的那个嗜酒话痨的艺术形象。而我们的KING HENRY IV(亨利四世)的台词只是第四位，占比重11%而已… 这样具体的搭配搜索之后，可以点击界面右上侧的save进行保存搜寻结果，再搭配share分享搜索结果的url网址，如图： Kibana的图像化展示Kibana也能做到类似grafana那样的炫酷图象化展示，更加立体的表现日志情况，首先选择左侧菜单栏里的Visualize（可视化）： 然后点击Create a Visualization,里面既有很多种图形供你选择，有饼型，有箭头的，有文字的，有仪表盘的，如图： 我们这里先建立一个饼型的，还是上面那个台词多少的例子，首先选择shakespeare作为数据源，然后点击split slices，如图： 然后在Aggergation里选择Terms，然后在Field里选择Speaker,size那里写8,最后点击上面的那个三角播放键，看看结果： 这就很清晰的看出，亨利四世一共说了1086句话，占比11.11%。 如果我们再加一个Split Slices，这一次在原有的specker的基础上选择play_name，图象变成了一个同心圆，最外面的一层就是新增的“play_name”的情况，如图显示FALSTAFF的所有台词会在两个play_name里出现： 如果这个盘子里不想统计FALSTAFF这个话包，就添加一个过滤器，选择speaker is not，后面写上FALSTAFF即可，如图： 效仿刚才的方法也可以做一个仪表盘，如图： 可视化的数据也可以save和share，同样在web界面的右上角。保存的数据是可以在左侧菜单栏里的Dashboard里展示，做成一个类似zabbix那样的展示！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作所用的模块回滚脚本]]></title>
    <url>%2F2018%2F01%2F17%2F%E5%B7%A5%E4%BD%9C%E6%89%80%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9D%97%E5%9B%9E%E6%BB%9A%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[前言与脚本内容部署中常备一个回滚脚本也是很有必要的，我所在公司的服务器模块名都是在初始化的时候写进/etc/role_install这个文件里，如下图的这个服务器就是fss服务器： 再比如下面这个服务器，虽然包含nginx的组件但是httpproxy的服务器： 那么有了这样的前提，整个回滚的脚本内容如下： 12345678910111213141516171819202122232425262728293031#!/bin/bash#Written by ChrisChan @July-4th-2017#Desription:这是一个回滚的脚本。module=$(cat /etc/role_install |grep -v zkclient|grep -v nginx)echo -e '\033[31m现在将执行回滚操作，本次回滚只回滚普通模块，不包含nginx和zkclient!\033[0m' echo "回滚的模块名称："$moduleecho -e '\033[33m如果想取消回滚操作，请ctrl+c立即停止本脚本...\033[0m'sleep 5cd /dxpbackup/hswx/$module &amp;&amp; zip $module.zip -x "*og*" -r . #到备份的文件夹里去压缩mv /dxpbackup/hswx/$module/$module.zip /mnt/hswx echo $module".zip文件已经生成！" until [ "$decision" == "Y" -o "$decision" == "y" -o "$decision" == "N" -o "$decision" == "n" ]do read -p "请问是否用回滚的压缩包覆盖到/mnt/hswx下？(y/n)" decision echo "您的选择是："$decision if [ $decision == Y -o $decision == y ] then echo "现在已经开始覆盖..." rm -rf /mnt/hswx/$module #先把原来的内容删除 unzip /mnt/hswx/$module.zip -d /mnt/hswx/$module #重新解压缩进去 echo -e '\033[32m覆盖已经完成，可以直接执行/startall脚本!\033[0m' elif [ $decision == N -o $decision == n ] then echo -e '\033[32m生成的'$module'.zip文件保存在/root文件夹里\033[0m' else echo -e '\033[31m输入字符不符合!请重新输入!\033[0m' fidone 新的知识点！1）zip在压缩文件夹的时候要过滤掉某些文件使用“-x”参数，比如说要在AAA文件夹里面过滤掉abc和jqk这两个文件，那么语句就是zip AAA.zip -x &quot;abc&quot; -x &quot;jqk&quot; -r .或者是zip -r -x=abc -x=jqk AAA.zip . 这样两个语句。 如果你要过滤掉的是一个文件夹，比如那么就要在文件夹后面名字加上一个，下图就是要压缩整个auc文件夹为456.zip但是又不想要lib这个文件夹，就使用了`zip 456.zip -x “lib“ -r .`： 不过如果文件夹里还有其他lib开头的文件夹也会被过滤掉，这一点要注意。 2）本shell里面涉及了逻辑判断，而[[和[的区别如下图： 3）如果if语句中出现报错“[: too many arguments”，很有可能就是字符串变量中可能存在空格，shell解析时将其认为是多个参数，再进行判断时，无法知道该获取哪个值，所以最好都用双引号括起来； 4）如果是“变量a等于aa且变量b等于bb 或者 变量c等于cc且变量d等于dd ” 这样的判断句怎么写？答曰： [ $a = “aa” -a $b = “bb” ] || [$c = “cc” -a $d = “dd” ] 参考资料https://zhangge.net/4776.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible的几个基本语句]]></title>
    <url>%2F2018%2F01%2F17%2FAnsible%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[开篇的废话批处理工具我最早接触的是pssh，因为它实在很简单粗暴，但是它由于太简单粗暴了，应付十台二十台机器还OK，应付五十台一百台服务器就心有余力不足了（而且xshell右键有一个“发送键入到所有会话”的功能，与pssh效果几乎一样），而且我还不太喜欢puppet，总觉得那玩意跟我八字不合，于是乎，在新头头的推荐下，我把目光放在了Ansible。 Ansible的安装很简单，在Redhat环境下直接yum install -y ansible就行。Redhat已经将Ansible公司收购了，所以在安装上提供了不小的便利。 Ansible在安装完毕之后，会在/etc/ansible/目录下看见一个叫hosts的文件，这里是所有你要控制的服务器的ip们，可以排列写，比如： 123192.168.1.122192.168.1.133192.168.1.144 也可以分组写，比如： 1234567[aliyun]10.22.33.4410.22.33.45[jinshanyun]121.23.45.66121.23.45.67121.23.45.68:2222 （这个不是使用ssh默认的22端口，就需要特别指出） 默认情况下，Ansible会把命令全用于这个hosts文件，比如 ansible all -m ping -u ashin这句话意思是整个hosts里的机器以ashin账户启动，而且都要ping 一下当前本机。 具体语句怎么连接主机与要控制的远程机器请按之前写的“http://chenx1242.blog.51cto.com/10430133/1763978”一文进行操作，这里先说几个命令语句： 1)ansible all -m shell -a &quot;/bin/echo hello&quot;对hosts里所有的机器一起使用”输出hello这个文字”。-m shell可以忽略不写，但是不是shell而是其他的模块就要写出来； 2)ansible aliyun -m copy -a &quot;src=~/projects/tests/t.py dest=~&quot;把hosts里aliyun组的机器的/projects/tests/t.py复制到~目录下；[注意！]copy模块不支持变量路径，也就是说如果目标服务器的部署路径不同，copy不会很智能的去访问.bash_profile来得到用户的自定义变量，写变量替换路径是不会达到目的的。 3)ansible jinshanyun[0:9] -i -m file -a &quot;dest=~/tests state=absent&quot;把hosts里jinshanyun组中从0~9这十台机器的/tests文件夹删除掉，absent是“缺席，不在”的意思； 4)ansible 192.168.1.133 -m ping这句话=ping 192.168.1.133； 5)ansible v1 -m service -a &quot;name=mysql state=started&quot; -u ashin --sudo -K以用户名为ashin登陆hosts里所有v1组的机器，然后检查mysql是否是started状态，若不是就start，同时要输入root的密码作为确认； 6)ansible 10.11.22.* -m user -a &quot;name=foo password=foo&quot; --sudo -Khosts文件里所有10.11.22开头的机器，都要添加一个新的用户名foo，同时密码是foo，并且输入root密码确认身份； 7)ansible v1:!v2 -m apt -a &quot;name=git state=latest&quot;检查所有属于v1组同时还不属于v2组的机器里的git文件是否是最新版本； 8)ansible webservers:&amp;dbservers -a &quot;/sbin/reboot&quot; -f 10 --sudo -K重新启动既是webservers组又是dbservers组的所有机器； 9)ansible webservers -m raw -a &#39;yum -y install python-simplejson&#39;用ansible去链接低版本的centos时，就乎出现“ansible requires a json module, none found! ”的错误，需要远程机安装samplejson包。raw模块是靠底层ssh的通讯，不依靠python的模块，所以如果碰到低版本的系统，如果command和shell模块无法使用，可以先用这条命令安装完需要的包。 10)ansible all -m synchronize -a &quot;src=/chenshuo/1.sh dest=/chenshuo delete=yes&quot;synchronize原意是“同步”，而这个模块是分发模块，这句话的意思是把控制端的/chenshuo/1.sh分发给host文件里的所有ip服务器，delete=yes意思是以控制端服务器的文件为准。 11)ansible 10.168.194.89 -m synchronize -a &quot;mode=pull src=/chenshuo/nba.txt dest=/chenshuo/a.txt&quot;将10.168.194.89这台服务器上的/chenshuo/nba.txt拉到控制服务器的/chenshuo文件夹下，顺便改名叫a.txt。 12)ansible all -m get_url -a &quot;url=https://pypi.python.org/packages/56/2b/9c9c113fb88082950067a42cc99e3c61f1df72035f89bb0bdf0a60308ca0/pexpect-4.1.0.tar.gz#md5=562a1a21f2a60b36dfd5d906dbf0943e dest=/chenshuo&quot;把那一大串网址的下载连接下载到host文件里的所有ip的/chenshuo文件夹下。 13)ansible 10.117.14.37 -m script -a &quot;/chenshuo/free.sh&quot;在10.117.14.37上执行操作端的free.sh，注意操作端必须要有free.sh这个脚本，而10.117.14.37这台机器上并不一定要有。 参考资料http://blog.csdn.net/iloveyin/article/details/46982023]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix用户密码忘记怎么办]]></title>
    <url>%2F2018%2F01%2F17%2FZabbix%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%E5%BF%98%E8%AE%B0%E6%80%8E%E4%B9%88%E5%8A%9E%2F</url>
    <content type="text"><![CDATA[zabbix的超级用户也是人，人就难免会忘记密码（或者清除了当前浏览器的缓存），忘记密码不要怕，因为zabbix所有的用户数据都是保存在server机器上的mysql里，只要打开zabbix_server.conf，就会查得到mysql的登录账号密码以及zabbix对应的数据库。（这里多说一句，zabbix自带的guest基本就是一个废物，forget it~） 在zabbix_server机器上输入mysql的账号密码来到mysql里，USE zabbix，然后SELECT * FROM users,就会看到笔者的画面。 这个时候就可以使用数据库的update命令去更改密码，比如说新的密码是“woshitiancai”，就可以写update users set passwd=md5(&quot;woshitiancai&quot;) where userid=&#39;1&#39;;然后就可以用woshitiancai来登陆啦~ 但是！！！你以为这就结束了吗？nononono！！！ 很多人即使更改了密码还是登陆不上去，很简单，那就是你连用户名都忘记了！或者是用户名你记得但是你手贱在zabbix的administration里的users对原来的设定增加了新东西，而且这些东西还特么的是中文！！！于是就像我上面图那样出现了???的字样。 那些？？？很重要吗？当然了！！！因为那些才是zabbix的登录用户名！！！看见了吗，zabbix使用蛋疼的alias作为真正的登录名而不是用name or surname，这真是一个蛋疼的事儿！ 那么剩下的问题很简单了，就是把???改变成中文，使用语句set names utf8; 然后界面就成了这样： 这次再使用“主管理员”搭配新的密码就可以华丽的登录了！~~我他妈当时都差点要把这个user表格删掉然后重拽一个表格进来，但是终于还是被我识破了，啊哈哈哈哈，我真是个天才！！！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker出现客户端与服务端有差的错误...]]></title>
    <url>%2F2018%2F01%2F16%2FDocker%E5%87%BA%E7%8E%B0%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%9C%89%E5%B7%AE%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[今天用docker搞redis镜像的的时候，出现了这样的错误提示：Error response from daemon: client is newer than server (client API version: 1.24, server API version: 1.22)，如图： 可见使用了docker version的时候也有提示：当前docker客户端比服务端版本更新。这样是无法创建镜像的，遇到这个问题很简单，那就是重启一下docker，命令如下： 12systemctl stop dockersystemctl start docker 然后我们再docker version看一下效果： 我做这个的时候，docker升级了也一样可以读到原先的镜像，但是出于保险起见我们也应该学会如何保存和导入镜像，比如现在我现在有这个叫docker.io/ubuntu的镜像，如图： 如果要备份它的话，语句就是： 1docker save docker.io/ubuntu &gt; /root/ubuntu.image 这里备份后的文件名就是ubuntu.image。 如果要导入的话，语句就是： 1docker load &lt; /root/ubuntu.image 这样导入的话，images create时间是不变的。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录日志系统ELKB 5.6.4的搭建过程]]></title>
    <url>%2F2018%2F01%2F16%2F%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9FELKB-5-6-4%E7%9A%84%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言ELK是最近比较流行的免费的日志系统解决方案，注意，ELK不是一个软件名，而是一个结局方案的缩写，即Elasticsearch+Logstash+Kibana（ELK Stack）。这哥几个都是java系的产品，但是众所周知，java的东西很吃内存和CPU，Logstash在当作为收集日志的Agent时，就显得太过臃肿了。听说直播平台“斗鱼”团队很为logstash占用资源的情况很而苦恼，后来为了解决这个问题，他们自己写了一个agent。不过后来官方在logstash-forwarder的基础上推出了beat系列，里面包括四个兄弟，分别是：Packetbeat（搜集网络流量数据）；Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）；Filebeat（搜集文件数据）；Winlogbeat（搜集 Windows 事件日志数据）。而Filebeat也就这样加入了“日志收集分析”的团队里，所以虽然大家还是习惯性的叫ELK，其实准确的说法已经是ELKB了。 ELKB这几个哥们的分工如下： Elasticsearch：分布式搜索和分析引擎，具有高可伸缩、高可靠和易管理等特点。基于 Apache Lucene 构建，能对大容量的数据进行接近实时的存储、搜索和分析操作。通常被用作某些应用的基础搜索引擎，使其具有复杂的搜索功能； Logstash：数据收集额外处理和数据引擎。它支持动态的从各种数据源搜集数据，并对数据进行过滤、分析、丰富、统一格式等操作，然后存储到用户指定的位置； Kibana：数据分析和可视化平台。通常与 Elasticsearch 配合使用，对其中数据进行搜索、分析和以统计图表的方式展示； Filebeat：ELK 协议栈的新成员，在需要采集日志数据的 server 上安装 Filebeat，并指定日志目录或日志文件后，Filebeat 就能读取数据，迅速发送到 Logstash 进行解析，亦或直接发送到 Elasticsearch 进行集中式存储和分析。 设计架构 本文的设计结构就是这样，其中红色的redis/RebbitMQ部分可以省略（我这个例子里暂省略），让日志直接传递到logstash，如果日志量较大，最好还是添加上redis，同时再横向扩容Elasticsearch，搞成一个集群。 对于这几个模块服务器多说几句：1）Logstash要选择计算能力强的，CPU和内存比较丰满的；2）Elasticsearch要选择磁盘容量大的，同时CPU和内存也比较丰满的； 实验软件版本Elasticsearch 5.6.4Logstash 5.6.4Kibana 5.6.4Filebeat 5.6.4Java 1.8+，安装方法：http://blog.51cto.com/chenx1242/2043924由于ELKB这几个东西都是墙外的，墙内的下载可能会比较费劲。所以我稍后会把所有ELKB的5.6.4程序都放在51CTO的存储空间里，需要的朋友可以去下载，还是那话，虽然ELK升级频率很快，但是5.6.4已经足够稳定了。 实验服务器情况 安装Elasticsearch 5.6.4（以下所有操作都是root下进行的）12curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.4.rpmrpm -ivh elasticsearch-5.6.4.rpm 然后编辑/etc/elasticsearch/elasticsearch.yml，不然的话logstash无法与之相连： 123cluster.name: my-application #如果是集群的es就把这个打开，Elasticsearch 启动时会根据配置文件中设置的集群名字（cluster.name）自动查找并加入集群，端口是9300network.host: 0.0.0.0 #取消注释，并且改成0.0.0.0http.port: 9200 #取消注释 保存之后，启动并且添加开机启动： 12systemctl start elasticsearch systemctl enable elasticsearch 使用curl localhost:9200能看到这样的情景就证明已经成功启动了： 安装kibana 5.6.4 (以下所有操作都是root下进行的)1234curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-5.6.4-linux-x86_64.tar.gztar xzvf kibana-5.6.4-linux-x86_64.tar.gzcd kibana-5.6.4-linux-x86_64/vim config/kibana.yml 把kibana.yml里的server.host: localhost改成server.host: 0.0.0.0，然后保存退出，在kibana的bin文件夹里执行./kibana即可。如果要后台启动就是nohup /kibana安装路径/bin/kibana &amp;。 启动之后，如图： 安装Logstash 5.6.4（以下所有操作都是root下进行的）12curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-5.6.4.rpm rpm -ivh logstash-5.6.4.rpm 如果安装的时候爆错：/usr/share/logstash/vendor/jruby/bin/jruby: line 388: /usr/bin/java: No such file or directory。那么就先which java查看一下java的文件，然后做一个软连接过去，然后重装logstash即可，如图： 用户可以使用TLS双向认证加密Filebeat和Logstash的连接，保证Filebeat只向可信的Logstash发送加密的数据（如果你的logstash和filebeat是内网通信，而且你认可当前内网的安全度，这一步可以省略）。同样的，Logstash也只接收可信的Filebeat发送的数据。这个功能默认是关闭的，要开启的话需要先vim /etc/pki/tls/openssl.cnf，如图： 找到[ v3_ca ]的字段，在底下添加subjectAltName = IP:logstash的内网IP字段，保存退出来到/etc/pki/tls/，执行下面命令： 1openssl req -x509 -days 365 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt 来生成一个期限为365天的IP SAN证书对，如果想生成一个十年的证书，就把365改成3650即可，如图： 安装完毕之后，vim /etc/logstash/logstash.yml，编辑成如下的样子： 然后在/etc/logstash/下手动建立一个目录conf.d，在conf.d里新建一个logstash.conf的文件，如下： 123456789101112131415161718192021222324252627282930313233343536373839$ cat /usr/local/logstash/config/conf.d/logstash.conf#在输入部分，配置Logstash通信端口以及添加SSL证书，从而进行安全通信。input &#123; beats &#123; port =&gt; 5044 ssl =&gt; true ssl_certificate =&gt; "/etc/pki/tls/certs/logstash-forwarder.crt" ssl_key =&gt; "/etc/pki/tls/private/logstash-forwarder.key" &#125;&#125; #在过滤器部分，我们将使用Grok来解析这些日志，然后将其发送到Elasticsearch。以下grok过滤器将查找“syslog”标记的日志，并尝试解析它们，以生成结构化索引。filter &#123; if [type] == "syslog" &#123; grok &#123; match =&gt; &#123; "message" =&gt; "%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;" &#125; add_field =&gt; [ "received_at", "%&#123;@timestamp&#125;" ] add_field =&gt; [ "received_from", "%&#123;host&#125;" ] &#125; syslog_pri &#123; &#125; date &#123; match =&gt; [ "syslog_timestamp", "MMM d HH:mm:ss", "MMM dd HH:mm:ss" ] &#125; &#125;&#125; #输出部分，我们将定义要存储的日志位置output &#123; elasticsearch &#123; hosts =&gt; [ "10.162.80.192:9200" ] #这个地址是elasticsearch的内网地址 index =&gt; "filebeat-%&#123;+YYYY.MM.dd&#125;" #设定这个是索引 #index =&gt; "auclogstash-%&#123;+YYYY.MM.dd&#125;" #这行是后来作实验的，可以忽视 user =&gt; elastic #这个是为了将来装x-pack准备的 password =&gt; changeme #同上 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 然后就是启动并且添加开机自启动: 12systemctl start logstash systemctl enable logstash 安装filebeat（以下所有操作都是root下进行的）在模块服务器上安装filebeat的方法如下: 12curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.4-x86_64.rpm rpm -ivh filebeat-5.6.4-x86_64.rpm 之前在logstash上生成了一个IP SAN证书，现在需要把这个证书传递给filebeat的机器里，使用scp语句如下： 1scp -pr root@10.162.80.171:/etc/pki/tls/certs/logstash-forwarder.crt /etc/ssl/certs/ #10.162.80.171就是logstash的内网IP 输入logstash的密码，并且密钥文件复制完毕之后，需要修改filebeat.yml，于是#vim /etc/filebeat/filebeat.yml： 12345678910111213141516[root@func-auc-001 log]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /mnt/hswx/auc/logs/*.log #这个是那个auc模块的路径 - /第二个日志路径/*.log #如果有第二个文件路径的话 tail_files: true #从文件末尾开始读取 document_type: "newnginx-api" #logstash那里已经设定了index，如果要使用了document_type，那么在logstash的index就要这么写："%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;" # 以下是规避数据热点的优化参数： spool_size: 1024 # 积累1024条消息才上报 idle_timeout: "5s" # 空闲5s上报 output.logstash: hosts: ["10.162.80.171:5044"] #这个地方要写logstash的内网地址 ssl.certificate_authorities: ["/etc/ssl/certs/logstash-forwarder.crt"] #这里就是刚刚复制的那个密钥文件路径 #注意上面是ssl而不是tls，1.0版本才是tls，如果这个写错了，启动的时候会出现“read: connection reset by peer”的错误 注意！Filebeat的配置文件采用YAML格式，这意味着缩进非常重要！请务必使用与这些说明相同数量的空格。 保存之后，使用/etc/init.d/filebeat start启动filebeat，如图： 故障解决ELK几个部件现在都已经启动了，并且互相telnet端口都是通的，在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;却出现这样的情况： 而使用tailf /var/log/filebeat/filebeat去查看filebeat的日志是这样的： 再看看logstash-plain.log，里面的情况是这样的： 从此可见，filebeat与logstash的联系是error状态，那么停止filebeat的进程，改用/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml，重新在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;发现已经成功读到了我们之前配置的目录“/mng/hswx/auc/log”，如图： 配置kibana在浏览器输入kibana服务器外网IP：5601打开kibana的web界面，把idenx pattern的地方改成filebeat-*(同之前配置的index索引一致)，然后点击create，如图： 然后就得到了细节的web界面，如图： 点击左侧框的Discover，就会看到梦寐以求的日志web界面，如图： 看一下红色框的内容里面有时间，有host主机，有source来源，还有具体的日志信息，我们再去func-auc-001这个日志源主机上查询一下日志： 两个日志是一样的，可见实现了预期的日志展示的目标！ 最后一步，就是把kibana与nginx联系起来（也可以把kibana做阿里云负载均衡的后端服务器），这样通过nginx/负载均衡来访问kibana的界面，对kibana来说更安全。配置端口监听如图，再把kibana服务器挂在负载均衡后面即可。 参考资料https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.htmlhttps://www.ibm.com/developerworks/cn/opensource/os-cn-elk/http://www.jinsk.vip/2017/05/24/elksetup/https://renwole.com/archives/661https://www.zybuluo.com/dume2007/note/665868https://www.elastic.co/guide/en/beats/libbeat/5.6/getting-started.htmlhttps://discuss.elastic.co/search?q=ERR%20Failed%20to%20publish%20events%20caused%20by%3A%20read%20tcphttp://jaminzhang.github.io/elk/ELK-config-and-use-Filebeat/ （这个博主很好，但是就是博客无法留言，这点比较坑）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大数据分析</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从“No space left on device”到删除海量文件]]></title>
    <url>%2F2018%2F01%2F16%2F%E4%BB%8E%E2%80%9CNo-space-left-on-device%E2%80%9D%E5%88%B0%E5%88%A0%E9%99%A4%E6%B5%B7%E9%87%8F%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[开发发现某个云服务器无法启动进程，提示“No space left on device”，但是使用df -h查看容量的时候，明明还有很多的空间。于是使用df -i，发现inode节点已经全部用光了，所以现在不能建立任何新的文件。如图： 既然如此就要查出来是哪个文件夹里会有如此多的文件来占用这些inode,使用一个小脚本：for i in /*; do echo $i; find $i | wc -l; done，获取到/mnt下有一个文件占用了绝大多数的inode，如图： 于是就进入到mnt这个文件夹里，慢慢找寻到底是哪个文件夹，用上面那个语句一点一点缩小范围，最后确定文件夹原来就是data文件夹，如图： 现在如果要rm -rf data/*的话，是没有效果的，有效果的话也很慢。而且很有可能报-bash: /bin/rm: Argument list too long的错，因为这个文件夹里面的小文件实在太多了，有足足两百五十多万个，那么怎么样处理这样的情况？ 用find搭配-type f -exec rm {} \;可能会引起内存溢出，用文件夹重置命令搭配”–reference” 也没什么效果。 这时最好的方法就是使用rsync! 先yum install rsync，当然了现在inode是饱和的状态，yum install是会报错的： 那么就需要手动删除一些文件，腾出来一部分inode供yum使用，安装完毕rsync之后，找到一个空文件夹，如果没有空文件夹，就手动建立一个。 使用命令：rsync --delete-before -a -H -v --progress --stats /空文件夹的路径/ /海量小文件的路径/ –delete-before 接收者在传输之前进行删除操作 –progress 在传输时显示传输过程 -a 归档模式，表示以递归方式传输文件，并保持所有文件属性 -H 保持硬连接的文件 -v 详细输出模式 -stats 给出某些文件的传输状态 如果你开了这个服务器的两个窗口，一个是执行上面的命令，另一个是在海量文件夹里执行ls，这个时候ls命令是卡死的，过了大约2分钟，就会看到ls展示的文件喷涌而出，整个电脑屏幕好比黑客帝国一样，异常壮观。 静等大约20分钟，整个文件夹删除干净，inode也释放了97%，世界恢复了清静。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Google Authenticator给ssh进行登录验证]]></title>
    <url>%2F2018%2F01%2F16%2F%E4%BD%BF%E7%94%A8Google-Authenticator%E7%BB%99ssh%E8%BF%9B%E8%A1%8C%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[普通情况下的服务器登录，是“服务器+密码”这种直白的验证方式，但是这种方式太过简单，一旦密码泄露，服务器就有危险，于是为了安全我们就要在登录上再加一把锁，那就是使用Google Authenticator（谷歌身份验证器）这个工具，在登录的时候进行一次验证，只有“验证通过了”+“密码正确”才能登陆服务器。 安装前准备1）关闭Selinux ：setenforce 02）安装依赖：yum -y install gcc make pam-devel libpng-devel libtool wget git3）添加阿里云epel 源： 1234RHEL 6/Centos 6wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repoRHEL 7/Centos 7wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 4）安装Qrencode，谷歌身份验证器需要调用该程序生成二维码并显示：yum install -y qrencode 安装谷歌身份验证器这个时候很多教程会让你去执行git clone https://github.com/google/google-authenticator.git，然而现在这个git里面已经不再含有libpam这个文件夹了，下载下来是一个错误的包，那么这个时候你可以使用yum install google-authenticator，不过yum安装的身份验证器的版本很老，这个时候可以执行wget https://github.com/google/google-authenticator-libpam/archive/1.04.tar.gz。 下载下来1.0.4版本的然后拆包解压缩，里面是这样几个文件： 然后就./bootstrap.sh &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install进行编译和安装。 安装过程完毕之后，还要复制google身份验证器pam模块到系统下，命令是：cp /usr/local/lib/security/pam_google_authenticator.so /lib64/security/。 调整登陆方式1）编辑/etc/pam.d/sshd这个文件，我这个centos的版本是7.0的，里面的内容可能跟centos 6.x的优点不同，不过没关系，就需要插入黄色框内的auth required pam_google_authenticator.so，如图： 修改完毕之后，保存退出。 注意！修改了这步之后，服务器千万不能断开连接，否则再连是需要google验证码的，而我们现在还没有生成码，所以肯定是无法连接服务器，如果是云服务器，可以通过登陆控制台的方式把这个文件修改回来，如果是实体服务器，那就呵呵呵了。 2）编辑/etc/ssh/sshd_config，就修改一个地方：ChallengeResponseAuthentication yes3）保存退出之后，重启一下ssh服务： 12RHEL6 /Centos6：Service sshd restartRHEL7 /Centos7：Systemctl resart sshd 生成登陆验证码这次以root用户为例，那么切换成root用户执行下面的过程。1）执行google-authenticator，由于我们之前已经安装了qrencode，那么这个时候会生成一个超级超级巨大的二维码，给各位感受一下： 红色内容是生成的密钥，很重要。绿色的内容是备用的紧急救助码，紧急救助码就是当你无法获取认证码时（比如手机丢了），可以当做认证码来用，每用一个少一个，但其实可以手动添加的，建议如果 root 账户使用 Google Authenticator 的话一定要把紧急救助码另外保存一份。 Do you want me to update your &quot;/home/test/.google_authenticator&quot; file? (y/n) y 是否更新用户的 Google Authenticator 配置文件，选择 y 才能使上面操作对当前用户生效，其实就是在对应用户的 Home 目录下生成了一个 .google_authenticator 文件，如果你想停用这个用户的 Google Authenticator 验证，只需要删除这个用户 Home 目录下的 .google_authenticator 文件就可以了。 Do you want to disallow multiple uses of the same authentication token? This restricts you to one login about every 30s, but it increases your chances to notice or even prevent man-in-the-middle attacks (y/n) y 每次生成的认证码是否同时只允许一个人使用？这里选择 y。 By default, tokens are good for 30 seconds. In order to compensate for possible time-skew between the client and the server, we allow an extra token before and after the current time. If you experience problems with poor time synchronization, you can increase the window from its default size of +-1min (window size of 3) to about +-4min (window size of 17 acceptable tokens). Do you want to do so? (y/n) n 是否增加时间误差？这里随便选择， ny都可以。 If the computer that you are logging into isn&apos;t hardened against brute-force login attempts, you can enable rate-limiting for the authentication module. By default, this limits attackers to no more than 3 login attempts every 30s. Do you want to enable rate-limiting (y/n) y 是否启用次数限制？这里选择 y，默认每 30 秒最多尝试登录 3 次。 如果想要写成脚本的话，那么上面交互式的设置也可用通过参数一次性设置：google-authenticator -t -f -d -l test@chen.super -i MR.chen -r 3 -R 30 -W。 -I和-i是可以随便写的，但是-i后期可以改，-I不能改。 搭配手机端如果手机是ios，就去apple store里搜索“Google Authenticator”，如果是安卓，就去应用商店搜索“谷歌动态口令”。 安装完后，打开App，点击“开始设置”，选择“扫描条形码”扫描上面google-authenticator命令生成的二维码，或者是选择“输入密钥”，然后手机上就能看到对应的六位数认证码了。 最后一步，返回xshell，修改登陆方式，设置登陆方法为Keyboard Interactive，如图： 这个时候，推荐各位保留原有的ssh不要动，在另外一个xshell窗口登陆一下看看效果，如果正常的话，这个时候会看到系统会让你先输入一个Verification code。这个值就是手机里的那个六位数，然后再输入密码，只有两个都是正确的，才能登陆！ 至此整个配置完成，如果登陆时遇到问题，请查看日志文件/var/log/secure。 更改存储位置在生成二维码那一步的时候，如果你错过了记住密钥也不要怕，系统会自动把密钥和紧急救助码保存在~/.google_authenticator这个文件里。 如果想要改变密钥存储位置，请使用–secret参数:google-authenticator --secret=&quot;/文件路径/用户名&quot;。 然后更改/etc/pam.d/sshd内的路径配置:auth required pam_google_authenticator.so user=root secret=/PATH_FOLDER/${USER}。 上面那句话里“user=root” 用于强制PAM使用root用户权限来搜索文件。 另外请注意，由于我们当时切换成了root用户，所以密钥文件的所有者是root，生成文件的用户只能读取文件(chmod: 400)： 12chown root.root /PATH_FILE/SECRET_KEY_FILESchmod 400 /PATH_FILE/SECRET_KEY_FILES]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次处理https监听不正确的过程]]></title>
    <url>%2F2018%2F01%2F12%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%A4%84%E7%90%86https%E7%9B%91%E5%90%AC%E4%B8%8D%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[今天开发反馈在测试金山云设备的时候遇到了这样的一个现象：123456wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 11:49:26-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 Resolving funchlscdn.lechange.cn... 120.92.158.134 Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected. OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol Unable to establish SSL connection. 爆“error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol”的错误，就是在当向只提供http的服务发送https请求造成的。 ping funchlscdn.lechange.cn，获得了这个域名对应的IP之后，返回到金山云的控制台查询这个IP，发现这个IP是一个负载均衡，但是这个负载均衡配置的时候对80端口是http协议，而对443端口还是http协议，于是更改成https，重新测试之后，发现错误变成了这样：123456[root@js-develop ~]# wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 16:08:15-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected.HTTP request sent, awaiting response... 502 Bad Gateway2017-07-26 16:08:15 ERROR 502: Bad Gateway. 在浏览器打开效果如图： 502 Bad GatewayThe proxy server received an invalid response from an upstream server. KSYUN ELB 1.0.0 同时发现金山云负载均衡里对nginx的8000健康检查是“异常”。但是使用http访问却是可以的，效果如下：12345678910111213[root@js-develop ~]# wget http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 15:31:55-- http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:80... connected.HTTP request sent, awaiting response... 302 FoundLocation: http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 [following]--2017-07-26 15:31:55-- http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Connecting to 120.92.133.76:8090... connected.HTTP request sent, awaiting response... 200 OKLength: 66 [application/x-mpegURL]Saving to: “dev_20170726085033_lpxh73ezzb92xxa8.m3u8”100%[========================================================================================================================================================&gt;] 66 --.-K/s in 0s 2017-07-26 15:31:55 (3.02 MB/s) - “dev_20170726085033_lpxh73ezzb92xxa8.m3u8” saved [66/66] 于是就叫来开发问一下http和https详细的流程，开发说在http里，设计路线如下：1http(80)-&gt;开发模块(9001) 而在https里，设计路线如下：1https(443)-&gt;nginx(8000)-&gt;开发模块(9001) 这时候就发现了问题，原来最早的时候金山云是没有配置https证书的，于是开发们就用nginx的8000端口去监听ssl这样达到https证书的效果，但是后来金山云控制台添加了https证书，就不再需要nginx去配置ssl证书了，再去https监听8000这一步也就是错误的了，于是在负载均衡那里改成了：1https(443)-&gt;开发模块(9001) 同时关闭了nginx，这时候再来测试一下https请求，就成功了！ 其实如果非要用nginx的ssl证书的话，那么的套路就是：开启nginx，但是在负载均衡那里使用tcp协议去监听nginx的8000端口，这样一样能达到效果。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Next主题添加音乐和将侧栏移动到左边]]></title>
    <url>%2F2018%2F01%2F12%2Fnext%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9F%B3%E4%B9%90%E5%92%8C%E4%BE%A7%E6%A0%8F%E5%B7%A6%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[玩Github博客也有一个多月的时间了，现在这个博客也被我折腾的有点样子了，目前博客里添加了如下功能：1.支持头像图片旋转，同时点击头像可以返回主页；2.背景图片随机出现，而且墙内用户也可以顺利访问；3.增加文章打分系统，觉得好可以给五星好评；4.开放评论系统，无需注册直接评论；5.添加了可视加载栏和公益404页面；6.添加桌面小宠物和访客统计；7.添加博客运行时间和代码橙色高亮； 目前欠缺的功能一个是“相册”，还有一个就是博客标题的加载方式希望更加高逼格。至于SEO和单独域名，我暂时还没有想去做，等将来再加上吧。而这篇文章里主要说的就是“博客添加音乐”和“侧栏左移”这两个事儿。 博客添加音乐Next主题添加网易云音乐不是一个很难的事儿，但是我发现对于非大陆的IP地址（比如我用的是公司VPN，香港IP），侧栏的网易云音乐就无法播放，而且打开博客页面就自动播放音乐这点对来访的用户来说，体验感觉是见仁见智。所以我打算把侧栏的网易云音乐撤掉，在“关于我”里单独放进音乐歌单。 若单独配置音乐同时不想被IP地址打扰的话可以使用由DIYgod所制作的APlayer。官方材料在这里：https://aplayer.js.org/docs/#/?id=options 。 要使用APlayer需要先在hexo根目录里安装插件：npm install aplayer --save 安装插件OK了后，具体在文章里添加的语法就是： 注意：如果lrc用的是这种URL形式，hexo g时请保持网络通畅，如果没有歌词，可以不用添加。 现在的世面上很少有在线提供歌曲MP3地址的网站了，很多都是下载mp3到本地，这里我推荐一个免费下载MP3的网站：https://www.tikitiki.cn 。里面有QQ音乐、网易云音乐和酷狗的资源，基本上大陆没有被封杀的艺人作品都能在里面找到（抱歉了，陈升先生和黄耀明先生）。然后再搭配七牛云，把下载的MP3和封面图片上传到七牛云存储里，然后搭配提供的外网域名就可以填写MP3地址和封面地址了。如图： 如果想做一个歌单，也很简单，如下：1234567891011121314151617181920212223&#123;% aplayerlist %&#125; &#123; "autoplay": false, "showlrc": 3, "mutex": true, "music": [ &#123; "title": "歌曲名", "author": "歌手名", "url": "https://具体地址.mp3", "pic": "https://封面图.jpg", "lrc": "https://歌词.lrc" #不愿意加歌词可以不写，注意逗号 &#125;, &#123; "title": "歌曲名", "author": "歌手名", "url": "https://具体地址.mp3", "pic": "https://封面图.jpg", "lrc": "https://歌词.lrc" &#125; ] &#125;&#123;% endaplayerlist %&#125; 不过我这个七牛云的账号比较挫，没有做https，只好用http了… 把侧栏移动到左边博客自从安装了宠物之后，发现小宠物与侧栏重叠，看上去感觉很不友好，但是很奇怪，默认的宠物即使调整了botton依旧无法移动，所以我就想那就把整个侧栏移动到了左边，但是发现更改next主题的_config.xml里的“sidebar的position属性”发现并没有效果，后来经过一顿查找，找到了改成左侧栏的方法(适用于next 5.1.3版本)。 首先，先更改\themes\next\source\css\_common\components\sidebar\sidebar.styl，把第三行的right改成left,如下：123.sidebar &#123; position: fixed; left: 0; 保存之后，打开\themes\next\source\js\src\motion.js，把101行和167行的paddingRight全改成paddingLeft,同时找到类似如下的代码，并替换成如下代码:123456789101112131415161718192021var sidebarToggleLine1st = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-first', status: &#123; arrow: &#123;width: '50%', rotateZ: '45deg', top: '2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '45deg', top: '5px', left: 0&#125; &#125;&#125;);var sidebarToggleLine2nd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-middle', status: &#123; arrow: &#123;width: '90%'&#125;, close: &#123;opacity: 0&#125; &#125;&#125;);var sidebarToggleLine3rd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-last', status: &#123; arrow: &#123;width: '50%', rotateZ: '-45deg', top: '-2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '-45deg', top: '-5px', left: 0&#125; &#125;&#125;); 保存完毕之后，hexo clean和hexo d -g。刷新一下页面，就大功告成了！ 参考资料https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html#hcm=1515719347596232 （这篇文章强烈推荐！）http://www.lmnsyunhao.cn/2017/03/29/hexo-next-themes-left-sidebar/http://mashirosorata.vicp.io/HEXO-NEXT主题个性化配置.html]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>博客美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix监控ActiveMQ队列数以及结合Grafana展示]]></title>
    <url>%2F2018%2F01%2F11%2FZabbix%E7%9B%91%E6%8E%A7ActiveMQ%E9%98%9F%E5%88%97%E6%95%B0%E4%BB%A5%E5%8F%8A%E7%BB%93%E5%90%88Grafana%E5%B1%95%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[在ZABBIX上监控MQ队列众所周知，Zabbix是可以自定义监控项的，那么就代表只要能获得到的数字都可以进入Zabbix的监控范围内。作为消息队列，Activemq里的“消息堆积数”是监控的重点项目之一。 获取消息堆积数并不是一个很难的事儿，浏览器里登陆MQ的web网页控制台，输入账号密码之后，在Queues的网页里就能看到如下的界面： 其中Pending Messages就是“等待消息”，Consumers是“消费者”，Enqueued是“入队”，Dequeued是“出队”。入队数=出队数+等待数。 现在我们要获取到图中的队列叫AggregateQueue里的那个23596，很简单，shell语句是： 1curl -s -u网站用户名:网站密码 http://网站外网IP地址:8161/admin/queues.jsp | grep -A 5 "具体的队列名&lt;/a&gt;&lt;/td&gt;"|awk -F '&lt;' '&#123;print $2&#125;'|sed 's/td&gt;//g'|head -2|tail -1 这里curl有一个-s的参数，不然会显示curl的状态。如图： 语句在此，写脚本就很easy了。不过我这里就直接监控具体数字了，没有写脚本，如果要写python脚本的话，我推荐各位移步：http://blog.51cto.com/sfzhang88/1316789 ，看一下这篇文章。 现在把这个监控项添加到具体的zabbix_agentd.conf里吧，具体添加过程可以参看 http://blog.51cto.com/chenx1242/1839829 ，由于是curl网站，那么直接把这个监控项加到Zabbix-server里就好，然后使用zabbix_get检查一下。有的zabbix 3.x里没有zabbix_get，安装zabbix_get方法：yum install zabbix-get.x86_64。 zabbix_get检查情况和具体的trigger情况如下： 配置Zabbix结合Grafana我使用的Grafana版本是4.3.2，下载地址：https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.3.2-1.x86_64.rpm ，下载完毕之后，直接yum install /路径/grafana-4.3.2-1.x86_64.rpm，由于Grafana使用的是AWS的云存储，可能在墙内的下载会比较吃力，有断开的情况就多试几次。话说Grafana的升级是比较频繁的，半年不到的时间升级了三次，现在最新版本已经是4.6.2。所以说这玩意，其实选择一个稳定的就好。 启动grafana的方法就是：systemctl start grafana-server.service，配置开机自启动的方法：chkconfig grafana-server on。然后在浏览器里输入grafana外网ip地址：3000就能看到grafana的界面，默认密码：admin/admin，grafana默认的日志存储路径是/var/log/grafana/。 Grafana与ZABBIX联系的插件下载方式：grafana-cli plugins install alexanderzobnin-zabbix-app，安装之后，重启一下grafana-server，在web界面就会看到插件已经成功安装，如图： 其他更多的插件下载可以在grafana的官方网站查看到：https://grafana.com/plugins ，用grafana-cli都能搞定，还是那话，墙里的同学速度要慢一点。 现在配置Zabbix作为Grafana的数据源，首选点击网站上面的红色漩涡标志，选择zabbix，点击Plugin Config，点击Enable，启动Zabbix插件。如图： 再次点击红色漩涡，这次选择Data Sources，点击Add data source，如果插件启动成功，那么在Type里是可以选择zabbix的，然后就是填各种东西，如图： 这里有一些要额外说明：1）url这个是zabbix的API地址http://ip/zabbix/api_jsonrpc.php，这个可以在zabbix服务端上可查找find / -name api_*.php；2）username和passwd是zabbix WEB界面的登录用户名和密码，有读的权限即可；3）alerting选择启动，min severity选择high； 然后点击save &amp; test，如果都正确的话，就会出现success，如图： 在Grafana展示趋势图点击左上方红色漩涡，Dashboards的地方点击+new，然后在小齿轮的地方选择Templating,如图： 在Templating里要建立4个模板，其中group的添加方法如下，如果Query正确的话，在点击Include All option的时候，就会有“组”显示出，而且和zabbix里完全一致： group添加完了，还有host、application、iteams，添加的大同小异，需要注意的是Query的不同：host的Query：$group.*application的Query: $group.$host.*iterm的Query:$group.$host.$application.* 以上四个template都搞定之后，应该是这个样子： 模板搞定了，下面就是图形展示，选择对应的hosts、application和items就自动有图像生成了！ 最后说一下页面自动刷新，点击右上角“Last 6 hours”, 在弹出的下拉框中，选择Time range下的Refreshing every选项，点击下拉框按钮，默认应该有“off”和“1m”两个选项。点击“1m” 然后Apply设置，即为每一分钟刷新一次数据的意思。设置成功后，在原来Last 6 hours的后面会出现Refresh every 1m的橙色文字！ 参考资料《实践MQ的小demo》http://www.jianshu.com/p/3a39c8dd4f29]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Python使用yaml的几个例子]]></title>
    <url>%2F2018%2F01%2F11%2F%E5%9C%A8Python%E4%BD%BF%E7%94%A8yaml%E7%9A%84%E5%87%A0%E4%B8%AA%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[python版本：2.7.5安装方法：pip install PyYaml “把变量写进yaml做配置文件，然后python脚本从yaml文件里面取到变量”的方法最近是在python编程里比较流行的配置项方法。yaml更加易读，而且通过缩进表示结构，这一点与python不谋而合。 Yaml有四个比较常用的用法，分别是load()、dump()、load_all()、dump_all()。这篇文章主要就是了解一下这四个方法。 首先我们先写一个很简单的test.py： 12345678910111213# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_str = """name: Gakkiage: 29job: Actressrelationship: Wife""" aaa = yaml.load(yaml_str)print aaa 执行的话，看到的效果就是： 12[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 这个aaa的类型是一个字典（dict），如果要得到里面那个”Gakki”，那么就是aaa[‘name’]。通过load方法，一个字符串变成了一个字典。 现在把test.py换成如下： 123456789101112# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_dict = &#123;"name": "Gakki", "age": 29, "job": "Actress", "relationship": "Wife" &#125;aaa = yaml.dump(yaml_dict, default_flow_style=False)print aaaprint (type(aaa)) 执行后的效果如下： 123456[root@paas-online-crs-001 chentest]# python test.py age: 29job: Actressname: Gakkirelationship: Wife&lt;type 'str'&gt; 可见，通过dump方法，把一个dict变成了一个字符串。 现在写一个配置文件，假如它叫test.yaml: 1234- Gakki- 29 - Actress- Wife 再来一个test.py，内容如下: 1234567# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yaml aaa = yaml.load(file('test.yaml', 'r'))print aaaprint (type(aaa)) 执行这个test.py： 123[root@paas-online-crs-001 chentest]# python test.py ['Gakki', 29, 'Actress', 'Wife']&lt;type 'list'&gt; #得到了一个列表 如果把那个test.yaml升级成字典和列表的混合结构，如下： 1234567- name: Chris age: 29 job: OM Engineer- name: Gakki age: 29 job: Actress relationship: Wife 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py [&#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;, &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125;]&lt;type 'list'&gt; 既然获得的结果是一个包含字典的列表，那么如果要获得“Gakki”就是aaa[1][‘name’] 如果想要复制和引用，那么要用&amp;和*，比如把test.yaml改成这样： 12name: &amp;name Gakkiwife: *name 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'name': 'Gakki', 'wife': 'Gakki'&#125;&lt;type 'dict'&gt; 在同一个yaml文件中，可以用 — 来分段，这样可以将多个文档写在一个文件中： 123456789--- name: Chris age: 29 job: OM Engineer--- name: Gakki age: 29 job: Actress relationship: Wife 再写一个新的test.py如下: 123456# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlys = yaml.load_all(file('gakki.yaml', 'r')) #load_all() 方法会生成一个迭代器，可以用for输出出来for y in ys: print y 执行这个py的效果： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;&#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 参考文档：https://huilansame.github.io/huilansame.github.io/archivers/recommond-case-file-type-yaml]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Zabbix去监控Redis]]></title>
    <url>%2F2018%2F01%2F10%2F%E4%BD%BF%E7%94%A8Zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7Redis%2F</url>
    <content type="text"><![CDATA[了解Redis的info要获得Redis的当前情况，使用info命令即可。具体用法：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info [参数] 。针对不同的参数就会看到具体的数字，如果没有带参数，那么就会把默认情况写出来，如果带上all参数，那么就会把所有情况都写出来。比如：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info server，就会看到redis关于server的一些数据，如下：可以看出，从server里可以查询到的是版本号、pid号、配置文件路径等等东西。 如果参数是client，记录了是客户端的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info clients# Clientsconnected_clients:64 #已连接客户端的数量（不包括通过从属服务器连接的客户端）client_longest_output_list:0 #当前连接的客户端当中，最长的输出列表client_biggest_input_buf:0 #当前连接的客户端当中，最大输入缓存blocked_clients:0 #正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 如果参数是memory，记录的是内存的相关信息： 12345678910[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info memory# Memoryused_memory:2252984 #由 Redis 分配器分配的内存总量，以字节（byte）为单位used_memory_human:2.15M #上面的数字加上了单位used_memory_rss:9293824 #常驻集大小，即Redis已分配的内存总量。这个值和top、ps等命令的输出一致used_memory_peak:2607520 #Redis 的内存消耗峰值（以字节为单位）used_memory_peak_human:2.49M #上面的数字加上了单位used_memory_lua:33792 #Lua 引擎所使用的内存大小（以字节为单位）mem_fragmentation_ratio:4.13 #used_memory_rss 和 used_memory 之间的比率mem_allocator:jemalloc-3.2.0 #在编译时指定的，Redis所使用的内存分配器。可以是libc、jemalloc或者tcmalloc。 这里要注意！在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿（我这个机器就已经属于严重的级别了）。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。 如果参数是stats，那就是统计的相关信息： 12345678910111213141516[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info stats# Statstotal_connections_received:150383 #服务器已接受的连接请求数量total_commands_processed:500935 #服务器已执行的命令数量instantaneous_ops_per_sec:0 #服务器每秒钟执行的命令数量rejected_connections:0 #因为最大客户端数量限制而被拒绝的连接请求数量sync_full:0 sync_partial_ok:0 sync_partial_err:0 #查找数据库键成功的次数expired_keys:41 #因为过期而被自动删除的数据库键数量evicted_keys:0 #因为最大内存容量限制而被驱逐（evict）的键数量keyspace_hits:78121 #查找数据库键成功的次数keyspace_misses:56 #查找数据库键失败的次数pubsub_channels:0 #目前被订阅的频道数量pubsub_patterns:0 #目前被订阅的模式数量latest_fork_usec:878 #最近一次 fork() 操作耗费的微秒数 如果参数是CPU，那么就会返回CPU的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info cpu# CPUused_cpu_sys:63.95 #Redis服务器耗费的系统CPUused_cpu_user:129.54 #Redis服务器耗费的用户CPU used_cpu_sys_children:1.70 #子进程耗费的系统CPUused_cpu_user_children:1.03 #子进程耗费的用户CPU 如果参数是keyspace，那么就会返回数据库相关的统计信息： 123[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info keyspace# Keyspacedb0:keys=262,expires=183,avg_ttl=284091259423 #据库的键数量、数据库设置有过期时间的key的数量（这个值减少是正常的） 除了以上之外其他还有更多信息，请移步：http://redisdoc.com/server/info.html 。感谢前人栽树！！！ 使用zabbix监控redis用zabbix监控redis是一个很简单的事儿，只需要把需要监控的数据提取出来即可。而提取数据的方法就是利用info去得到对应的数值。 首先先来一个判断redis服务器连接的脚本： 1234567891011[root@func-redis-001 ~]# cat check_redis.sh#这个脚本是用来zabbix监控自建redis的#!/bin/bashPORT='6379'PASSWD=‘REDIS密码’ STATUS_redis=$(redis-cli -h '127.0.0.1' -p $PORT -a $PASSWD ping)if [ "$STATUS_redis" == 'PONG' ];then echo '1'else echo '0'fi 然后更改zabbix_agentd.conf,如下： 12UserParameter=redis_status[*],redis-cli -h '127.0.0.1' -p $1 info | grep -w $2 | awk -F':' '&#123;print $NF&#125;'UserParameter=redis_ping,sudo sh /root/check_redis.sh 修改/etc/sudoers文件如下： 1234## Allow root to run any commands anywhereroot ALL=(ALL) ALLzabbix ALL=(ALL) NOPASSWD:ALL #这个是新增Defaults:zabbix !requiretty #这个是新增 保存之后，重启zabbix-agent服务，由于我这个redis是通过zabbix-proxy监控的，所以在zabbix-proxy一端用zabbix_get来查看结果： 然后在zabbix-proxy的模板里面添加一些需要监控的item即可，有必要的话可以设置trigger+action用来报警，如图： 最后就是grafana搞一个炫酷的图表来，如图： 最后一点，关于redis的内存优化，各位可以来看看：https://cachecloud.github.io/2017/02/16/Redis%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/ ，写的很全面了。还有zabbix各种模板整理，有需要的同学也可以去下载：https://monitoringartist.github.io/zabbix-searcher/ 。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过nginx配置修改网页cookie属性]]></title>
    <url>%2F2018%2F01%2F10%2F%E9%80%9A%E8%BF%87nginx%E9%85%8D%E7%BD%AE%E4%BF%AE%E6%94%B9%E7%BD%91%E9%A1%B5cookie%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[需求与具体配置公司的电子商城在十九大等保安检时期被折腾出去，结果这几天又折腾回来了，据说还会是明年大数据研究院的主要开发项目。结果回来没几天被测试中心的人在cookie方面发现了几个问题，如下： cookie没有使用http-only； cookie没有携带secure属性； http头中需要配置“X-Frame-Options：SAMEORIGIN”； 以上这几点可以通过nginx的配置来轻松实现，具体方法就是在需要更改的网页server的配置里面添加下面几句话。如图： 123add_header Set-Cookie "HttpOnly";add_header Set-Cookie "Secure";add_header X-Frame-Options "SAMEORIGIN"; 然后保存配置文件，nginx -s reload平滑重启即可，通过chrome在目标网页里按下ctrl+shift+c，先选择好network，然后重新刷新一下界面，选择域名，对应域名下点击headers，就会看到cookie的配置情况，如图： 扩展内容看到配置已经生效。那么这几个配置主要是干什么的呢？其实主要都是防范XSS攻击（跨域脚本攻击）的。 Cookie的Secure属性，意味着保持Cookie通信只限于加密传输，指示浏览器仅仅在通过安全/加密连接才能使用该Cookie。如果一个Web服务器从一个非安全连接里设置了一个带有secure属性的Cookie，当Cookie被发送到客户端时，它仍然能通过中间人攻击来拦截。 Cookie的HttpOnly属性，指示浏览器不要在除HTTP（和HTTPS)请求之外暴露Cookie。一个有HttpOnly属性的Cookie，是不可以通过例如调用JavaScript(引用document.cookie)这种非HTTP方式来访问。因此，也不可能通过跨域脚本（一种非常普通的攻击技术）来偷走这种Cookie。 X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在frame, iframe或者object中展现的标记。网站可以使用此功能，来确保自己网站的内容没有被嵌到别人的网站中去，也从而避免了点击劫持 (clickjacking) 的攻击。它有三个可选择项： 123DENY：表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许；SAMEORIGIN：表示该页面可以在相同域名页面的 frame 中展示；ALLOW-FROM uri地址：表示该页面可以在指定来源的 frame 中展示； 如果设置为 DENY，不光在别人的网站 frame 嵌入时会无法加载，在同域名页面中同样会无法加载。另一方面，如果设置为 SAMEORIGIN，那么页面就可以在同域名页面的 frame 中嵌套。 这里还要额外注意一下！配置了Cookie的HttpOnly属性和Secure属性之后，如果测试中心的人使用的协议是http而不是https的话，会有“浏览器请求后端服务时header不会带上cookie参数”的现象，那是因为“由于secure属性的存在，导致浏览器在与服务器通信时不会使用该cookie”。这个时候就需要把secure=”true”这个配置去掉才可以达到正确测试的目的。 参考资料https://imququ.com/post/my-nginx-conf-for-security.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django新增class的时候数据库格式出错]]></title>
    <url>%2F2018%2F01%2F10%2Fdjango%E6%96%B0%E5%A2%9Eclass%E7%9A%84%E6%97%B6%E5%80%99%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A0%BC%E5%BC%8F%E5%87%BA%E9%94%99%2F</url>
    <content type="text"><![CDATA[这几天开发频繁要求查看生产环境zookeeper的配置，于是就想在django里添加一个新的栏，以文本的形式随时更新zookeeper的情况。 于是我就登陆了django，在model.py里添加一个新的class，如下： 12345678#建立杭州测试ZK配置class HZfunczk(models.Model): hzfunczk_remark = models.CharField(verbose_name='杭州测试ZK配置',max_length=50000,blank=true) hzfunczk_signer = models.CharField(verbose_name='登记人',max_length=30,default='system') hzfunczk_signtime = models.DateField(auto_now_add=True) def __unicode__(self): return self.domain_name 然后在django的目录下执行python manage.py makemigrations，这一步没问题，但是在执行python manage.py migrate的时候，就出现了下面的错误： 我开始认为是charfield写错了，应该写Textfield，于是更改了一下，但是保存之后，再执行python manage.py migrate还是出错。其实这个错误主要原因就是因为我那个50000设置错了，因为字段hzfunczk_remark定义的长度50000超出了mysql的varchar的最大长度21845（在utf8编码情况下）。于是我就在model.py里把这个长度改成20000，保存之后，还是执行到python manage.py migrate这一步，依旧爆上面的错误。于是我就干脆把这个class先删除掉，没想到都删除光了，还是在make的时候会爆错。 这就很奇怪了，我已经删掉了为啥还有这样的事儿？于是就干脆进入到数据库去看，由于我现在只知道列名叫hzfunczk_remark，所以我要根据这个列名去查它所在的表，maria反馈如下： 12MariaDB [abccs]&gt; select TABLE_SCHEMA, TABLE_NAME from information_schema.columns where COLUMN_NAME = 'hzfunczk_remark'; Empty set (0.02 sec) 好尴尬呀，数据库里压根就没有列名为“hzfunczk_remark”的表。然后由于python manage.py migrate报错，现在无法启动django。怎么办？ 遇到这种状况，就去django里的migrations文件夹，这个文件夹里有很多的以时间命名的py文件，它们记录着数据库的每一步操作，不过这里面的py还没有真正执行到数据库里，我找到当时添加class那个时间段的py文件，里面是这样的： 先把里面CharField改成TextField，然后把50000改成小于21845的就行了。如果你性子比较烈，那就干脆把这个文件以及之后产生的所有文件都删除掉。重新的去make。 如果还是实在不行，还有一个万不得已的办法，几乎所有的数据库错误都可以用这个方法解决：将migrations文件夹下的文件除了init.py全部删掉，然后将数据库drop掉，重新建数据库。然后make和migrate，就可以使用一个新的数据库（但愿你永远用不到这个方法）。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通道信息加密工具--Qtunnel]]></title>
    <url>%2F2018%2F01%2F10%2F%E9%80%9A%E9%81%93%E4%BF%A1%E6%81%AF%E5%8A%A0%E5%AF%86%E5%B7%A5%E5%85%B7-Qtunnel%2F</url>
    <content type="text"><![CDATA[前言数据库做异地容灾是一个很常见的现象，既然信息要跨地域传递，要么就很土豪的打通机房之间的链路或者动用VPN，要不然就不可避免的走公网网络传输信息。既然选择了公网，那么数据库的语句就很容易被人监听到，所以把那些明文加密是必不可少的环节。 mysql支持tls/ssl加密方法对信息进行加密，这个方法的配置也很简单，就是两边各加上一个nginx，一个是正向代理一个是反向代理，配上ssl证书，然后就像配置网站https协议那样，在nginx.conf里开启ssl监听即可。 但是这种方法有一点小问题，就是在进行SSL握手之前，mysql会发送Server Greeting和Login Request数据包，然后才有可能使用SSL握手。这样步骤就多了一步鉴权，对访问性能有所影响。所以这个时候，我选择了另一个用于加密client和server之间链路通信的工具—-Qtunnel，因为它直接加密，速度更快。 Git的地址在这里：https://github.com/arstercz/qtunnel ，感谢arstercz大神的再加工！ 上面说过了Qtunnel是不需要认证的，默认加密方法是RC4，以字节流的方式加密明文的每一个字节，而且密钥长度最长支持256位，可以很好的抵御暴力搜索密钥的攻击，总而言之，Qtunnel是一个轻量且快速的加解密工具，而且还可以搭配atlas等数据库中间件使用。 下载与准备由于Qtunnel是用go语言写的，所以需要先安装golang，centos服务器的yum安装方法如下: 12rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install -y golang go语言安装完毕之后，我们就git clone https://github.com/arstercz/qtunnel.git ，获得qtunnel文件夹，文件夹内容如下： make，如果没有任何报错，那么就是安装成功了，使用./bin/qtunnel -h语句验证一番： 本次实验的计划是这样的：用A机器访问B机器的mysql，并且插入数据，在B机器上的3306端口抓包，查看数据是否是明文；然后再在A机器和B机器上都安装qtunnel并且启动，然后重新插入数据，在B机器上的端口抓包，查看数据是否被加密。流程图如下： 实验开始A机器和B机器都是使用阿里云虚拟服务器，版本都是centos 6.4，现在我们的加密实验正式开始。 首先A和B机器上都不启动qtunnel，然后我们在A机器上登陆B机器的数据库，如果之前没有授权，那么授权语句是： GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;A机器的IP地址&#39; IDENTIFIED BY &#39;密码&#39; WITH GRANT OPTION; 登陆mysql之后，我们随意的插一个语句，然后通过抓包发现无论这个语句还是数据库的反馈都是以明文的形式呈现，如图： 这种让数据裸奔的行为无疑于找死，那么这个时候我们就要配置一下qtunnel，来看一下它的加密效果。 在A服务器上，我们设定qtunnel是客户端，手动建立一个conf文件，比如vim /etc/conn.conf，内容如下： 123456[client1]faddr = 10.252.215.108:3309 #这里是qtunnel客户端的IPbaddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPcryptoMethod = rc4 #这里选用rc4的方式加密secret = 3301_test%Iad #rc4密钥，服务端的密码必须跟这个一致！clientmode = true #表示这端是客户端 然后使用./bin/qtunnel -conf=/etc/conn.conf -daemon -logto=syslog启动qtunnel，看一下进程和端口情况，如图： 在B服务器上，同样手动建立一个配置文件，假设也叫conn.conf，内容如下： 123456[server1]faddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPbaddr = 10.175.193.239:3306 #这里是数据库的地址，由于在同一台机器上，所以地址一样cryptoMethod = rc4 secret = 3301_test%Iad #rc4密钥，跟client密钥一致clientmode = false #表示这是服务器端 也用同样的语句启动qtunnel，查看3310这个端口已经被监听了： 现在，我们在A服务器上来重新连接B数据库，但是要注意！这个时候mysql里的-h不能再是B的IP地址了，而是A的地址！因为qtunnel现在已经打通了一个通道，访问qtunnel的3310端口就等于是访问B数据库的3306端口（有点类似atlas的意思）。 连上之后，我们随意插入一些语句，看一下qtunnel的能力: 可见这个时候，抓包显示都是加密的文字了，实验成功！ 总结与参考资料总结一下：qtunnel采用rc4加密，在算法强度和速度方面是很好的选择，不会引起slave太大的延迟，对管理员或开发而言数据都是透明的（如果在上面的实验启动了qtunnel之后，不监听3310端口，而是监听3306端口，得到的依旧是明文），只是在两端传输的过程中增加了加解密处理。核心的业务(比如用户和充值)在做异地架构的时候可以考虑该方式增强数据的安全性。 《mysql使用ssl简析》：https://hsulei.com/2017/10/19/mysql%E4%BD%BF%E7%94%A8ssl%E7%AE%80%E6%9E%90/《使用ssl加密mysql 5.6的官方文档》：https://dev.mysql.com/doc/refman/5.6/en/encrypted-connections.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>加密技术</tag>
        <tag>Qtunnel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix3.0搭配微信企业号报警]]></title>
    <url>%2F2018%2F01%2F10%2FZabbix3-0%E6%90%AD%E9%85%8D%E5%BE%AE%E4%BF%A1%E4%BC%81%E4%B8%9A%E5%8F%B7%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[Zabbix搭配微信企业号报警是一个很流行的手段，这里说一下如何配置。 准备工作建立一个企业号以及具体应用的链接在此：http://chenx1242.blog.51cto.com/10430133/1954634，里面写的都很明白了。 现在打开微信企业号的官方网站https://work.weixin.qq.com，然后扫描一下微信二维码登录到企业号的控制台。 在控制台网页里，需要查找几个元素，分别是CorpID、应用AgentId、应用Secret还有用户账号。 首先，在控制台里选择“我的企业”，然后就可以看见CorpID，如图： 然后点击“企业应用”，如果没有应用，那么就新建立一个应用。比如我已经建立了一个应用叫“zabbix告警”，那么应用AgentId和应用Secret就在如图的位置： 有了上面的CropID和Secret，就可以去验证一下accesstoken，登录http://qydev.weixin.qq.com/debug ，后在填入对应的CropID和Secret，看一下返回结果是否是“HTTP/1.0 200 OK”，如图： 在这个“zabbix告警”的应用里可见范围里添加对应需要通知的人，然后在“通讯录”里，找到对应的人，记录他们的账号，如图： 材料已经俱备完毕，现在需要做的是更改zabbix-server配置。 首先，在zabbix-server.conf里添加一句AlertScriptsPath=/usr/lib/zabbix/alertscripts，这是为了说明一下脚本所在的路径。当然，这个路径你可以自己更改，然后重启一下zabbix-server。 编写脚本cd /usr/lib/zabbix/alertscripts，在这个目录下我们要新写一个微信脚本，比如脚本名称叫wechat.py。 这个python脚本是需要requests模块的，所以需要先安装这个模块，安装方法如下： 12pip install requestspip install --upgrade requests 而python脚本内容如下，感谢https://github.com/X-Mars/Zabbix-Alert-WeChat/的脚本： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/python2.7#_*_coding:utf-8 _*_#this script is used for alarm by WECHATimport requests,sys,jsonimport urllib3urllib3.disable_warnings()reload(sys)sys.setdefaultencoding('utf-8')def GetToken(Corpid,Secret): Url = "https://qyapi.weixin.qq.com/cgi-bin/gettoken" Data = &#123; "corpid":Corpid, "corpsecret":Secret &#125; r = requests.get(url=Url,params=Data,verify=False) Token = r.json()['access_token'] return Token def SendMessage(Token,User,Agentid,Subject,Content): Url = "https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=%s" % Token Data = &#123; "touser": User, # 企业号中的用户帐号，在zabbix用户Media中配置，如果配置不正常，将按部门发送。 #"totag": Tagid, # 企业号中的部门id，群发时使用。 "msgtype": "text", # 消息类型。 "agentid": Agentid, # 企业号中的应用id。 "text": &#123; "content": Subject + '\n' + Content &#125;, "safe": "0" &#125; r = requests.post(url=Url,data=json.dumps(Data),verify=False) return r.text if __name__ == '__main__': User = sys.argv[1] # zabbix传过来的第一个参数 Subject = sys.argv[2] # zabbix传过来的第二个参数 Content = sys.argv[3] # zabbix传过来的第三个参数 Corpid = "这里填写Corpid" Secret = "这里填写Secret" Agentid = "这里填写应用的agentid" Token = GetToken(Corpid, Secret) Status = SendMessage(Token,User,Agentid,Subject,Content) print Status 脚本保存后，chown -R zabbix:zabbix wechat.py，然后小试一下，上面看到“Zabbix告警”这个微信应用里有一个用户账号叫ChenShuo，那么wechat.py执行语句是：python wechat.py ChenShuo 这个是标题 这里是正文！！ 然后看一下微信，如图： 正确出现了微信提示，可见这个脚本是OK的了。 配置zabbix现在我们要登录到zabbix网站，最上面的“Administration”里选择“Media types”，新建立一个Media type，如图： 保存之后，在“Administration”里选择“Users”，在Admin用户里点击“media”,把刚刚新增的“微信告警”这个media type添加进去，如图： 通知手段配置完毕，现在就是要在具体的Trigger上把微信告警这个新手段添加到active里。首先打开Configuration里的actions界面。此时假设现在有一个告警Trigger叫“模块发生了重启”，判断模块是否重启的依据就是pid值是否发生了变化。那么点击这个Trigger，在action里把“微信告警”添加到报警手段里，如图： 保存之后，整个的微信告警配置就完成了。为了验证配置是否生效，我冒死重启了一台生产环境的服务器，当然啦，好孩子千万不要效仿。 收到微信提示如图：不过考虑到微信告警可能会有所延迟，所以在这建议大家把告警阈值配置稍微早一点，避免“孩子死了奶来了”这种尴尬的情况。 参考资料http://www.yfshare.vip/2017/04/13/Zabbix%E4%B9%8B%E5%BE%AE%E4%BF%A1-Wechat-%E5%91%8A%E8%AD%A6/https://github.com/X-Mars/Zabbix-Alert-WeChat/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手搭建一个hexo博客demo]]></title>
    <url>%2F2018%2F01%2F10%2F%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AAhexo%E5%8D%9A%E5%AE%A2demo%2F</url>
    <content type="text"><![CDATA[曾几何时，自己动手做一个博客的想法愈加强烈，想在里面放一些更多除了技术之外的东西，比如烹饪的美食，比如PVP的视频，比如拍摄的照片，比如篮球足球的评论。在这种需求下，我从众多博客框架里面选择了hexo，原因就是“很多人都推荐hexo”….（囧）于是乎我在windows里搞一个，由于我在公司的网络是可以跨越长城的，所以搞github有一点天然的优势。而且github的博客不用花钱搞域名，他直接免费提供… 在搞github的时候墙裂推荐各位去用命令行，有linux的基本基础就可以很熟练的使用命令行搞github， 它的客户端真的不如命令行好用。 准备工作先去注册一个github，然后去https://git-scm.com 上下载一个最新的git windows的客户端，我下载的是2.15.1版本，如图： 下载完毕之后，就把这个exe文件安装，然后在“开始”里找到git再打开“Git Bash”，我的github账号是RorschachChan，电子邮件也已经配置过，所以现在就在这个bash窗口里写入如下语句： 12git config --global user.name "RorschachChan"git config --global user.email "chenx1242@163.com" 上面git config --global参数，表示你这台机器上所有的Git仓库都会使用这个配置。 再去https://nodejs.org/en/download/上根据自己windows的情况，下载最新的nodejs，下载完了之后就一路next，然后需要退出重进一下git bash，在bash的命令行里输入node -v，看到版本号就是OK，同时输入node，$会变成&gt;，然后输入.exit就可以退出返回到bash。 然后就是安装hexo，hexo的安装比较简单，就是在git bash里输入npm install -g hexo-cli和npm install -g hexo，然后需要等待一会，如果出现了npm ERR!不要怕，重新输入一次应该就会好了，安装完毕之后，输入hexo -v查看hexo的版本，如图： 然后建立一个github ssh密钥，在git bash里输入ssh-keygen -t rsa -C &quot;你的邮箱&quot;，然后告诉密钥生成的路径（下图黄框）以及会让你输入对应的口诀（红色箭头），这个口诀很重要，要妥善保存，如图： 这个密码会在你提交项目（hexo d）时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。这时候去C:\Users\33664\.ssh的路径里就会看到一对钥匙，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 来到github的个人配置里，选择SSH and GPG keys，然后输入title和id_rsa.pub的内容，点击add ssh key。如图：准备工作的最后一步，就是建立一个文件夹，我的文件夹建立在E盘下，名字就叫hexo。 开始搭建博客首先在git bash里进入/e/hexo，然后输入hexo init，这个命令是初始化命令，再输入hexo -g来生成静态文件，执行之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github上你的用户名.github.io的仓库上去的。然后可以输入hexo s来本地启动hexo，这个时候跑到浏览器里输入localhost:4000就会看到hexo博客最初的一个样子，如图： 这个默认的主题比较难看，我们去https://github.com/iissnan/hexo-theme-next下载最近一个比较火爆的主题next,并且把这个下载到hexo文件夹里的themes/next里，语句是：git clone https://github.com/iissnan/hexo-theme-next.git themes/next 然后打开hexo文件夹里的_config.xml，把原有的theme注释，换成新的next，注意，中间是有空格的！ 12#theme: landscapetheme: next 然后hexo clean和hexo g清除 Hexo 的缓存和重新生成静态文件，再次hexo s启动进程，来到浏览看一下发现博客的样子就变成下面的样子了： 这个看上去就简单大方很多了吧。 把博客上传到github现在有人问了，这个博客看上去好像很美，但是有两个致命的缺陷：第一，内容都是在我的windows里，如果我这个电脑坏了/出差/换新硬盘，那么如何保证我以前文件？第二，我启动进程需要执行 hexo -s，如果我电脑关机了，岂不是博客无法打开？ 需要解决就要把磁盘上的内容传递到github库里了，同时github是常开进程的，这样既可以更新我们的内容又不会关闭博客进程，除非github这个网站黄了。 先去github网站去建立一个库（repository），这里我直接选择了公共读，如图： 然后在hexo文件夹里面，修改一下_config.xml的几个地方： 1234567891011121314# Sitetitle: 石锤淡啤酒 #这个是网站在标签页的标题subtitle: 生活就是等待戈多 #这个是副标题description: 这里记录的不只有代码，还有生活和思想！ #这里也可以写网站的关键词，也可以矫情的写点别的author: Chris Chan #这个作者会在网页最下面显示language: zh-Hans #这里表示简体中文timezone:# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:RorschachChan/RorschachChan.github.io.git #这里写的就是刚刚申请的库名 branch: master 建立完库以及修改保存了_config.xml之后，我们执行一句hexo d部署命令，在执行的时候需要输入当时你建立id_rsa时候的口诀，刚刚申请的那个口诀不会这么快就忘了吧。 返回到github的网站就看到hexo里所有的内容都上传到了github网站里了，如图: 在浏览器里输入“https://你的用户名.github.io”，就看到了博客界面： 同理，如果你的github用户名是test，建立的是test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是http://test.github.io了，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。 至此，建立一个博客demo就到此结束了！ 参考资料https://baoyuzhang.github.io/2017/04/28/【Hexo搭建独立博客全纪录】（一）使用Git和Github/https://github.com/iissnan/hexo-theme-nexthttp://opiece.me/2015/04/09/hexo-guide/http://shenzekun.cn/hexo的next主题个性化配置教程.html 强烈推荐这篇文章，可以让你把next主题的博客做的更加漂亮！]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>hexo</tag>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Query String跟Arg的差异]]></title>
    <url>%2F2018%2F01%2F09%2FQuery-String%E8%B7%9Farg%E7%9A%84%E5%BC%82%E5%90%8C%2F</url>
    <content type="text"><![CDATA[前言与需求在https://rorschachchan.github.io/2018/01/09/记一次配置rewrite和return的经历/ 里记录了一次rewrite和return的故事，不过我当时在最后的return里是把域名给写死了：rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last;。 现在新的需求又来了，说域名不要写死，http://dvlshop.lechange.com/index.php/这部分要跟整个uri的state部分保持一致。 于是我这里再把整个uri贴出来，辣一下各位的眼睛：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 也就是说现在只需要变量state那点部分，那么这个时候就不能再使用$query_string了，要使用$arg。 $arg可以精确匹配变量，比如说我有一个参数（uri里？后面的那部分全叫参数）：&amp;p=你大爷&amp;q=你大娘，用$query_string和$arg就是获取所有，而使用$arg_p就是可以获取“你大爷”。 于是说动手就动手，把nginx.conf改成了：123456789101112131415161718location ~ .*\.php.*&#123; include php_fcgi.conf; include pathinfo.conf; set $flag "0"; if ( $args ~ "source_type=lc_app" ) &#123; set $flag "1"; &#125; if ( $args ~ "(.*)response_type(.*)" )&#123; set $Flag "$flag$flag"; set $id $1; set $query $2; &#125; if ($Flag = "11")&#123; set $flag "0"; return 301 $arg_state$id+auto+$query; &#125;&#125; 但是通过日志查看，发现$arg_state得到的是/http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html,这就很囧了，我希望获取http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html（不要前面的反斜杠）或者是/product-79.html（不要中间的网站）。这可怎么办？ 答案是，原生的nginx是做不到这一点，因为nginx不参与业务层逻辑方面的业务。如果说要达到改写的目的，就要搭配lua或者把nginx换成openresty。于是乎就让开发修改一下传递的state来达到目的。 扩展与补充看到这个结果突然让我想起来一道面试题，说开发有一个模块，同时这个模块会给nginx提供几个状态码，比如状态码是111，那就是代表OK，状态码不是111，那就是代表不OK，现在想写一个语句，如果nginx获得的状态码不是111，返回一个404的页面，怎么写？ 没错，答案也是“原生nginx写不了”，原因跟上面的一样，应用模块状态码是业务层的，nginx是http层的，不在一层压根就无法交流。 在这里也顺道补充一下“在浏览器中输入一个URL后都发生了什么？”，以下是一个大概流程： 浏览器向DNS服务器查找输入URL对应的IP地址； DNS服务器返回网站的IP地址； 浏览器根据IP地址与目标web服务器建立TCP连接； 发送HTTP请求； 服务器处理请求； 返回响应结果； 关闭TCP连接； 浏览器解析HTML； 浏览器布局渲染；]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次配置rewrite和return的经历]]></title>
    <url>%2F2018%2F01%2F09%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%85%8D%E7%BD%AErewrite%E5%92%8Creturn%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[前言与需求自动电商平台归属了大数据研究院之后，我又恢复了那个“把nginx当成爸爸”的日子。开发不断地提出了的要求，我一样一样的疲命应付，并且在应付后记录下来，就怕以后再遇到类似的问题。 这次的需求是一个跳转，满足某个条件之后把“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 ”改成“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27” 具体条件是: 先判断是否有source_type=lc_app； 再判断是否有response_type； 如果以上两个都满足，将“response_type”改成“+auto+”； 各位看官，我理解你们此时不想继续看下去的心情，其实我当初看着那么一大坨uri心里也直犯闹，但是没办法，“食君之禄，分君之忧”，我只能耐着性子一个一个的拆开，还别说，拆开的话就清晰许多了，如下：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 开始操作针对这次需求我的计划是这样的：把原地址看成”$1+ response_type +$2”这样的一个样式，确定$1和$2，然后rewrite成”$1+ +auto+ +$2”不就搞定了么？ 于是乎我就凭着我那二把刀的nginx技术开始动手。折腾了大约半个小时，拿出来这样一个配置： 123456789101112131415161718location ~ .*\.php.* &#123; include php_fcgi.conf; include pathinfo.conf; set $flag "0"; if ( $request_uri ~ "source_type=lc_app" ) &#123; set $flag "1"; &#125; if ( $request_uri ~ "(.*)response_type(.*)" )&#123; set $Flag "$flag$flag"; set $id $1; set $query $2; &#125; if ($Flag = "11")&#123; #注意这个地方是11 set $flag "0"; rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last; #前面那一段是写死的 &#125; &#125; 但是很不幸，nginx -s reload之后的结果是“$1+$2+$1+ response_type +$2”的格式（地址太长太恶心了，我就不写了）。 然后在arstercz大神的指点下，把那句rewrite改成了return 301 http://dvlshop.lechange.com/index.php/wap/?$id$query;。就达到了效果。 原因确定后来追寻原因，原来是： rewrite后面接的$uri不需要$args，因为$args会被自动带过来。而return的则会丢失$args，需要手动补上$args。而我上面的$1,$2恰巧就是$args，所以用rewrite的话就会重复。举个例子，比如请求「http://localhost/?a=1」想被 301 到「https://localhost/?a=1?a=1」，要么 1234server &#123; listen 80; rewrite / https://$host$uri permanent;&#125; 要么就 1234server &#123; listen 80; return 301 https://$host$request_uri;&#125; 补充说明PS，这里补充一下uri、request_uri、document_uri之间的区别： $request_uri: /stat.php?id=1585378&amp;web_id=1585378 $uri: /stat.php (不带？后面) $document_uri: /stat.php （与uri完全相同）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师面试题第一套]]></title>
    <url>%2F2018%2F01%2F04%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E9%A2%98%E7%AC%AC%E4%B8%80%E5%A5%97%2F</url>
    <content type="text"><![CDATA[这套题的出处是http://blog.51cto.com/nolinux/1670406，看到了闲着没事周末就做一做，答案都是我自己在工作里得到的，不一定百分百准确，只是无聊的时候做做，现在拿出来跟各位分享一番。 1、请写出五种系统性能分析工具，并简述其作用和特点[我的答案] top、free、vmstat、iostat、perf等等等等，如果你想装逼，可以回答fio,blktrace，oprofile。具体的作用和特点这里不多说了，但是我着重要推荐vmstat，很实用很棒的一个命令。 2、请写出web服务器的调优要点[我的答案]以nginx为例，个人总结有如下几个要点：1）尽可能的少用http，因为http是有开销的；2）尽可能的使用CDN；3）添加Expire/Cache-Control头，这个头是缓存用的，可以缓存图片和flash那样不轻易更改的文件，减少访问时间；4）启动gzip压缩，这个没啥好说的了；5）尽可能少的重定向，能rewrite就不要return，我也知道return比rewrite好写，但是重定向是需要时间的，增加一次重定向就会多一次web需求；6）如果可以，把ajax也做缓存；7）减少dns查询，很多网页会有外站的广告，这些广告也是会启动dns查询的，所以如果不缺钱，减少这种广告；8）调好服务器里的TCP协议栈，这个无论是web服务器还是应用服务器都是必须的； 3、请写出你知道或使用过的nginx扩展模块（注意标注知道和使用）[我的答案] 随便说几个，这玩意到时候结合工作过的情况说说吧：Nginx负载均衡模块：nginx-upstream-fair非阻塞访问redis模块：redis2-nginx-module分布式图片实时动态压缩：ngx-fastdfs 4、请简述你了解的自动化配置管理工具特点和运行原理[我的答案]我用的最多的就是ansible和saltstack，这俩都是python的，对于我这个半路出家的更亲切。ansible基于SSH协议传输数据，不用装agent，配置比较简单，对windows支持惨不忍睹；saltstack使用消息队列zeroMQ传输数据，如果1000台以上的话它速度比ansible还要快,要安装agent，对windows支持同样惨不忍睹； 5、目前，有一个文件，内容如下： 172.16.100.1 172.16.100.2 172.16.100.3 172.16.100.4 请使用while和ssh命令，登录文件内的ip并执行hostname命令[我的答案]这个我还真没有什么思路，不过应该是跟“&lt;”输入重定向命令结合的一个脚本吧。PS,为啥不用ansible…哪怕pssh也可以啊！ 6、请使用awk命令将如下两份文件中名字相同的两行合并起来 A文件： 大广州 21岁 广州大 23岁 州广大 22岁 广州大 24岁 B文件： 广州大 男 大广州 男 州广大 男 广州大 男输出效果： 大广州 21岁 男[我的答案]awk ‘NR==FNR{a[$1]=$2}NR&gt;FNR{print $0,a[$1]}’ 第2个文件名 第1个文件名PS，做完这道题，我已经不认识“广”“州”这两个字了… 7、请使用绘图的方式简述TCP/IP三次握手和四次断开的交互过程[我的答案]这种图满大街都是了，我这个灵魂画师在这里就不污染各位的眼睛，不过这里推荐各位去看一篇文章：https://mp.weixin.qq.com/s?__biz=MjM5NzA1MTcyMA==&amp;mid=2651160450&amp;idx=2&amp;sn=1128438fa5287b6cee503880698642b2&amp;scene=21 对原理讲的浅显易懂。多说一句，网易招聘java的时候也问这个问题，不过他们问的是“为什么要三次握手？” 8、请根据你的理解，简述高可用服务体系的相关组件，并列举该组件的具体实现服务名字[我的答案] 我觉得这个题是要问一些架构上的东西，以我工作环境为例：统一配置:zookeeper、Consul、Etcd+Confd(这俩比较常见于动态管理nginx)前端展示:nginx消息队列:activemq、kafka读写分离中间件:atlas日志分析:elk 9、请根据你的理解，简述负载均衡的实现方式[我的答案]负载均衡主要分为两种，硬件（F5）和软件（NGINX、Haproxy、LVS），硬件效果比较牛逼，它是把4-7层的负载均衡功能做到一个硬件里面，但是价格昂贵最近用的越来越少了。软件的负载均衡又分两种，四层和七层：四层是在IP/TCP协议栈上把网络包的IP地址和端口进行修改，达到转发的目的；七层就是在应用层里把HTTP请求、URL等具体的应用数据发送到具体的服务器上。四层的效率比七层的高，四层一般安排在架构的前端，七层一般就是在具体服务器的前端。软件负载均衡比较常见的几个分配方式如下：轮询：访问请求依序分发给后端服务器；加权轮询：访问请求依序分发后端服务器，服务器权重越高被分发的几率也越大；最小连接数： 将访问请求分发给当前连接数最小的一台后端服务器，服务器权重越高被分发的几率也越大； 10、请根据你的理解，简述数据迁移工具和数据存储服务有哪些以及相关特点[我的答案]由于我公司主要都放在了阿里云，数据库用过的就这么几个:mysql、redis和elasticsearch。对于Storm和Hadoop这俩我还是初学者。mysql:关系型数据库elasticsearch:全文检索框架，这玩意逐渐向一个数据库靠拢了redis:键值储存数据库 mysql的数据迁移最常见的就是mysqldump，但是要注意使用不当会锁表，redis的数据迁移最稳妥的方法就是主从同步：在slave端启动redis，然后执行slaveof master机器IP地址 6379，然后使用info的时候查看master_link_status如果是up那就是OK了，再执行slaveof no one,提示OK就是OK了；Elasticsearch的数据迁移工具就是Elasticsearch-Exporter，不过我对它仅仅只是了解，用的并不多； 总结这套题不算难，方向是偏应用的，但是对云端服务的运维来说不算很友好，因为云厂商基本都把数据备份和数据迁移都做成自己的工具（比如阿里云的DTS），所以很多云服务的运维对这种东西了解不多。]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx动态编译新的模块]]></title>
    <url>%2F2018%2F01%2F03%2FNginx%E5%8A%A8%E6%80%81%E7%BC%96%E8%AF%91%E6%96%B0%E7%9A%84%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[开始动手打算给电脑上的nginx添加一个当时没有编译安装的echo-nginx-module模块，这是一个第三方模块，要知道nginx要添加模块是需要重新编译的，这一点跟apache不同，apache是在配置文件里引用.so文件的。 首先先nginx -V，查看一下nginx已经编译的模块都有啥，如图： 于是我就git clone https://github.com/openresty/echo-nginx-module，但是发现竟然告诉我“git: command not found”。oh shit，原来这台nginx实验机器压根就没有装过git啊！而yum源里的软件基本上已经过时的太久了，就拿git来说吧，使用yum info git看到的版本是1.8.3.1。但是在https://github.com/git/git/releases 里可以看到，git的版本现在已经丧心病狂的到达了2.16的版本了。 那么我们先安装git!通过yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel和yum install gcc perl-ExtUtils-MakeMaker来安装依赖库。wget https://github.com/git/git/archive/v2.16.0-rc0.tar.gz来下载2.16的git保存到centos里。tar -xzvf v2.9.2.tar.gz -C /目标目录/，然后在目标目录里面执行make prefix=/usr/local/git all和make prefix=/usr/local/git install，编译过程可能会比较长，请耐心等待。 编译结束之后，echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/bashrc，把git添加到环境变量，再source /etc/bashrc让它实时生效，最后再一次看看git --version，大功告成！ 编译新模块git搞定了之后，重新git clone https://github.com/openresty/echo-nginx-module，然后在nginx的configure文件夹里面，把echo-nginx-module模块添加上。命令如下： ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/root/pcre-8.41 --with-http_v2_module --add-module=/root/echo-nginx-module-0.61,我这里还附赠了一个“http_v2_module”。 configure完毕之后，去make一下就可以了，不要轻易make install，不然就是重新安装了。原来的nginx.conf等配置都没了。 养成替换nginx二进制文件的好习惯，如下： cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak cp nginx编译目录/objs/nginx /usr/local/nginx/sbin/ 然后再打开看一下nginx -V]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从vmstat命令里看服务器瓶颈]]></title>
    <url>%2F2018%2F01%2F03%2F%E4%BB%8Evmstat%E5%91%BD%E4%BB%A4%E9%87%8C%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%93%B6%E9%A2%88%2F</url>
    <content type="text"><![CDATA[这几天重新翻看基础知识，看到了vmstat，我认为它是一个非常优秀的命令,因为它包括了top和free，甚至还包含了一些io的信息，可以说是运维人员常备命令之一。常用方法：vmstat (-a) 多少秒刷一次 刷多少次。 对上面这个图来一个简单的解释： r: 运行队列中进程数量，这个值长期大于1就要判断是否需要增加CPU。b: 等待IO的进程数量 swpd: 使用虚拟内存大小(如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能）free: 空闲物理内存大小buff: 用作缓冲的内存大小cache: 用作缓存的内存大小(如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小)inact: 非活跃内存大小（当使用-a选项时显示）active: 活跃的内存大小（当使用-a选项时显示） si: 每秒从交换区写到内存的大小，由磁盘调入内存so: 每秒写入交换区的内存大小，由内存调入磁盘注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。 bi: 每秒读取的块数bo: 每秒写入的块数注意：随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。 in: 每秒中断数，包括时钟中断。cs: 每秒上下文切换数。注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 us: 用户进程执行时间百分比(user time)注意： us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time)注意：sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 wa: IO等待时间百分比注意：wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 id: 空闲时间百分比 最后总结：如果r经常大于4 ，且id经常少于40，表示cpu的负荷很重。如果bi，bo长期不等于0，表示内存不足。 r（运行队列）展示了正在执行和等待CPU资源的任务个数。当这个值超过了CPU数目，就会出现CPU瓶颈了。 CPU 100%并不能说明什么，Linux总是试图要CPU尽可能的繁忙，使得任务的吞吐量最大化。唯一能够确定CPU瓶颈的还是r（运行队列）的值。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于阿里云CDN的两个故障解决]]></title>
    <url>%2F2017%2F12%2F28%2FCDN%E7%BD%91%E7%AB%99%E4%B8%80%E6%AC%A1%E6%89%93%E4%B8%8D%E5%BC%80%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[测试中心今天在测试时候发现了一个问题：官方的A网站做了域名跳转，跳转到阿里云CDN，但是在浏览器里输入A地址栏的时候，发现域名的确变成了CDN的域名，但是页面是403。 如图： 但是奇怪的是，再在浏览器点击一下回车，网页就神奇的打开了。 这个原因就是阿里云的CDN有一个“Refer防盗链”，需要在防盗链里面把A域名添加到白名单，这样的话就可以直接访问了。至于为什么第二次回车就可以访问，是因为那时候域名已经成CDN自己的域名了，当然可以访问。 但是这个防盗链也要注意！毕竟白/黑名单添加都是一个危险举动，一定三思后行。有可能你的css\js是用cdn加速的，一旦加上了白名单，可能css就会变得很难看。 不就之后，商城也下来一个需求，说公司有两个多年不用的域名B和C，打算废物利用，两个都要达到直接“跳转官网”的目的。 于是我就到阿里云域名管理的那里搜索一下，发现目前官网域名后端绑定的是一个CDN，于是也把域名B和域名C做一个CNAME到这个域名，不过登陆浏览器发现域名B和域名C都反馈502。 于是我就到电子商城后端的nginx.conf里查看，确认server_name字段没有写错，然后把域名B和域名C的CNAME直接改成了CDN的域名，再通过了dig确认。但是等于浏览器还是发现502。 最后找了阿里云的人了解，原来阿里云规定“一个CDN只能绑定一个域名，因为节点上没有那两个域名的配置，所以只要不符合节点上有配置文件信息的，全部502”。所以B和C是无法访问的。要解决这个问题有两招，1）把域名B和域名C直接A记录绑定CDN后面的SLB上，但是代价就是访问速度不如CDN快；2）重新购买两个CDN，都绑定SLB，然后把这两个CDN分别绑定到域名B和域名C上，代价是多收一点流量费…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>CDN</tag>
        <tag>网站技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[screen的用法]]></title>
    <url>%2F2017%2F12%2F21%2Fscreen%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[很多时候在Linux要后台执行程序，都是使用“&amp;”，或者是nohup，不过这两个更多应用于临时的脚本。一个比较高科技的方法就是使用screen。 安装screen的方法很简单：yum install -y screen。 如果新建一个screen，就输入screen -S name，这样会新开一个窗口，然后执行命令。比如我要启动django，那么就输入python manage.py runserver 0.0.0.0:9000即可。 这个重开一个窗口，列出所有screen进程，就这样： [root@docker ~]# screen -ls There are screens on: 3029.xiedi (Attached) 如果想链接上之前那个django，执行命令screen -r 3029即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>其他软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pictest]]></title>
    <url>%2F2017%2F12%2F13%2Fpictest%2F</url>
    <content type="text"><![CDATA[这是一个我用来测试图片上传的文章 啊！五环，你比四环多一环！啊！五环，你比六环少一环！终于有一天，你会修到七环]]></content>
      <categories>
        <category>用来保护视力的图片</category>
      </categories>
      <tags>
        <tag>美女</tag>
        <tag>图片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这里记录的不只有代码，还有生活和思想！]]></title>
    <url>%2F2017%2F12%2F13%2F%E8%BF%99%E9%87%8C%E8%AE%B0%E5%BD%95%E7%9A%84%E4%B8%8D%E5%8F%AA%E6%9C%89%E4%BB%A3%E7%A0%81%EF%BC%8C%E8%BF%98%E6%9C%89%E7%94%9F%E6%B4%BB%E5%92%8C%E6%80%9D%E6%83%B3%EF%BC%81%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer1"), narrow: false, autoplay: false, showlrc: 0, music: { title: "一个人去旅行", author: "陈升", url: "http://p1x3hd2at.bkt.clouddn.com/一个人去旅行.mp3", pic: "http://p1x3hd2at.bkt.clouddn.com/五十米深蓝.jpg", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 你说要一个人去旅行 但是归期却没有约定 亚得里亚海边风中的吉他声你说你带着苍白的回忆 却谢谢能与我相逢 我怕你在异乡夜里孤独醒来要拒绝两人单调的生活 想寻找自由 迷信了爱情 就迷失了我自己你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 一个人生活 你说要一个人去旅行 眼里藏着一朵乌云 知道你藏不住秘密 天空就会飘着雨你说你带着一本日记 却不想再拥有回忆 我怕你在异乡孤独的醒来要拒绝两人单调的生活 不想再随波逐流 迷信了孤独 就软弱的抛弃了我的等待 你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 让我孤独生活 你就这样 离开吧 抛弃我 孤独的旅人你就这样 离开我 抛弃我 让我孤独生活 我想要一个人去旅行 但愿归期会有约定 每个人都在问我 是否可以找到自由的你亚得里亚海边他乡的人和风中的吉他声 我怕你一个人在异乡孤独醒来我会带着你回来]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>音乐</tag>
        <tag>感悟</tag>
      </tags>
  </entry>
</search>
