{"meta":{"title":"Chris Chan's BLOG","subtitle":"那些在阳光下挥洒青春的日子啊！","description":"生活就是等待戈多","author":"Chris Chan","url":"http://yoursite.com"},"pages":[{"title":"","date":"2017-09-06T07:37:18.000Z","updated":"2018-01-09T06:45:46.132Z","comments":false,"path":"/404.html","permalink":"http://yoursite.com//404.html","excerpt":"","text":"&lt;!DOCTYPE HTML&gt;"},{"title":"关于我","date":"2018-01-09T12:47:40.000Z","updated":"2018-01-17T14:06:34.548Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"欢迎你来到我的博客!我是Chris Chan,也用“苏幕遮”这个名字行走江湖，生活在浙江杭州。在地球上我有很多身份，即是《魔兽世界》里的联盟玩家也是一名巴塞罗那的球迷，是蝙蝠侠的狂热爱好者也是一个懒散专业户。 目前就职于浙江大华股份研发中心大数据研究院，职位是LINUX运维工程师。 我之前的博客是在51cto上的，地址是http://blog.51cto.com/chenx1242 ，现在自己出来单独搞了一个博客，那么也会慢慢地把51cto上的东西都迁移过来。 名称：苏幕遮（Chris Chan） 兴趣：看日剧、打台球、跑步、观看举重、喝冰梅子酒、看梅西踢球、看库里三分、看Gakki卖萌 未来目标：练练摄影、学学游泳、养一只鹦鹉、好好练字 下一双想要收集的鞋： Asics的TBF-712（泽北荣治同款） 最近在读的书：《围城》、《Nginx高性能WEB服务器详解》 擅长的事情：撩骚、扯淡，其他好象就没了（囧~~） 社交：侧边栏里已经写的很全了，如果还想更多了解我，我网易云音乐账号是“四平青年赵山河”；虎扑账号是“fenshi91” 梦想：买一辆Panamera，如果再可以的话，买一辆奔驰cls… 明年目标：在杭州买房，跟女票结婚，去一趟日本，如果可以的话，再听一场perfume的演唱会 var options = {\"narrow\":false,\"autoplay\":false,\"showlrc\":0,\"mutex\":true,\"music\":[{\"title\":\"一块红布\",\"author\":\"崔健\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/一块红布.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/一块红布.jpg\"},{\"title\":\"快让我在雪地上撒点野\",\"author\":\"崔健\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/快让我在雪地上撒点野.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/一块红布.jpg\"},{\"title\":\"漩涡\",\"author\":\"黄耀明、彭羚\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/漩涡.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/黄耀明.jpg\"},{\"title\":\"昆仑仙境\",\"author\":\"蔡志展\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/昆仑仙境.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/金庸群侠传.jpg\"},{\"title\":\"荡空山\",\"author\":\"窦唯\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/荡空山.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/窦唯.jpg\"},{\"title\":\"哪呢\",\"author\":\"窦唯\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/哪呢.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/窦唯.jpg\"},{\"title\":\"怕你为自己流泪\",\"author\":\"窦唯\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/怕你为自己流泪.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/窦唯.jpg\"},{\"title\":\"努力活着\",\"author\":\"赵传\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/努力活着.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/赵传.jpg\"},{\"title\":\"So bad\",\"author\":\"Eminem\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/so bad.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/eminem.jpg\"},{\"title\":\"到我碗里来\",\"author\":\"大笑\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/到我碗里来.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/大笑.jpg\"},{\"title\":\"龙拳\",\"author\":\"周杰伦\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/龙拳.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/八度空间.jpg\"},{\"title\":\"星より先に見つけてあげる(TV Size)\",\"author\":\"森口博子\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/一拳超人片尾曲.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/一拳超人.jpg\"},{\"title\":\"THE HERO !! ~怒れる拳に火をつけろ~\",\"author\":\"JAM Project\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/一拳超人主题曲.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/一拳超人.jpg\"},{\"title\":\"垃圾\",\"author\":\"卢巧音\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/垃圾.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/卢巧音垃圾.jpg\"},{\"title\":\"长安县\",\"author\":\"马飞\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/长安县.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/马飞.jpg\"},{\"title\":\"我能chua\",\"author\":\"马飞\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/我能chua.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/马飞.jpg\"},{\"title\":\"那一份自我\",\"author\":\"单行道\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/那一份自我.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/那一份自我.jpg\"},{\"title\":\"Fall\",\"author\":\"槇原敬之\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Fall.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/明天不上班.jpg\"},{\"title\":\"缺口\",\"author\":\"蔡琴\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/缺口.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/蔡琴遇见.jpg\"},{\"title\":\"失格\",\"author\":\"橘いずみ\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/失格.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/桃花期.jpg\"},{\"title\":\"マルマルファンク (映画 Live ver.)\",\"author\":\"在日ファンク\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/マルマルファンク (映画 Live ver.).mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/桃花期.jpg\"},{\"title\":\"The Itch\",\"author\":\"Keb'Mo'\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/the itch.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/kebmo.jpg\"},{\"title\":\"恋上外星人\",\"author\":\"张智霖\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/恋上外星人.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/恋上外星人.jpg\"},{\"title\":\"Automatic\",\"author\":\"宇多田光\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Automatic.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/宇多田光.jpg\"},{\"title\":\"Can You Keep a Secret\",\"author\":\"宇多田光\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/CanYouKeepaSecret.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/宇多田光.jpg\"},{\"title\":\"Fly me to the moon\",\"author\":\"宇多田光\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/flymetothemoon.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/宇多田光.jpg\"},{\"title\":\"In my room\",\"author\":\"宇多田光\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Inmyroom.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/宇多田光.jpg\"},{\"title\":\"Miss Alissa\",\"author\":\"Eagles of Death Metal\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Miss Alissa.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/Miss Alissa.jpg\"},{\"title\":\"一颗苹果\",\"author\":\"五月天\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/一颗苹果.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/一颗苹果.jpg\"},{\"title\":\"Who is it\",\"author\":\"Micheal Jackson\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/whoisit.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/MJ_Dangerous.jpg\"},{\"title\":\"No woman,No cry\",\"author\":\"Bob Marley & The Wailers\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/NowomanNocry.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/nowomannocry.jpg\"},{\"title\":\"追远\",\"author\":\"炎凉乐队\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/追远.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/炎凉乐队.jpg\"},{\"title\":\"夜已如歌\",\"author\":\"绿色频道\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/夜已如歌.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/夜已如歌.jpg\"},{\"title\":\"十万嬉皮（Live）\",\"author\":\"Hebe田馥甄\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/十万嬉皮.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/hebe.jpg\"},{\"title\":\"La Donna e Mobile\",\"author\":\"Luciano Pavarotti\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/女人善变.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/女人善变.jpg\"},{\"title\":\"天煞孤星\",\"author\":\"谢霆锋\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/天煞孤星.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/903.jpg\"},{\"title\":\"Under Pressure (Live)\",\"author\":\"David Bowie\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Under Pressure (Live).mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/David Bowie.jpg\"},{\"title\":\"不想堕落\",\"author\":\"孽子\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/不想堕落.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/孽子.png\"},{\"title\":\"Third Day of a Seven Day Binge\",\"author\":\"Marilyn Manson\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Third Day of a Seven Day Binge.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/marilynmanson.png\"},{\"title\":\"Kill4ME\",\"author\":\"Marilyn Manson\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/kill4me.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/marilynmanson.png\"},{\"title\":\"为爱说抱歉\",\"author\":\"孙楠\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/为爱说抱歉.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/孙楠.jpg\"},{\"title\":\"In cherrycloud\",\"author\":\"餃子屋本舗\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/in cherrycloud.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/餃子屋本舗.png\"},{\"title\":\"黑夜尽头\",\"author\":\"黄立行\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/黑夜尽头.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/黄立行.jpg\"},{\"title\":\"Happy Dreamer\",\"author\":\"Laidback\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Happy Dreamer.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/Buddha-BarVII.jpg\"},{\"title\":\"Over Your Shoulder\",\"author\":\"Chromeo\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Over Your Shoulder.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/Chromeo.jpg\"},{\"title\":\"Bésame mucho\",\"author\":\"Disney\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Bésame mucho.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/coco.jpg\"},{\"title\":\"Chick Habit\",\"author\":\"April March\",\"url\":\"http://p1x3hd2at.bkt.clouddn.com/Chick Habit.mp3\",\"pic\":\"http://p1x3hd2at.bkt.clouddn.com/ChickHabit.jpg\"}]}; options.element = document.getElementById(\"aplayer1\"); var ap = new APlayer(options); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 习武之人有三个阶段：见自己，见天地，见众生。"},{"title":"对我有什么想说的","date":"2017-12-14T08:55:38.000Z","updated":"2017-12-14T08:56:41.508Z","comments":true,"path":"guestbook/index.html","permalink":"http://yoursite.com/guestbook/index.html","excerpt":"","text":""}],"posts":[{"title":"Zabbix-proxy的搭建和配置全过程","slug":"Zabbix-proxy的搭建和配置全过程","date":"2018-01-26T06:27:04.000Z","updated":"2018-01-26T07:02:20.193Z","comments":true,"path":"2018/01/26/Zabbix-proxy的搭建和配置全过程/","link":"","permalink":"http://yoursite.com/2018/01/26/Zabbix-proxy的搭建和配置全过程/","excerpt":"","text":"Zabbix-proxy的用途和构建图Zabbix-server是建立在金山云的，现在需要监控阿里云的redis，但是阿里云跟金山云之间通信是无法走内网的，如果直接让zabbix-server与redis直接联系，一旦公网的信息被截获的话，整个金山区的zabbix可能都会遭殃，那么既然有这种“远程监控+当监控的位置通信不便”的需求，就搭建一个zabbix-proxy来解决问题。 Zabbix-proxy是一个监控代理服务器，它收集监控到的数据，先存放在缓冲区，保存的时间可以通过配置文件设定，然后再传送到zabbix-server，这样也大大减缓了zabbix-server的压力，注意！监控代理需要一个单独的数据库，因为它的数据库表名与zabbix-server的数据库表名是一样的，如果不单独分开，后果就是数据错乱。 有人看到这里可能问了，说来说去你的zabbix-proxy跟阿里的redis依旧是走公网的啊！虽然这样也是走公网，我现在只需要配置一个防火墙规则来让他俩保证通信即可，通过防火墙来提升安全系数。架构如图： 安装Mysql 5.5Zabbix-proxy机器情况：金山云centos 6.5，安装zabbix版本：3.0.8 1234567891011[root@js-online-cjhmq-002 opt]yum list installed | grep mysql #列出已经安装过的mysql情况[root@js-online-cjhmq-002 opt]yum -y remove mysql-libs.x86_64 #把之前的mysql连根拔起[root@js-online-cjhmq-002 opt]# rpm -ivh http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmRetrieving http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmPreparing... ########################################### [100%] 1:mysql-community-release########################################### [100%][root@js-online-cjhmq-002 opt]groupadd zabbix #新建用户组zabbix[root@js-online-cjhmq-002 opt]useradd -g zabbix -u 808 -m zabbix#-g：指定用户所属的群组；#-u：指定用户id。#-m：自动建立用户的登入目录； 现在要修改一下/etc/yum.repos.d/mysql-community.repo这个文件，将5.5的enabled改为1,5.6的enabled改为0： 123456789101112131415# Enable to use MySQL 5.5[mysql55-community]name=MySQL 5.5 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.5-community/el/6/$basearch/enabled=1 #这里改成1gpgcheck=1 gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/6/$basearch/enabled=0 #这里改成0gpgcheck=1gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 然后执行yum install mysql-community-client mysql-community-devel mysql-community-server php-mysql， 安装服务端和客户端，安装完毕之后可以mysql -h127.0.0.1看一下。 安装完毕之后，修改一下/etc/my.cnf，如图： 12innodb_buffer_pool_size = 512M #这个根据服务器性能填写，这个机器是2核2G的，所以我拿出半个G给mysqlinnodb_file_per_table=1 #这个是新增的字段，设置InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据目录 mysql安装完毕之后，我们还要导表进去，如图： 123456service mysqld startmysqladmin -uroot password '123456'mysql -uroot -p123456 -e 'create database zabbix_proxy character set utf8;'mysql -uroot -p123456 -e \"grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'zabbix';\"mysql -uroot -p123456 -e \"flush privileges;\"mysql -uzabbix -pzabbix zabbix_proxy &lt;/解压路径/zabbix-3.0.8/database/mysql/schema.sql 至此，mysql部分已经全部搞定。 安装Zabbix-proxy先去https://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/3.0.8/下载zabbix-3.0.8.tar.gz，上传到proxy服务器里。 12tar -zxvf zabbix-3.0.8.tar.gz./configure --prefix=/usr/local/zabbix-3.0.8 --sysconfdir=/etc/zabbix --enable-proxy --enable-agent --enable-ipv6 --with-mysql=/usr/bin/mysql_config --with-net-snmp --with-libcurl --with-openipmi --with-unixodbc --with-ldap --with-ssh2 --enable-java 如果出现了configure: error: Invalid LDAP directory - unable to find ldap.h，解决方法就是： 1yum -y install openldap* Zabbix-proxy的配置打开/etc/zabbix/zabbix_proxy.conf，需要修改几个地方： 123456789101112ProxyMode=0 #0是主动模式，1是被动模式Server=A.B.C.D #这里填写zabbix-server的内网IPHostname=J.Q.K.A #这里要与/etc/hosts下的名字一模一样LogFile=/tmp/zabbix_proxy.logDBHost=localhostDBName=zabbix_proxyDBUser=zabbixDBPassword=zabbixConfigFrequency=120 #主动去server端去拉去配置更新的频率120秒一次DataSenderFrequency=60 #发送采集的监控数据到服务器端，默认是1秒，我们一分钟发送一次#ProxyLocalBuffer=0 #ProxyLocalBuffer表示数据传递给server之后还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。#ProxyOfflineBuffer=1 #ProxyOfflineBuffer表示数据没有传递给server的话还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。 然后就是启动proxy: 1# /usr/local/zabbix_proxy/sbin/zabbix_proxy 用netstat查看一下端口和进程是否都OK： Zabbix-server端的配置登入zabbix-server的网页，如图添加proxy： 点击“create proxy”之后，就对应填写资料吧： 这里对上面的几个选项多说几句： 12345678Connections to proxy：服务器如何连接到被动代理：无加密（默认），使用PSK（预共享密钥）或证书。Connections from proxy：从活动代理中选择允许的连接类型。 可以同时选择几种连接类型（用于测试和切换到其他连接类型）。 默认为“无加密”。#点击Certificate之后又两个参数：Issuer：允许颁发证书。 证书首先通过CA（认证机构）验证。 如果CA有效，则由CA签名，则可以使用Issuer字段来进一步限制允许的CA。 该字段是可选的，如果您的Zabbix安装使用多个CA的证书，则使用该字段。Subject：允许的证书。 证书首先通过CA验证。 如果它有效，由CA签名，则主题字段可用于仅允许Subject字符串的一个值。 如果此字段为空，则接受由配置的CA签名的任何有效证书。 #点击PSK之后又两个参数：PSK identity：预共享密钥身份字符串。PSK ： 预共享密钥（hex-string）。 如果Zabbix使用mbed TLS（PolarSSL）库，Zabbix将使用GnuTLS或OpenSSL库，64位十六进制（32字节PSK），最大长度为512位十六进制数（256字节PSK）。 示例：1f87b595725ac58dd977beef14b97461a7c1045b9a1c963065002c5473194952 保存之后，就在zabbix-server用zabbix-get去ping一下proxy，看看返回值是否是1，如果是zabbix_get [18290]: Check access restrictions in Zabbix agent configuration，就检查一下刚才的hostname等值是否正确。 被监控机器的配置在被监控的阿里云redis里安装zabbix-agent，在agentd.conf里把hostname写成自己在/etc/hosts里的hostname，Server地址和ServerActive的地址都要写成proxy的外网IP地址。保存之后启动agent进程，这个时候在proxy端是可以通过zabbix_get得到这台被监控机器的值，如图： 在Zabbix-Server的WEB界面里，为阿里云的redis新建一个host，Agent interface那里填写被监控的机器IP，端口是10050，Monitored by proxy的地方要写成刚刚添加的proxy。如图： 上面已经提到过，用proxy模式并且zabbix的客户端也是主动模式提交数据，这样能大大提高采集效率，降低zabbix服务器端和proxy端的压力。现在我们希望添加的还是使用zabbix_agent的方式，新加到zabbix_proxy里面的主机使用zabbix_agent（active）的方式。注意在模板的克隆要选择full clone，不要选“clone”，那样的话就仅仅是把iterm的名字克隆过去而已，如图： 然后在items选择具体的类型，根据需要，想改那个改哪个，如图，注意！我图里写的是Zabbix agent，但是type这里选择Zabbix agent (active)。 改完之后，保存一下，就会看到type都是zabbix agent（active）了。 最后在host里把这个机器添加到proxy的模板里，如图： 在Administration的Proxies也看到效果了，如果server与proxy没有正确连接的话，last seen的地方会是--，如果连接的话就会显示具体时间，如图: 返回到hosts里，查看那个被监控的redis机器也成功被监控到了，ZBX已经变绿。如图： 因为我们线上环境基本都是用的zabbix_proxy方式是active方式，然后客户端也是active方式，既然都是active方式，那么zabbix_agent的Hostname就很重要，打个比方如果再zabbix_server端把一个主机的Hostname改了，然后客户端那边也改了，服务端和客户端的Hostname是统一的，但是proxy那里还记录的是旧Hostname，然后就会在proxy日志里面看到下面一条： 1cannot send list of active checks to \"proxy内网IP地址\": host [virt_proxy内网IP地址] not found proxy主动模式下，ConfigFrequency默认的是3600秒一小时，显然有点大了，可以适当的调低一下，如10分钟或者几分钟什么的。然后出现问题多看看zabbix服务端和proxy的日志，对症下药。 参考资料http://www.51niux.com/?id=156http://www.cnblogs.com/wangxiaoqiangs/p/5336630.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"监控技术","slug":"监控技术","permalink":"http://yoursite.com/tags/监控技术/"}]},{"title":"阿里云服务器更改时区为utc","slug":"阿里云服务器更改时区为utc","date":"2018-01-25T14:31:16.000Z","updated":"2018-01-26T06:55:58.895Z","comments":true,"path":"2018/01/25/阿里云服务器更改时区为utc/","link":"","permalink":"http://yoursite.com/2018/01/25/阿里云服务器更改时区为utc/","excerpt":"","text":"开发提出需求说，某个模块是给洋人使用，于是把服务器里的时间改成UTC时间。我登陆到服务器里使用date查看了一下，发现目前使用的是东八区时间，如图： 首先先开启UTC，方法就是在/etc/sysconfig/clock的文件里修改这样一处：UTC=true。这样即使机器重启，UTC时间依旧会“BIOS ▶ UTC时区转换 ▶ 系统时间”的顺序正常使用。 在Centos 6.5里，各时区的时间是在一个叫/usr/share/zoneinfo/的文件夹下，在里面我们发现了我们的目标—-UTC，如图： 然后就是修改，方法如下： 12mv /etc/localtime /etc/localtime-bakln -s /usr/share/zoneinfo/UTC /etc/localtime 先把老的时间文件备份，然后把UTC文件做一个软连接过来即可。我们所熟悉的date命令就是/etc/localtime的输出结果。 现在去date一下，看看结果，果然改成了UTC： 这个时候，如果你服务器里装的是nginx的话，就会发现nginx日志里的时间也会变成UTC而不会再是CST了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"},{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"阿里云购买、启动、停止ecs等等操作的python脚本","slug":"阿里云购买、启动、停止ecs的python脚本","date":"2018-01-24T14:52:41.000Z","updated":"2018-01-25T04:47:44.335Z","comments":true,"path":"2018/01/24/阿里云购买、启动、停止ecs的python脚本/","link":"","permalink":"http://yoursite.com/2018/01/24/阿里云购买、启动、停止ecs的python脚本/","excerpt":"","text":"以下所有脚本都是在python 2.7的环境亲自测试的。阿里云的ak/sk是没有地域概念的，在任何地域都可以使用。 购买服务器以在新加坡购买服务器为例子： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#注意！服务器创建完毕之后，状态是关机的。from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionfrom aliyunsdkecs.request.v20140526 import CreateInstanceRequest# 创建 Client 实例clt = client.AcsClient('阿里云ak','阿里云sk','新加坡的地域') #各地域的缩写请看：https://help.aliyun.com/document_detail/40654.html?spm=5176.doc25499.2.14.yh6n8c# 创建 request，并设置参数request = CreateInstanceRequest.CreateInstanceRequest()# 设置ECS细节request.set_ImageId(\"centos_7_04_64_20G_alibase_201701015.vhd\") #这里是镜像request.set_InstanceName(\"xjp-test-001\") #这里写名称request.set_SecurityGroupId(\"sg-23t6c6mjw\") #这里是安全组request.set_Password(\"W2.bi7FX1dyb)T3Wh^,[\") #这里是密码，推荐使用https传输，安全request.set_InstanceChargeType(\"PrePaid\") #确定是包年包月request.set_Period(\"2\") #先买两个月的request.set_SystemDiskCategory(\"cloud_efficiency\") #注意，如果是海外的机器的话，要额外说明，海外的机器只有高速云盘和SSD盘# 设置实例规格request.set_InstanceType(\"ecs.s2.large\")# 发起 API 请求并打印返回response = clt.do_action_with_exception(request)print response 服务器停机1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StopInstanceRequestlist1 = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list1: shutdown = StopInstanceRequest.StopInstanceRequest() shutdown.set_InstanceId(i) action = clt.do_action_with_exception(shutdown) print \"现在停机:\" + i print action 服务器启动1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StartInstanceRequestlist = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list: start = StartInstanceRequest.StartInstanceRequest() start.set_InstanceId(i) action = clt.do_action_with_exception(start) print \"现在启动:\" + i print action 查询阿里云镜像123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeImagesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeImagesRequest.DescribeImagesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 查询服务器规格123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeInstanceTypesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeInstanceTypesRequest.DescribeInstanceTypesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 参考资料https://help.aliyun.com/document_detail/25499.html?spm=5176.doc25501.6.857.wR0MHP","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"阿里云api","slug":"阿里云api","permalink":"http://yoursite.com/tags/阿里云api/"}]},{"title":"Crontab里解决脚本时间重叠的问题","slug":"Crontab里解决脚本时间重叠的问题","date":"2018-01-24T06:17:32.000Z","updated":"2018-01-24T06:26:57.148Z","comments":true,"path":"2018/01/24/Crontab里解决脚本时间重叠的问题/","link":"","permalink":"http://yoursite.com/2018/01/24/Crontab里解决脚本时间重叠的问题/","excerpt":"","text":"正文Linux里的Crontab是一个好东西，但是它的默认最小执行频率是1分钟，但是我们在实际生产环境里有的时候遇到的脚本执行时间是大于1分钟的，这样就会出现一个很尴尬的情况，就是在1分钟过后，系统进程会出现多个脚本，neck and neck式的在后台运行，比如这样： 从上面的图可以看到，10点36分log499.sh没有执行完毕，10点37又开始了执行了一个新的log499.sh脚本。这种脚本冲突肯定不是我们所希望的，那么如何才能保证后台只是在一段时间里只执行一个脚本呢？ 这个时候我们就要使用文件锁，flock，这种方法要比判断pid高大上的多。 首先假设我们的脚本名字叫abc.sh，这个脚本文件的执行时间是要大于1分钟的，同时我们再设定一个锁文件，位置就叫/tmp/abc.lock,这个文件可以是空的，然后crontab -e，添加一句命令如下： 1* * * * * flock -xn /tmp/abc.lock -c 'sh /路径/abc.sh &gt;&gt; /记录日志的路径 2&gt;&amp;1' 这个时候静候crontab启动abc.sh，通过ps -ef|grep abc，发现在后台始终只有一个abc进程。 但是有的时候会有这样的一个问题，就是abc执行一次之后，在下一次该执行的时候却没有执行，好像crontab失效了一样，对于这样的情况，就需要添加下面的语句到abc.sh末尾： 123rm -rf /tmp/abc.lock #删除掉原有的锁文件sleep n #睡n秒touch /tmp/abc.lock #再新建一个锁文件 这样不断地更新lock锁文件，就会保证crontab每次都会按期执行。 这里要注意一下，里面我加了一句sleep n，这里的n是为了跨分钟的存在，这是为了防止没有走到下一个分钟又会生成一个新的lock锁文件，这样还是会出现重复启动脚本的情况。 这里就涉及到flock的一个原理：在每一次执行任务的时候都会先去尝试取到锁文件，如果取到了锁文件，那么就会下一步，反之就会放弃执行。A任务在运行的时候已经占据了lock文件，那么B任务来了，发现没有lock了，就不会执行任务。 这里我们使用了flock的三个参数： 123-x, --exclusive: 获得一个独占锁-n, --nonblock: 如果没有立即获得锁，直接失败而不是等待-c, --command: 在shell中运行一个单独的命令 当然，flock还是有很多丰富的参数可以供各位使用，大家就各自去google一下吧。 参考资料http://blog.csdn.net/fdipzone/article/details/38284009http://chuansong.me/n/285635151949https://segmentfault.com/q/1010000008039907","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"crontab","slug":"crontab","permalink":"http://yoursite.com/tags/crontab/"},{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"}]},{"title":"yum提示Error: rpmdb open failed","slug":"yum提示Error-rpmdb-open-failed","date":"2018-01-24T06:09:35.000Z","updated":"2018-01-25T09:35:20.166Z","comments":true,"path":"2018/01/24/yum提示Error-rpmdb-open-failed/","link":"","permalink":"http://yoursite.com/2018/01/24/yum提示Error-rpmdb-open-failed/","excerpt":"","text":"今天在一台机器里，使用yum安装的时候，出现了如下的故障： 这种情况就是RPM数据库被破坏了，这个时候就需要我们重建数据库，于是就输入如下的命令： 1234cd / var / lib / rpm /for i in ` ls | grep 'db.' ` ; do mv $i $i .bak ; donerpm -- rebuilddbyum clean all 重新cleanup就正常了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"yum","slug":"yum","permalink":"http://yoursite.com/tags/yum/"}]},{"title":"由一个实例浅析sed用法","slug":"由一个实例浅析sed用法","date":"2018-01-23T14:27:54.000Z","updated":"2018-01-24T05:56:59.068Z","comments":true,"path":"2018/01/23/由一个实例浅析sed用法/","link":"","permalink":"http://yoursite.com/2018/01/23/由一个实例浅析sed用法/","excerpt":"","text":"首先，假设我们有一个文件，叫123.txt，cat一下看到里面的内容是这样的： 12345678[root@func-lms-001 ~]# cat 123.txt jamescurry durantwadeyaoming messi[root@func-lms-001 ~]# 如果我们想在james前面加上lebron，那么采用的sed语句就是：sed -i &#39;/^james/s/^/lebron /&#39; 123.txt，如果要在curry后面加上champion，那么采用的语句就是：sed -i &#39;/^curry/s/$/ champion!/&#39; 123.txt。 使用完上面两句话之后，再#cat一下，看下效果： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion! durantwadeyaoming messi[root@func-lms-001 ~]# 现在我们要把durant前面加上FMVP这几个字母，按照上面的语句找葫芦画瓢的话，应该是：sed -i &#39;/^durant/s/^/FMVP /&#39; 123.txt。但是很抱歉，这个语句是错误的！因为^是匹配开头durant的意思，而我们再看一下durant那一行的开头是空格。 那么就要用liunx的正则来匹配空格，于是这句话就变成了：sed -i &#39;/^\\s\\+durant/s/^/FMVP/&#39; 123.txt，^\\s\\+这个就是正则里匹配空格的意思 。 cat一下： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion!FMVP durantwadeyaoming messi[root@func-lms-001 ~]# 那么现在要在messi后面加上”GOAL !!!”，就很简单了。语句是：sed -i &#39;/^\\s\\+messi/s/$/ GOAL !!!/&#39; 123.txt。 以上我们把有/无空格情况下的首尾添加字符都练习了一遍，下面我们要看看如果要在中间添加怎么办？ 比如说，有一天苦逼的运维接到开发PL的邮件，说”由于安全基线要求，现在需要监听内网端口“，具体的需求就是把所有含tomcat的模块里的server.xml的文件里添加上内网IP。 原有的server.xml的节选如下： 12345678910&lt;Service name=\"LMS\"&gt; &lt;Connector port=\"8080\" connectionTimeout=\"20000\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"8443\" enableLookups=\"false\" disableUploadTimeout=\"true\" maxThreads=\"500\" minSpareThreads=\"20\" acceptCount=\"100\"/&gt; &lt;Connector port=\"8088\" connectionTimeout=\"20000\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"8443\" enableLookups=\"false\" disableUploadTimeout=\"true\" maxThreads=\"500\" minSpareThreads=\"20\" acceptCount=\"100\"/&gt; &lt;Connector port=\"8099\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; &lt;Engine defaultHost=\"localhost\" name=\"Catalina\"&gt; &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"&gt; &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\" /&gt; &lt;/Realm&gt; 现在要把&lt;Connector port=&quot;8099&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;这一句里面加上内网IP:1.2.3.4，改成这样： 12345678910&lt;Service name=\"LMS\"&gt; &lt;Connector port=\"8080\" connectionTimeout=\"20000\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"8443\" enableLookups=\"false\" disableUploadTimeout=\"true\" maxThreads=\"500\" minSpareThreads=\"20\" acceptCount=\"100\"/&gt; &lt;Connector port=\"8088\" connectionTimeout=\"20000\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"8443\" enableLookups=\"false\" disableUploadTimeout=\"true\" maxThreads=\"500\" minSpareThreads=\"20\" acceptCount=\"100\"/&gt; &lt;Connector port=\"8099\" address=\"1.2.3.4\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; &lt;Engine defaultHost=\"localhost\" name=\"Catalina\"&gt; &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"&gt; &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\" /&gt; &lt;/Realm&gt; 请问怎么做？ 答案1： 1sed -i '/&lt;Connector port=\"8099\"/s/port=\"8099\"/port=\"8099\" address=\"1.2.3.4\"/g' server.xml 答案2： 1sed -i 's@Connector port=\"8099\"@&amp; address=\"1.2.3.4\"@' server.xml","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"Zabbix添加网卡内外流量监控","slug":"Zabbix添加网卡内外流量监控","date":"2018-01-23T13:41:12.000Z","updated":"2018-01-23T13:51:44.231Z","comments":true,"path":"2018/01/23/Zabbix添加网卡内外流量监控/","link":"","permalink":"http://yoursite.com/2018/01/23/Zabbix添加网卡内外流量监控/","excerpt":"","text":"现在笔者想对host名单里面的zabbix_server进行网卡的内外流量情况的一个监控，首先登录zabbix之后，configuration—hosts，出现如下的菜单： 现在可以看到这个zabbix_server后面link了很多个模板，正是因为link了很多的模板，所以导致它的items非常多，42个。现在是要在zabbix_server里添加两个新的监控项，这一步跟模板其实没有什么关系，只需要在items里直接添加items即可。 我们先添加网卡外流量的items，整个配置如图所示： 里面具体的数值可以自己更换，比如Applications什么的，key\\units\\Use custom multiplier这些是固定的，全部写完之后就可以save。 找葫芦画瓢，我们可以再添加一个网卡的内流量监控，也是一样的套路，如图所示： 有了items，就要有trigger，有了items里的key，那么trigger也很简单，这里的expression多时候各位都是从网上ctrl+c下来，却不能ctrl+v，因为会红字报错—-Incorrect item key &quot;net.if.in[eth0,bytes]&quot; provided for trigger expression on &quot;服务器名称&quot;，于是就有很多不明真相的吃瓜群众就走“add”路线，然后发现要走add路线还要先把服务器添加到对应的模板上去。其实大可不必，这个expression是可以自己写的，但是一定要确定trigger跟items是配对的。以外网流量所示： 在这里我添加成了1K，这样是为了方便监控，具体数值因情况而异，而且重要性我选择了无。 最后就是要形成图表来糊弄领导，让领导感受一下什么叫做高大上，在graph的界面里选择create graph，然后就如图所示的填写： 一个是红色线，一个是绿色线，双龙戏珠，save。 最后来到Monitoring—Graphs里，找到正确的host,group和graph，就会看到激动人心的图表了： 这里要注意几点，有时候zabbix反应较慢，可能写好的key会出现not support的情况，这个时候可以先登录zabbix_server去zabbix_get一下，zabbix_get的方法之前有讲过，请见http://chenx1242.blog.51cto.com/10430133/1738820 ，如果zabbix_get是成功返回值的，先检查对应的单位（结果是浮点值，但是units设定是一个整数值肯定会not support）,如果单位检查正确，就修改zabbix重新check的时间，实在不行就重新建立一个items。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"服务器监控","slug":"服务器监控","permalink":"http://yoursite.com/tags/服务器监控/"}]},{"title":"使用Nessus进行漏洞扫描的过程","slug":"使用Nessus进行漏洞扫描的过程","date":"2018-01-23T04:53:51.000Z","updated":"2018-01-23T06:04:53.571Z","comments":true,"path":"2018/01/23/使用Nessus进行漏洞扫描的过程/","link":"","permalink":"http://yoursite.com/2018/01/23/使用Nessus进行漏洞扫描的过程/","excerpt":"","text":"对于一个服务器运维工作者，掌握和运用一门漏洞扫描的工具也是行走江湖的必备项，Nessus就是漏洞扫描的强力武器。Nessus为一款当下比较流行的系统弱点扫描与分析软件，他的优点是操作简单（配置几乎全web化），而且页面精美、扫描项广泛；缺点就是目前不支持中文… 下载与安装要安装Nessus，需要登陆https://www.tenable.com/products/nessus/select-your-operating-system,选择对应的系统，我这个服务器是centos 7，那么就选择下图里红色的那个rpm包： 点击之后，出来一个同意条款，同意之后就开始自动下载。但是要安装nessus仅仅有程序是不够的，还需要一个对应的验证码，在上面那个界面里，下拉一点有一个get an activation code的check，点击之后跳转到https://www.tenable.com/products/nessus/nessus-plugins/obtain-an-activation-code，里选择家用free版，点击下面的register now： 注册是很简单的，填写名称和电邮就可以了。不久后就会在电子邮件里面获得一个校验码。 把下载的那个Nessus-6.11.1-es7.x86_64.rpm包上传到centos之后，rpm -ivh Nessus-6.11.1-es7.x86_64.rpm进行安装，安装完成之后，service nessusd start启动进程，启动完毕之后，使用netstat -lnpt|grep 8834，来检查一下8834端口是否被监听，如图： 端口监听OK，那么在浏览器里输入https://服务器外网IP地址:8834打开控制web界面，如果有提示当前连接不安全，无视掉就可以。nessus的欢迎界面如下： 注册一个账号之后，在这个界面里面选择home那一条，输入邮箱里面获得的那个注册码： 整个的配置就完事了，继而就是nessus自动安装的过程，大约需要几分钟： 整个安装完毕之后，就会看到nessus的主界面，简单明了的风格： 至此整个nessus的安装过程结束。 配置扫描策略以及启动扫描任务nessus扫描漏洞的流程很简单：需要先”制定策略”，然后在这个策略的基础上建立”扫描任务”，然后执行任务。首先，我们先建立一个policy，如图： 点击New Policy之后，就会出现很多种扫描策略，这里我们选择Advanced Scan(高级扫描)： 我给这个测试的扫描策略，起名叫”chenchenchen”，如图： 对于上面这个图，Permissions是权限管理，是否可以准许其他的nessus用户来使用你这个策略；Discovery里面有主机发现、端口扫描和服务发现等功能；assessment里面有对于暴力攻击的一些设定；Report里面是报告的一些设定；Advanced里面是一些超时、每秒扫描多少项等基础设定，一般来说这里默认就好。我们主要来看看那个plugins。 Plugins里面就是具体的策略，里面有父策略，具体的父策略下面还有子策略，把这些策略制定得体的话，使用者可以更加有针对性的进行扫描。比如我这个策略是针对于centos系统的扫描策略，那么一些冗余的项目大可以完全不要，举个例子： 在上面这个图里面，我不需要amazon linux local security checks这个“亚马逊linux本地安全检查”父策略，那就把它disabled掉，而对于centos local security checks这个父策略呢，我又不需要那几个关于bind的子策略，那我就单独把那些子策略disabled掉，这样等等操作，就搭配成为了一个用时不长但是又包含了所有制定的检查项的策略，然后点击save保存。 保存完后，我们就发现policy里多了一条chenchenchen的记录： 既然策略有了，现在我们就来制定一个任务。在主界面里选择My Scans,点击New Scans,这个时候还是有很多个图标，但是我们选择后面的User defined，如图： 这里我们就看到了我们已经制定好的那个chenchenchen策略，点击这个chenchenchen之后，就要给这个依赖chenchenchen策略的任务起名字以及需要扫描的网络段，由于我这个测试机的内网ip段是10.132.27.0，于是我就写了“10.132.27.0/24”，任务名字叫chentest： 启动扫描任务点击save保存之后，就会看到My Scans里多了这个chentest的任务，点击三角播放箭头，那么这个任务就开始执行了！如图： 从该界面可以看到扫描任务的状态为Running（正在运行），表示chentest扫描任务添加成功。如果想要停止扫描，可以单击方块（停止一下）按钮。如果暂停扫描任务，单击暂停按钮。 扫描完毕之后，我们就会看到一个结果反馈，如图： 具体的颜色代表，在旁边有描述，例子里这些蓝色的info代表没有重大漏洞，点击一下蓝色，还会出现更加详细的信息，包括IP地址、操作系统类型、扫描的起始时间和结束时间： 同时，nessus还支持pdf、web、csv等多种方式汇报扫描结果，至此，整个nessus漏洞扫描的全过程就结束了。 Nessus配置smtpNessus漏洞扫描是提供邮件服务，可以将扫描的结果发送给指定的邮箱。配置它的方法很简单，先登陆Nessus的界面，点击左上角的settings，然后选择左侧菜单栏里的Smtp server，如图： 再就是填写对应的项目，我这里发送邮件的地址是：chenx3314@sina.com，接受的地址是124208739@qq.com，由于发送邮件使用的是新浪的邮箱，那么host就填写新浪的smtp服务器，即smtp.sina.com，如果是要SSL加密的话，端口写465，同时在Encryption那里选择Force SSL，在Auth Method那里选择login的鉴权方式，然后输入chenx3314@sina.com的账号密码，如图： 点击Send Test Email，然后输入接收的邮箱，如果是多个邮箱那么就用英文逗号隔开。看到成功的提示就是OK了： 然后就可以到邮箱里面看到那个测试的邮件内容：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"nessus","slug":"nessus","permalink":"http://yoursite.com/tags/nessus/"}]},{"title":"mysql清除磁盘碎片","slug":"mysql清除磁盘碎片","date":"2018-01-23T02:44:23.000Z","updated":"2018-01-23T06:47:49.775Z","comments":true,"path":"2018/01/23/mysql清除磁盘碎片/","link":"","permalink":"http://yoursite.com/2018/01/23/mysql清除磁盘碎片/","excerpt":"","text":"任务背景接到金山云报警短信，说某数据库的容量已经达到了90%的水位线，于是登陆控制台查看详细情况。 在控制台首先发现，每一天的磁盘容量的确有所波动，那么就证明开发人员写的“资源回收”模块是在正常运行的，如图： 那么就说明没有什么数据是可以删的，既然删不掉多余的数据又不想多掏钱扩磁盘容量，只能从“磁盘碎片”下手了。而InnoDB引擎清理磁盘碎片的命令就是OPTIMIZE。 具体操作首先我先查询一下所有的“磁盘碎片情况”，使用语句如下： 1select CONCAT(TABLE_SCHEMA,'.',TABLE_NAME) as 数据表名,concat(truncate(sum(DATA_LENGTH+DATA_FREE+INDEX_LENGTH)/1024/1024,2),' MB') as total_size, concat(truncate(sum(DATA_LENGTH)/1024/1024,2),' MB') as data_size,concat(truncate(sum(DATA_FREE)/1024/1024,2),' MB') as data_free, concat(truncate(sum(INDEX_LENGTH)/1024/1024,2),'MB') as index_size from information_schema.tables group by TABLE_NAME order by data_length desc; 或者使用select table_schema, table_name, data_free, engine from information_schema.tables where table_schema not in (&#39;information_schema&#39;, &#39;mysql&#39;) and data_free &gt; 0;也可以，这个是查询data_free大于0的所有表。 然后看到我这个叫history_device_flow_day的表里情况如下： 表里的data_free就是磁盘碎片的量，比如我现在要干掉history_device_flow_day里所有的磁盘碎片，是975MB，于是先查询一下这个history_device_flow_day的存储引擎，使用语句如下： 1show table status from jsonlinefssrds where name='history_device_flow_day'; 上面语句里的jsonlinefssrds是对应的数据库，看到的效果如下： 存储引擎是InnoDB，那么就可以启动清除碎片的语句了：OPTIMIZE TABLE 数据表表名;，因为OPTIMIZE TABLE只对MyISAM、BDB和InnoDB表起作用。 再执行了OPTIMIZE TABLE history_device_flow_day;之后，大约9分钟，就会看到“OK”的字样： 估计有的朋友会问，那上面不是明明写了“Table does not support optimize, doing recreate + analyze instead”吗？这个其实无妨，实际上磁盘碎片已经被清除掉了。我们可以再用一次查询磁盘碎片的命令看一下，如图： 的确释放了900多M。 或者使用ALTER TABLE 表名 ENGINE = Innodb;（只是InnoDB的表可以这么做，而且据说这么做更友好）来达到清理磁盘碎片的目的，这个命令表面上看什么也不做,实际上是重新整理碎片了。当执行优化操作时,实际执行的是一个空的ALTER命令,但是这个命令也会起到优化的作用,它会重建整个表,删掉未使用的空白空间。 补充为什么会产生磁盘碎片？那是因为某一个表如果经常插入数据和删除数据，必然会产生很多未使用的空白空间，这些空白空间就是不连续的碎片，这样久而久之，这个表就会占用很大空间，但实际上表里面的记录数却很少，这样不但会浪费空间，并且查询速度也更慢。 注意！OPTIMIZE操作会暂时锁住表,而且数据量越大,耗费的时间也越长,它毕竟不是简单查询操作。所以把OPTIMIZE命令放在程序中是不妥当的,不管设置的命中率多低,当访问量增大的时候,整体命中率也会上升,这样肯定会对程序的运行效率造成很大影响。比较好的方式就是做个shell,定期检查mysql中 information_schema.TABLES字段,查看DATA_FREE字段,大于0的话,就表示有碎片，然后启动脚本。 参考资料http://pengbotao.cn/mysql-suipian-youhua.htmlhttp://irfen.me/mysql-data-fragmentation-appear-and-optimization/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"一道传说中是百度面试的shell试题","slug":"一道传说中是百度面试的shell试题","date":"2018-01-23T01:37:31.000Z","updated":"2018-01-23T01:45:15.170Z","comments":true,"path":"2018/01/23/一道传说中是百度面试的shell试题/","link":"","permalink":"http://yoursite.com/2018/01/23/一道传说中是百度面试的shell试题/","excerpt":"","text":"【问题】写脚本实现，可以用shell、perl等。把文件b中有的，但是文件a中没有的所有行，保存为文件c，并统计c的行数。翻译成人话就是，假设有一个文件a是:abcd 文件b是:1234ab 现在要求输出“b有a没有”的行，即1 2 3 4，然后wc -l一下。 【思路】两个文件比较，第一想法就是diff，但是diff无论是-c还是-y会牵扯进大量的&gt; &lt; + -不说，而且diff命令是直白对比，即使字母相同但所在行不同，也会被diff记录。如果再用for in语句然后一项一项对比也不会很清晰的解决这个问题，所以要换个方法。 第二个方法就是comm命令，但是这个命令有一个前提，就是要sort排序，comm比diff高明之处在于它只比较内容而不在意是否同一行，但是要注意对比文件的先后。comm -12 a b是找”a和b都有”的项，comm -23 a b就是找”a有而b没有”。 【解答】perl我不会，我就用shell写： 123456#!/bin/bash#written by ChrisChan @ 2016-4-21sort a.txt&gt;a1.txt #排序，不然会有提示sort b.txt&gt;b1.txtcomm -23 b1.txt a1.txt &gt;c.txt #由于是要找b有a没有的,就要b写在前，a写在后echo $(cat c.txt|wc -l) 其实还有一个更简单的，只用一句话: 1grep -v -x b.txt -f a.txt|wc -l 很多书上不写grep -x -f的意思，这里补一下：-f:指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。-x:只显示全列符合的列。 从一个题就能轻松看出shell的能力级别，用diff死纠缠就是初级，用comm就是中级，而grep就是高级。的确是一个好题。 【补充】如果考python，求这种类似“你有我没有”的东西，用set里面的差集算法。 12345678910&gt;&gt;&gt;A=&#123;1，2，3，4&#125;&gt;&gt;&gt;B=&#123;3，4，5，6&#125;&gt;&gt;&gt;print(A-B)set([1,2]) #A有B没有&gt;&gt;&gt;print(A ^ B)set([1,2,5,6]) #差集的补集&gt;&gt;&gt; A&amp;B&#123;3, 4&#125; #交集&gt;&gt;&gt; A|B&#123;1, 2, 3, 4, 5, 6&#125; #全集","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"面试经验","slug":"面试经验","permalink":"http://yoursite.com/tags/面试经验/"}]},{"title":"解决Zabbix在web界面中文显示的问题","slug":"解决Zabbix在web界面中文显示的问题","date":"2018-01-22T03:31:40.000Z","updated":"2018-01-22T04:42:32.036Z","comments":true,"path":"2018/01/22/解决Zabbix在web界面中文显示的问题/","link":"","permalink":"http://yoursite.com/2018/01/22/解决Zabbix在web界面中文显示的问题/","excerpt":"","text":"注意！这个是解决web界面中文显示乱码的问题，不是zabbix web界面全中文汉化的问题。 2.2版本的处理方法zabbix里给host或者item等项目起中文名字的时候，可能在graph上无法正确显示中文字符，如图： 那么遇到这样的情况其实很简单，就是zabbix的web界面没有安装中文字库的问题，那就对症下药，下载中文字库。 中文字库的下载地址在这里：http://linux.linuxidc.com/2012%E5%B9%B4%E8%B5%84%E6%96%99/11%E6%9C%88/22%E6%97%A5/Zabbix%E4%B8%AD%E6%96%87%E4%B8%8D%E8%83%BD%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98/ ，下载“LinuxIDC.com下载-kaiti.tar.gz”。 后把这个文件改一下名，可能很多linux不识别那个中文字“下载”,mv LinuxIDC.com下载-kaiti.tar.gz kaiti.tar.gz，tar -zxvf kaiti.tar.gz 然后就会发现当前路径里生成了一个叫kaiti.ttf，这个就是我们所需要的中文“楷体”字体文件。 来到zabbix的web字体路径，在我的机器里，这个负责字体的文件夹叫/usr/local/nginx/html/zabbix/fonts/。虽然各位安装zabbix的路径各有差别，但是这个文件夹一般都是在nginx or apache的html下，所以很好找的。 在这个fonts文件夹里默认已经有一个叫DejaVuSans.ttf的文件了，于是就把这个kaiti.tff也放到这个文件夹下。 光有字体文件没有用，还需要在配置文件里使用这个字体文件，于是就vim一下同样在nginx or apache/html/zabbix/include的defines.inc.php。把里面所有的DejaVuSans替换成kaiti，.tff这个后缀是不用加的。然后保存退出，重新刷一下界面就看到效果了。 vim的替换语句 :%s/DejaVuSans/kaiti/g 3.x版本的处理方法现在zabbix已经升级到3.x了，上述的方法已经失效了，这里记录一下新的中文配置方法。 首先从windows里，拷贝一个中文字体的文件到zabbix的服务器的/usr/share/zabbix/fonts文件夹里，比如我先择了“楷体”，这个文件叫simkai.ttf，chmod +x simkai.ttf 给予可执行权限。 然后vim /usr/share/zabbix/include/defines.inc.php，修改两处地方，分别是第四十五行，把原来的改成simkai，如图： 还有一处就是第九十三行，也是改成SIMKAI： 保存文件之后，刷新一下zabbix界面即可。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"运维与监控","slug":"运维与监控","permalink":"http://yoursite.com/tags/运维与监控/"}]},{"title":"防盗链的等等相关","slug":"防盗链的等等相关","date":"2018-01-22T01:48:38.000Z","updated":"2018-01-22T02:27:02.701Z","comments":true,"path":"2018/01/22/防盗链的等等相关/","link":"","permalink":"http://yoursite.com/2018/01/22/防盗链的等等相关/","excerpt":"","text":"为什么网站们都要限制流量？无论是网站服务器亦或是游戏服务器还是邮件服务器，说穿了也是一台电脑，也有CPU和内存。只不过服务器的CPU功能比个人电脑的CPU功能强大，比如个人电脑的CPU一秒钟能算1亿个数，那么服务器的CPU一秒钟就能算十亿个数。毕竟个人电脑只针对个人，但是服务器是要“接客”的，有了强大的硬件做后盾，网页/游戏/邮箱才不会那么轻易的Down掉。 但是CPU不是人类大脑，人脑是越用越聪明，CPU是越用越磨损，毕竟始终在连电的环境下。于是乎，没有必要的运算能省就省，一个人省一次，十万个人就省十万次，一千万个人就省一千万次，这样达到积少成多的目的。 CPU计算的是各种数据，而这些数据也叫作流量。有用的流量、有价值的流量通过CPU计算无可厚非，但是出现了没有用的流量或者是别人盗用我们的资源，那么这种情况能避免都要避免。什么叫盗用我们的资源，比如自己网站（网站A）上的图片或者视频，被其他人直接复制网站然后粘贴到他们的主页（网站B）上，其他用户登录了B网站，然后点击了那个图片和视频，由于是网址重链接，里外里提供数据的还是我们的服务器。也就是说B网站就是一个中介，而真正提供服务的是网站A，但是广告费和点击率都要网站B赚走了，这事儿实在是叔可忍婶不可忍。 什么是盗链？如何发现被盗链？什么叫盗链，上面已经说的差不多了，如果上面的文字没有看懂的话，举个例子，如果您看到了这两个图片，证明这个网站就是在盗链。 这两个就是一个盗取的是QQ空间的图片，另一个就是百度的图片。用其他网站的图片这事儿本身是无所谓的，只要不涉及版权问题，都希望自己的作品能广泛传播，但是请不要直接通过网址重定向，厚道一点的行为应该是：“图片另存为”，然后到目标网站上去重新上传一下。 这里再多说一点网站的基础知识。 PV值：PV=page view，网站是有少则一个网页多则N多网页组成的一个整体，PV值就是统计用户访问网站的总页数。比如www.JQK.com这个网站，今天有100个用户登录，平均每个用户翻阅了里面5个网页。那么这个网站的PV值就是500。若一个IP地址，对一个页面刷新10000次，PV值也是1.要查询网站的PV值登陆http://www.alexa.cn就行。 Hit值：这个就是对网页里每个元素的点击量，一个网页里的图片就是一个元素，一个flv文件也是一个元素，一首歌曲也是一个元素。这些的总量就是hit值，hit值越高就证明这个网站被人查看的情况越高，那么也证明网站的高人气，那么自然广告也会卖出去很多钱。 因为建网站这事儿关心到了金钱利益，网站越被人关注，自然价值也越大。于是会有一个公式来评判网站的“每日贡献”：总流量=访问流量+下载流量= Page view值 x 页面大小+下载文件大小 x 下载次数 作为管理者，每天观察一下自己一亩三分地儿的网站数据情况是本职工作。但是有时候也会遇到网站流量很惊人的情况，一般来说，网站流量过大（CPU运转很多）的原因如下： 1）网站是一个很大的网站：比如说淘宝，京东，网易，youtube,facebook那种大网站，里面成万上亿的网页，而且每天又有那么多人登陆，自然浏览量很大。虽然这些大集团的服务器也是少则几千，多则上万，甚至在不同地区也会有不少的服务器集群，但是这几万台服务器需要提供的数据会很多也是不争的事实。这种现象是正常的。 2）网页内容太大：可能本身网站是一个小网站，加起来也就十页二十页的内容，但是每一天的流量依旧很惊人，那么很有可能是单页或者某几页的字节太大。比如网页里有太多的图片，太多的视频，太多的其他链接，也有可能是前端码农们给这个网页的规划不合理。导致这个网页每一次被点击都要大费周折（hit值和PV值不高，但是日流量很高），长此以往不仅会耽误用户的整体体验，对服务器也是一个重大伤害。 3）搜索引擎产生了大量的数据流量：网站需要推广，于是就在各种搜索引擎上打广告，也有自己网站的很多图片用于外部调用。这样的结果就是本身来观摩网站的人很少，但是“借着引擎经过”的人很多，所以就会有PV值不高，但是Hit值和日流量很高的现象出现。 4）图片或者其他元素被盗链：第一部分就说过了，别人拿我们的图片去吸引别人关注，然后别人想要深入了解，还要来使用我们的服务器去提供详细数据。这种“用我们的牌子住我们的房，吃我们的饭却不给我们钱”的现象实在应该被弄死。这种现象的特征也是PV值不高（没人真正点击网站），但是Hit值和日流量很大（自己服务器的数据都给别的网站提供了）。 5）网站被DDos攻击了：被一些恶意的IP地址频繁登陆，来回的刷流量。这样迫使CPU做出运算的行为其实就是在远程的破坏服务器的硬件CPU，遇到这种现象，之前Nginx文章里有写，要么通过access.log找到这些IP封掉，要么就在配置文件里加上限制limit-rate。 服务器是如何知道图片是从站外而来的呢？在http协议里有一个重要的选项叫refer，这个选项的内容就是该元素的来源地址。如果这个元素是服务器自己提供的，那么头文件里是没有refer这个选项的。通过refer这个信息，我们也可以知道登陆网站的客户是从哪个网站点击链接而来的。这样方便进行一个统计和规划。 假如，我在QQ空间里面发现一个图，然后右键图片，选择”在新标签栏里打开图片”，这时候通过浏览器“审查元素”的功能，能查查看请求头信息和响应头信息，发现响应头信息里多了一个refer，里面的内容就是图片的源地址： 我在QQ空间里看腾讯的照片自然是可以的，但是如果我在别的网站里看腾讯的照片，加重了腾讯服务器的负担，自然腾讯公司会不满意。于是腾讯服务器发现当前要引用这个图片的地址与refer头信息不是一个来源之后，就不会把这个图片的数据传送过来，于是就看到那个“此图片来自QQ空间，未经准许不可饮用”的警告图片。 既然知道了服务器是如何判断文件是否盗链，那么只要伪装一个refer就可以欺骗服务器达到“反防盗链”的目的了。至于这部分，可以自己单独研究。如何使用Nginx反盗链？ 同样的使用Nginx.conf，在http的大括号下面，新建一个location，加入如下信息： 12345678910111213141516location ~ .*\\.(wma|wmv|asf|mp3|mmf|zip|rar|jpg|gif|png|swf|flv)$ &#123;#指定对以上几种类型的文件建立防盗链 valid_referers none blocked *.alala.com alala.com;#盗链的范围不包括alala.com和alala.com下的二级网站， if($invalid_referer) &#123; #rewrite ^/ http://www.alala.com/error.html; return403;#如果发现有引用以上文件的地址与refer头信息不符的情况，直接重定向成error.html这个网页，服务器返回403，forbidden。 &#125;&#125; 使用第三方模块ngx_http_accesskey_module实现Nginx防盗链实现方法如下： 下载NginxHttpAccessKeyModule模块文件：http://wiki.nginx.org/File:Nginx-accesskey-2.0.3.tar.gz； 解压此文件后，找到nginx-accesskey-2.0.3下的config文件。编辑此文件：替换其中的$HTTP_ACCESSKEY_MODULE为ngx_http_accesskey_module； 用一下参数重新编译nginx： ./configure –add-module=Nginx目录/to/nginx-accesskey然后执行: make &amp;&amp; make install 修改nginx的conf文件，添加以下几行： 123456location /download &#123; accesskey on; accesskey_hashmethod md5; accesskey_arg \"key\"; accesskey_signature \"mypass$remote_addr\";&#125; 其中：1.accesskey为模块开关；2.accesskey_hashmethod为加密方式MD5或者SHA-1；3.accesskey_arg为url中的关键字参数；4.accesskey_signature为加密值，此处为mypass和访问IP构成的字符串。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"http","slug":"http","permalink":"http://yoursite.com/tags/http/"},{"name":"网络相关","slug":"网络相关","permalink":"http://yoursite.com/tags/网络相关/"}]},{"title":"记录一次配置http跳转https的过程","slug":"记录一次配置http跳转https的过程","date":"2018-01-18T09:33:31.000Z","updated":"2018-01-22T02:35:54.038Z","comments":true,"path":"2018/01/18/记录一次配置http跳转https的过程/","link":"","permalink":"http://yoursite.com/2018/01/18/记录一次配置http跳转https的过程/","excerpt":"","text":"公司最近搞了一个数据运营平台，这个平台会以web界面的形式把各个数据展示出来，这个项目是我们一个经理的重点关照项目。把平台模块部署完毕并且启动之后，又把这个平台服务器的外网IP绑定到alkaid.lechange.com这个域名上，在浏览器里输入https://alkaid.lechange.com,就看到了前端同行们写的网页。 但是我们的霸气经理说这样不行，说要更多要求更高标准更好体验，于是乎提出一个需求就是：在输入alkaid.lechange.com的时候会自动跳转到https://alkaid.lechange.com。 既然如此，我们就在nginx上原有的nginx.conf里补充几个配置文件： 12345#include upstreaminclude upstream.conf;# include serversinclude alkaid.conf;include alkaid-https.conf; 这样在执行nginx.conf的时候，就会调用upstream.conf、alkaid.conf和alkaid-https.conf，我们主要看一下这三个文件。 alkaid.conf文件如下： ```js server { listen 80; server_name *.lechange.com; proxy_buffering off; location / { rewrite ^/ https://alkaid.lechange.com permanent; client_max_body_size 100m; } } 这里我们监听了80端口，下面那个client_max_body_size 100m是用来设定nginx+php上传文件的大小，这里规定是100m，这个可以写进nginx.conf里，如果有对上传文件方面感兴趣，可以看http://www.cnblogs.com/zhwl/archive/2012/09/18/2690714.html 。 再来看看alkaid-https.conf，如下： ``js server { listen 10000; server_name *.lechange.com; proxy_buffering off; location / { proxy_pass http://alkaid_backend; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; } } 这里监听了10000端口，location写的是http://alkaid_backend`,这个`alkaid_backend`是啥东西? 这个时候我们就需要看一下upstream.conf，里面内容是: ```js upstream alkaid_backend { server X.X.X.X:JQK; check interval=5000 rise=2 fall=5 timeout=1000 type=tcp default_down=false; } X.X.X.X是模块服务器的内网IP地址，而JQK是模块服务器的模块端口，这里要根据实际的情况来写。可见alkaid_backend对应的就是模块服务器和它的端口，下面是检查间隔等等数值。 现在我们启动nginx，然后把nginx的外网地址绑定去alkaid.lechange.com这个域名，在浏览器里输入alkaid.lechange.com，就会达到自动跳转的目的了！ 这里要额外多说一下，我们这里设定了80的配置文件也设置了443的文件，但是这俩文件的转发过程却不同：alkaid-https.conf文件把443的请求转向了平台模块服务器的服务，而alkaid.conf文件把凡是从80端口进来的请求直接全部永久重定向到https://alkaid.lechange.com ，但是这个alkaid.lechange.com还是会去访问平台模块服务器的服务，也就是说alkaid.conf文件多了一步重定向。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"https","slug":"https","permalink":"http://yoursite.com/tags/https/"}]},{"title":"将电商平台测试环境添加了域名和https","slug":"将电商平台测试环境添加了域名和https","date":"2018-01-18T06:42:12.000Z","updated":"2018-01-22T02:35:56.432Z","comments":true,"path":"2018/01/18/将电商平台测试环境添加了域名和https/","link":"","permalink":"http://yoursite.com/2018/01/18/将电商平台测试环境添加了域名和https/","excerpt":"","text":"情况描述今天电商平台来了新的产品经理。摸了一遍情况之后，提出了两个需求，第一个是要把测试环境也要上https，达到与线上一致；第二个就是测试环境要配上域名，不要再用IP地址登陆。 配置域名是很简单的，在阿里云的云解析上直接给测试环境新加一个域名，然后对应添加阿里云外网SLB的IP地址即可。进入页面也发现首页地址显示正常，但是再点点就发现了里面有点不对。 没错，现象就是“只有首页是域名，其他网站都是IP”， 遇到这个情况，我就跑去nginx.conf里，看一下server_name的配置，看到的确写得是func.lechange.com，如图： 于是就在页面上使用ctrl+shift+c查看具体情况，发现里面的代码是这个样的： 这就人赃俱获了，开发已经在html里把地址写死了，使用了绝对路径而不是相对路径，于是就打回让开发自己慢慢改。 然后又回到SLB界面，新增新的https监听，前端端口443，后端是80，搭配正确的证书，SLB保存之后，在浏览器输入测试环境的https://网址之后，发现整个界面全乱了，如图： 但是使用http://网址去访问还是正常的，如图： 很明显，这是因为https下跨协议调用http的是不行的，所以那些css、js如果不支持https的话就无法正常显示。使用ctrl+shift+c看错误更加明显。 遇到这个问题，就有如下几种方法： 第一种：将所有的访问路径都写死https，不过这个我们公司代码规范不准许;第二种：去掉URL中的http://或https://，将其替换为//，这样，浏览器就可以根据当前页面的请求方式来动态切换了；第三种：可以在&lt;head&gt;中添加&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;upgrade-insecure-requests&quot;&gt;,浏览器会在加载HTTP资源时自动替换成HTTPS请求；第四种：在nginx里写一个proxy_redirect跳转，这个就比较有技术含量了； 参考资料https://thehackernews.com/2015/04/disable-mixed-content-warning.htmlhttps://www.tuicool.com/articles/ARVVFjIhttps://developer.mozilla.org/en-US/docs/Web/Security/Mixed_content/How_to_fix_website_with_mixed_content","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/tags/网络基础/"}]},{"title":"Linux运维工程师笔试题第十四套","slug":"Linux运维工程师笔试题第十四套","date":"2018-01-17T14:18:33.000Z","updated":"2018-01-23T14:16:45.049Z","comments":true,"path":"2018/01/17/Linux运维工程师笔试题第十四套/","link":"","permalink":"http://yoursite.com/2018/01/17/Linux运维工程师笔试题第十四套/","excerpt":"","text":"前言这几天一边看着《nginx高性能WEB服务器详解》，一边看着基础知识。那么最容易入眼的基础知识是什么呢？当然是面试题了，于是乎就找出来一些阿里（含滴滴和蚂蚁金服）的运维面试题，以题带看。 看完之后觉得阿里真的不是盖的，面试题的质量比那些晚上乱七八糟的题质量好多了，细节抠的真是非常细。我记得曾经有一个前辈曾经说过，工作中我们经常注意一些奇淫技巧，但是忽视了基础知识的重要性，现在好多程序员不会认认真真地读本书，喜欢快餐文化，受了市面上很多培训机构的影响，这是要不得的。 最后再说一句，以下所有的题都属于“开放性”试题，可以根据基本点去发散，说出你的理解和认识。但是注意，不要避重就轻耍滑头，问A，可以发散到A1、A2…但是不要发散到X、Y、Z，然后大谈特谈XYZ，这种“小聪明”就是找死的行为。 废话到此为止，上题1）http一般是无状态的，怎么让它变成有状态的？[我的答案]http跟IP、UDP一样都是无状态的，http的无状态意思是“每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是无直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况”。补充一下，TCP是有状态的，它的请求并不独立，它通过包头的一些控制字段来分别包的关系，这里可以自行脑补一下“三次握手”的图。 那么http是无状态的这一点是无法改变的，那么要变得“有状态”，就需要引入cookie和session，通过这两个机制去实现一个有状态的WEB应用。用一个表达式可以这么理解：Web应用=http协议+session、cookies等状态机制+其他辅助的机制。 2）解释一下cookie和session的区别[我的答案]Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中，session是一个抽象概念，开发者为了实现中断和继续等操作，抽象出来的一个“会话”，接上面那道题，session这个东西能不用就不要用，因为它是有状态的，服务器要维护一个有状态的东西是很消耗资源的（比如内存和空间），我估计，天猫京东那规模的电商，肯定有一个专门的session集群。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式，cookie是一个实际存在的东西，它是在http协议中定义在header中的字段。 session的常见实现要借助cookie来发送sessionID给客户端，如果浏览器禁用cookie，那么就要通过重写url来获取sessionid，各位可以联想一下电商的购物车，购物车可以实现在一个网站的不同页面把东西都放进一个购物车，这就是session的重点应用。现在也很流行一个token，其实token和sessionid是一个意思。 3）多进程和多线程的区别，自己喜欢用哪个？为什么？ 4) lvs脑裂如何解决，为什么会产生双master？双master时VIP通不通?[我的答案] 额外补充一句，要排除脑裂问题，第一步是检查iptables，重要的话不说三遍也重要！ 5) 为什么TCP比UDP的信息更加可靠？tcp滑动窗口，详细说说原理，窗口的大小如何确定。 6) cdn的工作原理。如何评估一个cdn sp做的好不好。[我的答案]cdn的工作原理：通过权威dns服务器来实现优质节点的选择，通过缓存来减少源站的压力。 IT界有个很有名的比喻，正向代理是“找马云借钱”，反向代理是“给10086打电话”，而反向代理就是CDN的实现原理雏形的一部分。 7）dns查询的过程说一下，为什么要有cname而不是直接返回一个cdn边缘节点的ip。[我的答案]dns查询的过程以www.taobao.com为例：1.在浏览器键入www.taobao.com,其实真正dns协议里用到的是www.taobao.com.最后还有一个点，可能是因为美观等原因，一般都不显示;2.查询本地缓存（host文件或者是浏览器的缓存）中有没有该域名对应的记录，有的话就直接用了;3.向运营商的DNS服务器发起dns解析的请求，一般称运营商的DNS服务器为local dns;4.local dns会查询本地的缓存，local dns设置的缓存时间是有讲究的，过长过短都不好。另外local dns的查询是运营商的事，这里面水很深，外部不可控(这也是天朝能搭建特色墙的根源)；5.local dns如果没有缓存，会把域名从右往左扫描，依次请求对应的服务器，例如对于域名www.taobao.com.，先去问负责.的根域名服务器，就是传说中全球只有几台的那些服务器，他们会答复.com是谁管理的，然后local dns又去找管理.com的服务器（假设名字为S1），去问问taobao.com是谁管，一般来说，在S1查到的记录是一条cname记录（阿里毕竟大公司，自己管理自己旗下的域名），然后就转到了阿里自己的DNS服务器上来了，一般称之为权威服务器；6.权威服务器是阿里自己建的，然后根据公司内部的一些配置啊，调整啊，查到www.taobao.com.对应的服务器是谁，返回一个IP地址；7.local dns缓存这个IP地址，并且回复浏览器；8.浏览器和对应的IP地址的服务器建立TCP连接，发送HTTP报文； 用图表示就是： 8）举例说下正则表达式和扩展正则表达式例如：url、ip、邮箱的正则表达式？ 9）解释raid0、raid1、raid01、raid10、raid5、raid6，并分析各自读写性能？ 10）radi为什么不搞个raid50、raid15，不能搞是因为有什么冲突还是什么等等? 拓展阅读https://segmentfault.com/a/1190000007243675http://mertensming.github.io/2016/10/19/cookie-session/https://wizardforcel.gitbooks.io/network-basic/content/index.htmlhttps://coolshell.cn/articles/11564.htmlhttps://coolshell.cn/articles/11609.htmlhttp://blog.sina.com.cn/s/blog_93b45b0f0101a4ix.html","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"},{"name":"职场","slug":"职场","permalink":"http://yoursite.com/tags/职场/"}]},{"title":"实战Kibana的日志关键词搜索和日志可视化","slug":"实战Kibana的日志关键词搜索和日志可视化","date":"2018-01-17T07:44:01.000Z","updated":"2018-01-22T02:32:43.719Z","comments":true,"path":"2018/01/17/实战Kibana的日志关键词搜索和日志可视化/","link":"","permalink":"http://yoursite.com/2018/01/17/实战Kibana的日志关键词搜索和日志可视化/","excerpt":"","text":"准备工作首先，先下载一个elastic网站上下载一个它提供的demo—莎翁的《亨利四世》，下载地址是https://download.elastic.co/demos/kibana/gettingstarted/shakespeare.json 。 打开这个json字符串，里面就是《亨利四世》的话剧剧本，长得是这个样子： 可以看到里面有play_name、speaker、speech_number、line_id等等名称，每个名称后面都有一个对应的值。 然后启动elasticsearch，按照上面的文件格式生成索引。语句如下： 1234567891011121314curl -XPUT http://localhost:9200/shakespeare -d '&#123; \"mappings\" : &#123; \"_default_\" : &#123; \"properties\" : &#123; \"speaker\" : &#123;\"type\": \"string\", \"index\" : \"not_analyzed\" &#125;, #确定type是字符 \"play_name\" : &#123;\"type\": \"string\", \"index\" : \"not_analyzed\" &#125;, \"line_id\" : &#123; \"type\" : \"integer\" &#125;, #确定type是数字 \"speech_number\" : &#123; \"type\" : \"integer\" &#125; &#125; &#125; &#125;&#125;'; 导入刚刚下载的那个json：curl -XPOST &#39;localhost:9200/shakespeare/_bulk?pretty&#39; --data-binary @shakespeare.json 具体elasticsearch的增删改查语法可以参看阮大师的http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html ，个人建议将elasticsearch和mysql对比一下，这样更方便理解。 然后后台启动kibana，确认5601端口已经stand by，如图： 然后在浏览器地址栏输入服务器外网ip：5601打开kibana。 导入数据结束之后，使用curl &#39;localhost:9200/_cat/indices?v&#39;，去查看一下效果，如果看到index里有shakespeare那一栏就是导入成功了，如图： 在启动Kibana后，Kibana会自动在配置的es中创建一个名为.kibana的索引（上图第二个），这个索引用来存储数据，注意！不要删除了它。 Kibana的界面搜索如果此时的kibana里是第一次配置的话，那么第一步就是配置新索引，我们之前在生成索引的时候写的是shakespeare，那么现在也写shakespeare，然后点击create，如图： 然后在菜单栏左侧的discover里选择刚刚建立的shakespeare，就会看到这样的东西： 在Search上就可以进行搜寻，比如说我搜寻freedom，如图： 如果我搜寻KING HENRY IV，他不分大小写的把所有king、henry、iv都搜索出来。 如果我想搜寻line_id的第一行到第三行，那么语句就是line_id:[1 TO 3]，如图： 如果想在上面的基础上进一步细化，比如说要在line_id是从第一行到第三行，同时_type是scene的语句：line_id:[1 TO 3] AND _type:scene： 假如不想要scene，那么就把AND改成NOT。 如果这个时候只想关注一些指定的字段，那么可以将鼠标移动到索引下面的字段上，然后选在add即可，同样的移动上面已经选择的字段选择remove进行移除，比如我们试一下这个speaker： add之后在点击右侧的具体的speaker，就会看到里面的细节，比如这位westmoreland（威斯摩兰伯爵）： 这个时候就能看见这位伯爵大哥的台词细节，在第几场的第几节，说的是什么台词。再返回菜单左侧点击这个speaker，我们还会看到一个比重： 从这里就很清晰的看到，FALSTAFF（法斯塔夫）这个哥们的台词最多，也符合书里塑造的那个嗜酒话痨的艺术形象。而我们的KING HENRY IV(亨利四世)的台词只是第四位，占比重11%而已… 这样具体的搭配搜索之后，可以点击界面右上侧的save进行保存搜寻结果，再搭配share分享搜索结果的url网址，如图： Kibana的图像化展示Kibana也能做到类似grafana那样的炫酷图象化展示，更加立体的表现日志情况，首先选择左侧菜单栏里的Visualize（可视化）： 然后点击Create a Visualization,里面既有很多种图形供你选择，有饼型，有箭头的，有文字的，有仪表盘的，如图： 我们这里先建立一个饼型的，还是上面那个台词多少的例子，首先选择shakespeare作为数据源，然后点击split slices，如图： 然后在Aggergation里选择Terms，然后在Field里选择Speaker,size那里写8,最后点击上面的那个三角播放键，看看结果： 这就很清晰的看出，亨利四世一共说了1086句话，占比11.11%。 如果我们再加一个Split Slices，这一次在原有的specker的基础上选择play_name，图象变成了一个同心圆，最外面的一层就是新增的“play_name”的情况，如图显示FALSTAFF的所有台词会在两个play_name里出现： 如果这个盘子里不想统计FALSTAFF这个话包，就添加一个过滤器，选择speaker is not，后面写上FALSTAFF即可，如图： 效仿刚才的方法也可以做一个仪表盘，如图： 可视化的数据也可以save和share，同样在web界面的右上角。保存的数据是可以在左侧菜单栏里的Dashboard里展示，做成一个类似zabbix那样的展示！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"},{"name":"大数据","slug":"大数据","permalink":"http://yoursite.com/tags/大数据/"}]},{"title":"工作所用的模块回滚脚本","slug":"工作所用的模块回滚脚本","date":"2018-01-17T04:25:25.000Z","updated":"2018-01-22T02:31:05.833Z","comments":true,"path":"2018/01/17/工作所用的模块回滚脚本/","link":"","permalink":"http://yoursite.com/2018/01/17/工作所用的模块回滚脚本/","excerpt":"","text":"前言与脚本内容部署中常备一个回滚脚本也是很有必要的，我所在公司的服务器模块名都是在初始化的时候写进/etc/role_install这个文件里，如下图的这个服务器就是fss服务器： 再比如下面这个服务器，虽然包含nginx的组件但是httpproxy的服务器： 那么有了这样的前提，整个回滚的脚本内容如下： 12345678910111213141516171819202122232425262728293031#!/bin/bash#Written by ChrisChan @July-4th-2017#Desription:这是一个回滚的脚本。module=$(cat /etc/role_install |grep -v zkclient|grep -v nginx)echo -e '\\033[31m现在将执行回滚操作，本次回滚只回滚普通模块，不包含nginx和zkclient!\\033[0m' echo \"回滚的模块名称：\"$moduleecho -e '\\033[33m如果想取消回滚操作，请ctrl+c立即停止本脚本...\\033[0m'sleep 5cd /dxpbackup/hswx/$module &amp;&amp; zip $module.zip -x \"*og*\" -r . #到备份的文件夹里去压缩mv /dxpbackup/hswx/$module/$module.zip /mnt/hswx echo $module\".zip文件已经生成！\" until [ \"$decision\" == \"Y\" -o \"$decision\" == \"y\" -o \"$decision\" == \"N\" -o \"$decision\" == \"n\" ]do read -p \"请问是否用回滚的压缩包覆盖到/mnt/hswx下？(y/n)\" decision echo \"您的选择是：\"$decision if [ $decision == Y -o $decision == y ] then echo \"现在已经开始覆盖...\" rm -rf /mnt/hswx/$module #先把原来的内容删除 unzip /mnt/hswx/$module.zip -d /mnt/hswx/$module #重新解压缩进去 echo -e '\\033[32m覆盖已经完成，可以直接执行/startall脚本!\\033[0m' elif [ $decision == N -o $decision == n ] then echo -e '\\033[32m生成的'$module'.zip文件保存在/root文件夹里\\033[0m' else echo -e '\\033[31m输入字符不符合!请重新输入!\\033[0m' fidone 新的知识点！1）zip在压缩文件夹的时候要过滤掉某些文件使用“-x”参数，比如说要在AAA文件夹里面过滤掉abc和jqk这两个文件，那么语句就是zip AAA.zip -x &quot;abc&quot; -x &quot;jqk&quot; -r .或者是zip -r -x=abc -x=jqk AAA.zip . 这样两个语句。 如果你要过滤掉的是一个文件夹，比如那么就要在文件夹后面名字加上一个，下图就是要压缩整个auc文件夹为456.zip但是又不想要lib这个文件夹，就使用了`zip 456.zip -x “lib“ -r .`： 不过如果文件夹里还有其他lib开头的文件夹也会被过滤掉，这一点要注意。 2）本shell里面涉及了逻辑判断，而[[和[的区别如下图： 3）如果if语句中出现报错“[: too many arguments”，很有可能就是字符串变量中可能存在空格，shell解析时将其认为是多个参数，再进行判断时，无法知道该获取哪个值，所以最好都用双引号括起来； 4）如果是“变量a等于aa且变量b等于bb 或者 变量c等于cc且变量d等于dd ” 这样的判断句怎么写？答曰： [ $a = “aa” -a $b = “bb” ] || [$c = “cc” -a $d = “dd” ] 参考资料https://zhangge.net/4776.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"http://yoursite.com/tags/Shell/"}]},{"title":"Ansible的几个基本语句","slug":"Ansible的几个基本语句","date":"2018-01-17T03:43:52.000Z","updated":"2018-01-22T02:27:27.780Z","comments":true,"path":"2018/01/17/Ansible的几个基本语句/","link":"","permalink":"http://yoursite.com/2018/01/17/Ansible的几个基本语句/","excerpt":"","text":"开篇的废话批处理工具我最早接触的是pssh，因为它实在很简单粗暴，但是它由于太简单粗暴了，应付十台二十台机器还OK，应付五十台一百台服务器就心有余力不足了（而且xshell右键有一个“发送键入到所有会话”的功能，与pssh效果几乎一样），而且我还不太喜欢puppet，总觉得那玩意跟我八字不合，于是乎，在新头头的推荐下，我把目光放在了Ansible。 Ansible的安装很简单，在Redhat环境下直接yum install -y ansible就行。Redhat已经将Ansible公司收购了，所以在安装上提供了不小的便利。 Ansible在安装完毕之后，会在/etc/ansible/目录下看见一个叫hosts的文件，这里是所有你要控制的服务器的ip们，可以排列写，比如： 123192.168.1.122192.168.1.133192.168.1.144 也可以分组写，比如： 1234567[aliyun]10.22.33.4410.22.33.45[jinshanyun]121.23.45.66121.23.45.67121.23.45.68:2222 （这个不是使用ssh默认的22端口，就需要特别指出） 默认情况下，Ansible会把命令全用于这个hosts文件，比如 ansible all -m ping -u ashin这句话意思是整个hosts里的机器以ashin账户启动，而且都要ping 一下当前本机。 具体语句怎么连接主机与要控制的远程机器请按之前写的“http://chenx1242.blog.51cto.com/10430133/1763978”一文进行操作，这里先说几个命令语句： 1)ansible all -m shell -a &quot;/bin/echo hello&quot;对hosts里所有的机器一起使用”输出hello这个文字”。-m shell可以忽略不写，但是不是shell而是其他的模块就要写出来； 2)ansible aliyun -m copy -a &quot;src=~/projects/tests/t.py dest=~&quot;把hosts里aliyun组的机器的/projects/tests/t.py复制到~目录下；[注意！]copy模块不支持变量路径，也就是说如果目标服务器的部署路径不同，copy不会很智能的去访问.bash_profile来得到用户的自定义变量，写变量替换路径是不会达到目的的。 3)ansible jinshanyun[0:9] -i -m file -a &quot;dest=~/tests state=absent&quot;把hosts里jinshanyun组中从0~9这十台机器的/tests文件夹删除掉，absent是“缺席，不在”的意思； 4)ansible 192.168.1.133 -m ping这句话=ping 192.168.1.133； 5)ansible v1 -m service -a &quot;name=mysql state=started&quot; -u ashin --sudo -K以用户名为ashin登陆hosts里所有v1组的机器，然后检查mysql是否是started状态，若不是就start，同时要输入root的密码作为确认； 6)ansible 10.11.22.* -m user -a &quot;name=foo password=foo&quot; --sudo -Khosts文件里所有10.11.22开头的机器，都要添加一个新的用户名foo，同时密码是foo，并且输入root密码确认身份； 7)ansible v1:!v2 -m apt -a &quot;name=git state=latest&quot;检查所有属于v1组同时还不属于v2组的机器里的git文件是否是最新版本； 8)ansible webservers:&amp;dbservers -a &quot;/sbin/reboot&quot; -f 10 --sudo -K重新启动既是webservers组又是dbservers组的所有机器； 9)ansible webservers -m raw -a &#39;yum -y install python-simplejson&#39;用ansible去链接低版本的centos时，就乎出现“ansible requires a json module, none found! ”的错误，需要远程机安装samplejson包。raw模块是靠底层ssh的通讯，不依靠python的模块，所以如果碰到低版本的系统，如果command和shell模块无法使用，可以先用这条命令安装完需要的包。 10)ansible all -m synchronize -a &quot;src=/chenshuo/1.sh dest=/chenshuo delete=yes&quot;synchronize原意是“同步”，而这个模块是分发模块，这句话的意思是把控制端的/chenshuo/1.sh分发给host文件里的所有ip服务器，delete=yes意思是以控制端服务器的文件为准。 11)ansible 10.168.194.89 -m synchronize -a &quot;mode=pull src=/chenshuo/nba.txt dest=/chenshuo/a.txt&quot;将10.168.194.89这台服务器上的/chenshuo/nba.txt拉到控制服务器的/chenshuo文件夹下，顺便改名叫a.txt。 12)ansible all -m get_url -a &quot;url=https://pypi.python.org/packages/56/2b/9c9c113fb88082950067a42cc99e3c61f1df72035f89bb0bdf0a60308ca0/pexpect-4.1.0.tar.gz#md5=562a1a21f2a60b36dfd5d906dbf0943e dest=/chenshuo&quot;把那一大串网址的下载连接下载到host文件里的所有ip的/chenshuo文件夹下。 13)ansible 10.117.14.37 -m script -a &quot;/chenshuo/free.sh&quot;在10.117.14.37上执行操作端的free.sh，注意操作端必须要有free.sh这个脚本，而10.117.14.37这台机器上并不一定要有。 参考资料http://blog.csdn.net/iloveyin/article/details/46982023","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"Zabbix用户密码忘记怎么办","slug":"Zabbix用户密码忘记怎么办","date":"2018-01-17T03:12:57.000Z","updated":"2018-01-22T02:29:28.186Z","comments":true,"path":"2018/01/17/Zabbix用户密码忘记怎么办/","link":"","permalink":"http://yoursite.com/2018/01/17/Zabbix用户密码忘记怎么办/","excerpt":"","text":"zabbix的超级用户也是人，人就难免会忘记密码（或者清除了当前浏览器的缓存），忘记密码不要怕，因为zabbix所有的用户数据都是保存在server机器上的mysql里，只要打开zabbix_server.conf，就会查得到mysql的登录账号密码以及zabbix对应的数据库。（这里多说一句，zabbix自带的guest基本就是一个废物，forget it~） 在zabbix_server机器上输入mysql的账号密码来到mysql里，USE zabbix，然后SELECT * FROM users,就会看到笔者的画面。 这个时候就可以使用数据库的update命令去更改密码，比如说新的密码是“woshitiancai”，就可以写update users set passwd=md5(&quot;woshitiancai&quot;) where userid=&#39;1&#39;;然后就可以用woshitiancai来登陆啦~ 但是！！！你以为这就结束了吗？nononono！！！ 很多人即使更改了密码还是登陆不上去，很简单，那就是你连用户名都忘记了！或者是用户名你记得但是你手贱在zabbix的administration里的users对原来的设定增加了新东西，而且这些东西还特么的是中文！！！于是就像我上面图那样出现了???的字样。 那些？？？很重要吗？当然了！！！因为那些才是zabbix的登录用户名！！！看见了吗，zabbix使用蛋疼的alias作为真正的登录名而不是用name or surname，这真是一个蛋疼的事儿！ 那么剩下的问题很简单了，就是把???改变成中文，使用语句set names utf8; 然后界面就成了这样： 这次再使用“主管理员”搭配新的密码就可以华丽的登录了！~~我他妈当时都差点要把这个user表格删掉然后重拽一个表格进来，但是终于还是被我识破了，啊哈哈哈哈，我真是个天才！！！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"Docker出现客户端与服务端有差的错误...","slug":"Docker出现客户端与服务端有差的错误","date":"2018-01-16T00:36:32.000Z","updated":"2018-01-22T02:28:30.873Z","comments":true,"path":"2018/01/16/Docker出现客户端与服务端有差的错误/","link":"","permalink":"http://yoursite.com/2018/01/16/Docker出现客户端与服务端有差的错误/","excerpt":"","text":"今天用docker搞redis镜像的的时候，出现了这样的错误提示：Error response from daemon: client is newer than server (client API version: 1.24, server API version: 1.22)，如图： 可见使用了docker version的时候也有提示：当前docker客户端比服务端版本更新。这样是无法创建镜像的，遇到这个问题很简单，那就是重启一下docker，命令如下： 12systemctl stop dockersystemctl start docker 然后我们再docker version看一下效果： 我做这个的时候，docker升级了也一样可以读到原先的镜像，但是出于保险起见我们也应该学会如何保存和导入镜像，比如现在我现在有这个叫docker.io/ubuntu的镜像，如图： 如果要备份它的话，语句就是： 1docker save docker.io/ubuntu &gt; /root/ubuntu.image 这里备份后的文件名就是ubuntu.image。 如果要导入的话，语句就是： 1docker load &lt; /root/ubuntu.image 这样导入的话，images create时间是不变的。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/容器/"}]},{"title":"记录日志系统ELKB 5.6.4的搭建过程","slug":"记录日志系统ELKB-5-6-4的搭建过程","date":"2018-01-15T23:59:43.000Z","updated":"2018-01-22T02:31:02.292Z","comments":true,"path":"2018/01/16/记录日志系统ELKB-5-6-4的搭建过程/","link":"","permalink":"http://yoursite.com/2018/01/16/记录日志系统ELKB-5-6-4的搭建过程/","excerpt":"","text":"前言ELK是最近比较流行的免费的日志系统解决方案，注意，ELK不是一个软件名，而是一个结局方案的缩写，即Elasticsearch+Logstash+Kibana（ELK Stack）。这哥几个都是java系的产品，但是众所周知，java的东西很吃内存和CPU，Logstash在当作为收集日志的Agent时，就显得太过臃肿了。听说直播平台“斗鱼”团队很为logstash占用资源的情况很而苦恼，后来为了解决这个问题，他们自己写了一个agent。不过后来官方在logstash-forwarder的基础上推出了beat系列，里面包括四个兄弟，分别是：Packetbeat（搜集网络流量数据）；Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）；Filebeat（搜集文件数据）；Winlogbeat（搜集 Windows 事件日志数据）。而Filebeat也就这样加入了“日志收集分析”的团队里，所以虽然大家还是习惯性的叫ELK，其实准确的说法已经是ELKB了。 ELKB这几个哥们的分工如下： Elasticsearch：分布式搜索和分析引擎，具有高可伸缩、高可靠和易管理等特点。基于 Apache Lucene 构建，能对大容量的数据进行接近实时的存储、搜索和分析操作。通常被用作某些应用的基础搜索引擎，使其具有复杂的搜索功能； Logstash：数据收集额外处理和数据引擎。它支持动态的从各种数据源搜集数据，并对数据进行过滤、分析、丰富、统一格式等操作，然后存储到用户指定的位置； Kibana：数据分析和可视化平台。通常与 Elasticsearch 配合使用，对其中数据进行搜索、分析和以统计图表的方式展示； Filebeat：ELK 协议栈的新成员，在需要采集日志数据的 server 上安装 Filebeat，并指定日志目录或日志文件后，Filebeat 就能读取数据，迅速发送到 Logstash 进行解析，亦或直接发送到 Elasticsearch 进行集中式存储和分析。 设计架构 本文的设计结构就是这样，其中红色的redis/RebbitMQ部分可以省略（我这个例子里暂省略），让日志直接传递到logstash，如果日志量较大，最好还是添加上redis，同时再横向扩容Elasticsearch，搞成一个集群。 对于这几个模块服务器多说几句：1）Logstash要选择计算能力强的，CPU和内存比较丰满的；2）Elasticsearch要选择磁盘容量大的，同时CPU和内存也比较丰满的； 实验软件版本Elasticsearch 5.6.4Logstash 5.6.4Kibana 5.6.4Filebeat 5.6.4Java 1.8+，安装方法：http://blog.51cto.com/chenx1242/2043924由于ELKB这几个东西都是墙外的，墙内的下载可能会比较费劲。所以我稍后会把所有ELKB的5.6.4程序都放在51CTO的存储空间里，需要的朋友可以去下载，还是那话，虽然ELK升级频率很快，但是5.6.4已经足够稳定了。 实验服务器情况 安装Elasticsearch 5.6.4（以下所有操作都是root下进行的）12curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.4.rpmrpm -ivh elasticsearch-5.6.4.rpm 然后编辑/etc/elasticsearch/elasticsearch.yml，不然的话logstash无法与之相连： 123cluster.name: my-application #如果是集群的es就把这个打开，Elasticsearch 启动时会根据配置文件中设置的集群名字（cluster.name）自动查找并加入集群，端口是9300network.host: 0.0.0.0 #取消注释，并且改成0.0.0.0http.port: 9200 #取消注释 保存之后，启动并且添加开机启动： 12systemctl start elasticsearch systemctl enable elasticsearch 使用curl localhost:9200能看到这样的情景就证明已经成功启动了： 安装kibana 5.6.4 (以下所有操作都是root下进行的)1234curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-5.6.4-linux-x86_64.tar.gztar xzvf kibana-5.6.4-linux-x86_64.tar.gzcd kibana-5.6.4-linux-x86_64/vim config/kibana.yml 把kibana.yml里的server.host: localhost改成server.host: 0.0.0.0，然后保存退出，在kibana的bin文件夹里执行./kibana即可。如果要后台启动就是nohup /kibana安装路径/bin/kibana &amp;。 启动之后，如图： 安装Logstash 5.6.4（以下所有操作都是root下进行的）12curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-5.6.4.rpm rpm -ivh logstash-5.6.4.rpm 如果安装的时候爆错：/usr/share/logstash/vendor/jruby/bin/jruby: line 388: /usr/bin/java: No such file or directory。那么就先which java查看一下java的文件，然后做一个软连接过去，然后重装logstash即可，如图： 用户可以使用TLS双向认证加密Filebeat和Logstash的连接，保证Filebeat只向可信的Logstash发送加密的数据（如果你的logstash和filebeat是内网通信，而且你认可当前内网的安全度，这一步可以省略）。同样的，Logstash也只接收可信的Filebeat发送的数据。这个功能默认是关闭的，要开启的话需要先vim /etc/pki/tls/openssl.cnf，如图： 找到[ v3_ca ]的字段，在底下添加subjectAltName = IP:logstash的内网IP字段，保存退出来到/etc/pki/tls/，执行下面命令： 1openssl req -x509 -days 365 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt 来生成一个期限为365天的IP SAN证书对，如果想生成一个十年的证书，就把365改成3650即可，如图： 安装完毕之后，vim /etc/logstash/logstash.yml，编辑成如下的样子： 然后在/etc/logstash/下手动建立一个目录conf.d，在conf.d里新建一个logstash.conf的文件，如下： 123456789101112131415161718192021222324252627282930313233343536373839$ cat /usr/local/logstash/config/conf.d/logstash.conf#在输入部分，配置Logstash通信端口以及添加SSL证书，从而进行安全通信。input &#123; beats &#123; port =&gt; 5044 ssl =&gt; true ssl_certificate =&gt; \"/etc/pki/tls/certs/logstash-forwarder.crt\" ssl_key =&gt; \"/etc/pki/tls/private/logstash-forwarder.key\" &#125;&#125; #在过滤器部分，我们将使用Grok来解析这些日志，然后将其发送到Elasticsearch。以下grok过滤器将查找“syslog”标记的日志，并尝试解析它们，以生成结构化索引。filter &#123; if [type] == \"syslog\" &#123; grok &#123; match =&gt; &#123; \"message\" =&gt; \"%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\\[%&#123;POSINT:syslog_pid&#125;\\])?: %&#123;GREEDYDATA:syslog_message&#125;\" &#125; add_field =&gt; [ \"received_at\", \"%&#123;@timestamp&#125;\" ] add_field =&gt; [ \"received_from\", \"%&#123;host&#125;\" ] &#125; syslog_pri &#123; &#125; date &#123; match =&gt; [ \"syslog_timestamp\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] &#125; &#125;&#125; #输出部分，我们将定义要存储的日志位置output &#123; elasticsearch &#123; hosts =&gt; [ \"10.162.80.192:9200\" ] #这个地址是elasticsearch的内网地址 index =&gt; \"filebeat-%&#123;+YYYY.MM.dd&#125;\" #设定这个是索引 #index =&gt; \"auclogstash-%&#123;+YYYY.MM.dd&#125;\" #这行是后来作实验的，可以忽视 user =&gt; elastic #这个是为了将来装x-pack准备的 password =&gt; changeme #同上 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 然后就是启动并且添加开机自启动: 12systemctl start logstash systemctl enable logstash 安装filebeat（以下所有操作都是root下进行的）在模块服务器上安装filebeat的方法如下: 12curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.4-x86_64.rpm rpm -ivh filebeat-5.6.4-x86_64.rpm 之前在logstash上生成了一个IP SAN证书，现在需要把这个证书传递给filebeat的机器里，使用scp语句如下： 1scp -pr root@10.162.80.171:/etc/pki/tls/certs/logstash-forwarder.crt /etc/ssl/certs/ #10.162.80.171就是logstash的内网IP 输入logstash的密码，并且密钥文件复制完毕之后，需要修改filebeat.yml，于是#vim /etc/filebeat/filebeat.yml： 12345678910111213141516[root@func-auc-001 log]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /mnt/hswx/auc/logs/*.log #这个是那个auc模块的路径 - /第二个日志路径/*.log #如果有第二个文件路径的话 tail_files: true #从文件末尾开始读取 document_type: \"newnginx-api\" #logstash那里已经设定了index，如果要使用了document_type，那么在logstash的index就要这么写：\"%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\" # 以下是规避数据热点的优化参数： spool_size: 1024 # 积累1024条消息才上报 idle_timeout: \"5s\" # 空闲5s上报 output.logstash: hosts: [\"10.162.80.171:5044\"] #这个地方要写logstash的内网地址 ssl.certificate_authorities: [\"/etc/ssl/certs/logstash-forwarder.crt\"] #这里就是刚刚复制的那个密钥文件路径 #注意上面是ssl而不是tls，1.0版本才是tls，如果这个写错了，启动的时候会出现“read: connection reset by peer”的错误 注意！Filebeat的配置文件采用YAML格式，这意味着缩进非常重要！请务必使用与这些说明相同数量的空格。 保存之后，使用/etc/init.d/filebeat start启动filebeat，如图： 故障解决ELK几个部件现在都已经启动了，并且互相telnet端口都是通的，在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;却出现这样的情况： 而使用tailf /var/log/filebeat/filebeat去查看filebeat的日志是这样的： 再看看logstash-plain.log，里面的情况是这样的： 从此可见，filebeat与logstash的联系是error状态，那么停止filebeat的进程，改用/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml，重新在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;发现已经成功读到了我们之前配置的目录“/mng/hswx/auc/log”，如图： 配置kibana在浏览器输入kibana服务器外网IP：5601打开kibana的web界面，把idenx pattern的地方改成filebeat-*(同之前配置的index索引一致)，然后点击create，如图： 然后就得到了细节的web界面，如图： 点击左侧框的Discover，就会看到梦寐以求的日志web界面，如图： 看一下红色框的内容里面有时间，有host主机，有source来源，还有具体的日志信息，我们再去func-auc-001这个日志源主机上查询一下日志： 两个日志是一样的，可见实现了预期的日志展示的目标！ 最后一步，就是把kibana与nginx联系起来（也可以把kibana做阿里云负载均衡的后端服务器），这样通过nginx/负载均衡来访问kibana的界面，对kibana来说更安全。配置端口监听如图，再把kibana服务器挂在负载均衡后面即可。 参考资料https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.htmlhttps://www.ibm.com/developerworks/cn/opensource/os-cn-elk/http://www.jinsk.vip/2017/05/24/elksetup/https://renwole.com/archives/661https://www.zybuluo.com/dume2007/note/665868https://www.elastic.co/guide/en/beats/libbeat/5.6/getting-started.htmlhttps://discuss.elastic.co/search?q=ERR%20Failed%20to%20publish%20events%20caused%20by%3A%20read%20tcphttp://jaminzhang.github.io/elk/ELK-config-and-use-Filebeat/ （这个博主很好，但是就是博客无法留言，这点比较坑）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://yoursite.com/tags/ELK/"},{"name":"大数据分析","slug":"大数据分析","permalink":"http://yoursite.com/tags/大数据分析/"}]},{"title":"从“No space left on device”到删除海量文件","slug":"从“No-space-left-on-device”到删除海量文件","date":"2018-01-15T16:48:39.000Z","updated":"2018-01-22T02:29:29.526Z","comments":true,"path":"2018/01/16/从“No-space-left-on-device”到删除海量文件/","link":"","permalink":"http://yoursite.com/2018/01/16/从“No-space-left-on-device”到删除海量文件/","excerpt":"","text":"开发发现某个云服务器无法启动进程，提示“No space left on device”，但是使用df -h查看容量的时候，明明还有很多的空间。于是使用df -i，发现inode节点已经全部用光了，所以现在不能建立任何新的文件。如图： 既然如此就要查出来是哪个文件夹里会有如此多的文件来占用这些inode,使用一个小脚本：for i in /*; do echo $i; find $i | wc -l; done，获取到/mnt下有一个文件占用了绝大多数的inode，如图： 于是就进入到mnt这个文件夹里，慢慢找寻到底是哪个文件夹，用上面那个语句一点一点缩小范围，最后确定文件夹原来就是data文件夹，如图： 现在如果要rm -rf data/*的话，是没有效果的，有效果的话也很慢。而且很有可能报-bash: /bin/rm: Argument list too long的错，因为这个文件夹里面的小文件实在太多了，有足足两百五十多万个，那么怎么样处理这样的情况？ 用find搭配-type f -exec rm {} \\;可能会引起内存溢出，用文件夹重置命令搭配”–reference” 也没什么效果。 这时最好的方法就是使用rsync! 先yum install rsync，当然了现在inode是饱和的状态，yum install是会报错的： 那么就需要手动删除一些文件，腾出来一部分inode供yum使用，安装完毕rsync之后，找到一个空文件夹，如果没有空文件夹，就手动建立一个。 使用命令：rsync --delete-before -a -H -v --progress --stats /空文件夹的路径/ /海量小文件的路径/ –delete-before 接收者在传输之前进行删除操作 –progress 在传输时显示传输过程 -a 归档模式，表示以递归方式传输文件，并保持所有文件属性 -H 保持硬连接的文件 -v 详细输出模式 -stats 给出某些文件的传输状态 如果你开了这个服务器的两个窗口，一个是执行上面的命令，另一个是在海量文件夹里执行ls，这个时候ls命令是卡死的，过了大约2分钟，就会看到ls展示的文件喷涌而出，整个电脑屏幕好比黑客帝国一样，异常壮观。 静等大约20分钟，整个文件夹删除干净，inode也释放了97%，世界恢复了清静。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"}]},{"title":"使用Google Authenticator给ssh进行登录验证","slug":"使用Google-Authenticator给ssh进行登录验证","date":"2018-01-15T16:39:26.000Z","updated":"2018-01-22T02:32:42.229Z","comments":true,"path":"2018/01/16/使用Google-Authenticator给ssh进行登录验证/","link":"","permalink":"http://yoursite.com/2018/01/16/使用Google-Authenticator给ssh进行登录验证/","excerpt":"","text":"普通情况下的服务器登录，是“服务器+密码”这种直白的验证方式，但是这种方式太过简单，一旦密码泄露，服务器就有危险，于是为了安全我们就要在登录上再加一把锁，那就是使用Google Authenticator（谷歌身份验证器）这个工具，在登录的时候进行一次验证，只有“验证通过了”+“密码正确”才能登陆服务器。 安装前准备1）关闭Selinux ：setenforce 02）安装依赖：yum -y install gcc make pam-devel libpng-devel libtool wget git3）添加阿里云epel 源： 1234RHEL 6/Centos 6wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repoRHEL 7/Centos 7wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 4）安装Qrencode，谷歌身份验证器需要调用该程序生成二维码并显示：yum install -y qrencode 安装谷歌身份验证器这个时候很多教程会让你去执行git clone https://github.com/google/google-authenticator.git，然而现在这个git里面已经不再含有libpam这个文件夹了，下载下来是一个错误的包，那么这个时候你可以使用yum install google-authenticator，不过yum安装的身份验证器的版本很老，这个时候可以执行wget https://github.com/google/google-authenticator-libpam/archive/1.04.tar.gz。 下载下来1.0.4版本的然后拆包解压缩，里面是这样几个文件： 然后就./bootstrap.sh &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install进行编译和安装。 安装过程完毕之后，还要复制google身份验证器pam模块到系统下，命令是：cp /usr/local/lib/security/pam_google_authenticator.so /lib64/security/。 调整登陆方式1）编辑/etc/pam.d/sshd这个文件，我这个centos的版本是7.0的，里面的内容可能跟centos 6.x的优点不同，不过没关系，就需要插入黄色框内的auth required pam_google_authenticator.so，如图： 修改完毕之后，保存退出。 注意！修改了这步之后，服务器千万不能断开连接，否则再连是需要google验证码的，而我们现在还没有生成码，所以肯定是无法连接服务器，如果是云服务器，可以通过登陆控制台的方式把这个文件修改回来，如果是实体服务器，那就呵呵呵了。 2）编辑/etc/ssh/sshd_config，就修改一个地方：ChallengeResponseAuthentication yes3）保存退出之后，重启一下ssh服务： 12RHEL6 /Centos6：Service sshd restartRHEL7 /Centos7：Systemctl resart sshd 生成登陆验证码这次以root用户为例，那么切换成root用户执行下面的过程。1）执行google-authenticator，由于我们之前已经安装了qrencode，那么这个时候会生成一个超级超级巨大的二维码，给各位感受一下： 红色内容是生成的密钥，很重要。绿色的内容是备用的紧急救助码，紧急救助码就是当你无法获取认证码时（比如手机丢了），可以当做认证码来用，每用一个少一个，但其实可以手动添加的，建议如果 root 账户使用 Google Authenticator 的话一定要把紧急救助码另外保存一份。 Do you want me to update your &quot;/home/test/.google_authenticator&quot; file? (y/n) y 是否更新用户的 Google Authenticator 配置文件，选择 y 才能使上面操作对当前用户生效，其实就是在对应用户的 Home 目录下生成了一个 .google_authenticator 文件，如果你想停用这个用户的 Google Authenticator 验证，只需要删除这个用户 Home 目录下的 .google_authenticator 文件就可以了。 Do you want to disallow multiple uses of the same authentication token? This restricts you to one login about every 30s, but it increases your chances to notice or even prevent man-in-the-middle attacks (y/n) y 每次生成的认证码是否同时只允许一个人使用？这里选择 y。 By default, tokens are good for 30 seconds. In order to compensate for possible time-skew between the client and the server, we allow an extra token before and after the current time. If you experience problems with poor time synchronization, you can increase the window from its default size of +-1min (window size of 3) to about +-4min (window size of 17 acceptable tokens). Do you want to do so? (y/n) n 是否增加时间误差？这里随便选择， ny都可以。 If the computer that you are logging into isn&apos;t hardened against brute-force login attempts, you can enable rate-limiting for the authentication module. By default, this limits attackers to no more than 3 login attempts every 30s. Do you want to enable rate-limiting (y/n) y 是否启用次数限制？这里选择 y，默认每 30 秒最多尝试登录 3 次。 如果想要写成脚本的话，那么上面交互式的设置也可用通过参数一次性设置：google-authenticator -t -f -d -l test@chen.super -i MR.chen -r 3 -R 30 -W。 -I和-i是可以随便写的，但是-i后期可以改，-I不能改。 搭配手机端如果手机是ios，就去apple store里搜索“Google Authenticator”，如果是安卓，就去应用商店搜索“谷歌动态口令”。 安装完后，打开App，点击“开始设置”，选择“扫描条形码”扫描上面google-authenticator命令生成的二维码，或者是选择“输入密钥”，然后手机上就能看到对应的六位数认证码了。 最后一步，返回xshell，修改登陆方式，设置登陆方法为Keyboard Interactive，如图： 这个时候，推荐各位保留原有的ssh不要动，在另外一个xshell窗口登陆一下看看效果，如果正常的话，这个时候会看到系统会让你先输入一个Verification code。这个值就是手机里的那个六位数，然后再输入密码，只有两个都是正确的，才能登陆！ 至此整个配置完成，如果登陆时遇到问题，请查看日志文件/var/log/secure。 更改存储位置在生成二维码那一步的时候，如果你错过了记住密钥也不要怕，系统会自动把密钥和紧急救助码保存在~/.google_authenticator这个文件里。 如果想要改变密钥存储位置，请使用–secret参数:google-authenticator --secret=&quot;/文件路径/用户名&quot;。 然后更改/etc/pam.d/sshd内的路径配置:auth required pam_google_authenticator.so user=root secret=/PATH_FOLDER/${USER}。 上面那句话里“user=root” 用于强制PAM使用root用户权限来搜索文件。 另外请注意，由于我们当时切换成了root用户，所以密钥文件的所有者是root，生成文件的用户只能读取文件(chmod: 400)： 12chown root.root /PATH_FILE/SECRET_KEY_FILESchmod 400 /PATH_FILE/SECRET_KEY_FILES","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"}]},{"title":"记录一次处理https监听不正确的过程","slug":"记录一次处理https监听不正确的过程","date":"2018-01-12T11:58:54.000Z","updated":"2018-01-22T04:04:34.715Z","comments":true,"path":"2018/01/12/记录一次处理https监听不正确的过程/","link":"","permalink":"http://yoursite.com/2018/01/12/记录一次处理https监听不正确的过程/","excerpt":"","text":"今天开发反馈在测试金山云设备的时候遇到了这样的一个现象：123456wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 11:49:26-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 Resolving funchlscdn.lechange.cn... 120.92.158.134 Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected. OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol Unable to establish SSL connection. 爆“error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol”的错误，就是在当向只提供http的服务发送https请求造成的。 ping funchlscdn.lechange.cn，获得了这个域名对应的IP之后，返回到金山云的控制台查询这个IP，发现这个IP是一个负载均衡，但是这个负载均衡配置的时候对80端口是http协议，而对443端口还是http协议，于是更改成https，重新测试之后，发现错误变成了这样：123456[root@js-develop ~]# wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 16:08:15-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected.HTTP request sent, awaiting response... 502 Bad Gateway2017-07-26 16:08:15 ERROR 502: Bad Gateway. 在浏览器打开效果如图： 502 Bad GatewayThe proxy server received an invalid response from an upstream server. KSYUN ELB 1.0.0 同时发现金山云负载均衡里对nginx的8000健康检查是“异常”。但是使用http访问却是可以的，效果如下：12345678910111213[root@js-develop ~]# wget http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 15:31:55-- http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:80... connected.HTTP request sent, awaiting response... 302 FoundLocation: http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 [following]--2017-07-26 15:31:55-- http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Connecting to 120.92.133.76:8090... connected.HTTP request sent, awaiting response... 200 OKLength: 66 [application/x-mpegURL]Saving to: “dev_20170726085033_lpxh73ezzb92xxa8.m3u8”100%[========================================================================================================================================================&gt;] 66 --.-K/s in 0s 2017-07-26 15:31:55 (3.02 MB/s) - “dev_20170726085033_lpxh73ezzb92xxa8.m3u8” saved [66/66] 于是就叫来开发问一下http和https详细的流程，开发说在http里，设计路线如下：1http(80)-&gt;开发模块(9001) 而在https里，设计路线如下：1https(443)-&gt;nginx(8000)-&gt;开发模块(9001) 这时候就发现了问题，原来最早的时候金山云是没有配置https证书的，于是开发们就用nginx的8000端口去监听ssl这样达到https证书的效果，但是后来金山云控制台添加了https证书，就不再需要nginx去配置ssl证书了，再去https监听8000这一步也就是错误的了，于是在负载均衡那里改成了：1https(443)-&gt;开发模块(9001) 同时关闭了nginx，这时候再来测试一下https请求，就成功了！ 其实如果非要用nginx的ssl证书的话，那么的套路就是：开启nginx，但是在负载均衡那里使用tcp协议去监听nginx的8000端口，这样一样能达到效果。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"https","slug":"https","permalink":"http://yoursite.com/tags/https/"}]},{"title":"Next主题添加音乐和将侧栏移动到左边","slug":"next主题添加音乐和侧栏左移","date":"2018-01-12T07:56:38.000Z","updated":"2018-01-22T04:04:13.870Z","comments":true,"path":"2018/01/12/next主题添加音乐和侧栏左移/","link":"","permalink":"http://yoursite.com/2018/01/12/next主题添加音乐和侧栏左移/","excerpt":"","text":"玩Github博客也有一个多月的时间了，现在这个博客也被我折腾的有点样子了，目前博客里添加了如下功能：1.支持头像图片旋转，同时点击头像可以返回主页；2.背景图片随机出现，而且墙内用户也可以顺利访问；3.增加文章打分系统，觉得好可以给五星好评；4.开放评论系统，无需注册直接评论；5.添加了可视加载栏和公益404页面；6.添加桌面小宠物和访客统计；7.添加博客运行时间和代码橙色高亮； 目前欠缺的功能一个是“相册”，还有一个就是博客标题的加载方式希望更加高逼格。至于SEO和单独域名，我暂时还没有想去做，等将来再加上吧。而这篇文章里主要说的就是“博客添加音乐”和“侧栏左移”这两个事儿。 博客添加音乐Next主题添加网易云音乐不是一个很难的事儿，但是我发现对于非大陆的IP地址（比如我用的是公司VPN，香港IP），侧栏的网易云音乐就无法播放，而且打开博客页面就自动播放音乐这点对来访的用户来说，体验感觉是见仁见智。所以我打算把侧栏的网易云音乐撤掉，在“关于我”里单独放进音乐歌单。 若单独配置音乐同时不想被IP地址打扰的话可以使用由DIYgod所制作的APlayer。官方材料在这里：https://aplayer.js.org/docs/#/?id=options 。 要使用APlayer需要先在hexo根目录里安装插件：npm install aplayer --save 安装插件OK了后，具体在文章里添加的语法就是： 注意：如果lrc用的是这种URL形式，hexo g时请保持网络通畅，如果没有歌词，可以不用添加。 现在的世面上很少有在线提供歌曲MP3地址的网站了，很多都是下载mp3到本地，这里我推荐一个免费下载MP3的网站：https://www.tikitiki.cn 。里面有QQ音乐、网易云音乐和酷狗的资源，基本上大陆没有被封杀的艺人作品都能在里面找到（抱歉了，陈升先生和黄耀明先生）。然后再搭配七牛云，把下载的MP3和封面图片上传到七牛云存储里，然后搭配提供的外网域名就可以填写MP3地址和封面地址了。如图： 如果想做一个歌单，也很简单，如下：1234567891011121314151617181920212223&#123;% aplayerlist %&#125; &#123; \"autoplay\": false, \"showlrc\": 3, \"mutex\": true, \"music\": [ &#123; \"title\": \"歌曲名\", \"author\": \"歌手名\", \"url\": \"https://具体地址.mp3\", \"pic\": \"https://封面图.jpg\", \"lrc\": \"https://歌词.lrc\" #不愿意加歌词可以不写，注意逗号 &#125;, &#123; \"title\": \"歌曲名\", \"author\": \"歌手名\", \"url\": \"https://具体地址.mp3\", \"pic\": \"https://封面图.jpg\", \"lrc\": \"https://歌词.lrc\" &#125; ] &#125;&#123;% endaplayerlist %&#125; 不过我这个七牛云的账号比较挫，没有做https，只好用http了… 把侧栏移动到左边博客自从安装了宠物之后，发现小宠物与侧栏重叠，看上去感觉很不友好，但是很奇怪，默认的宠物即使调整了botton依旧无法移动，所以我就想那就把整个侧栏移动到了左边，但是发现更改next主题的_config.xml里的“sidebar的position属性”发现并没有效果，后来经过一顿查找，找到了改成左侧栏的方法(适用于next 5.1.3版本)。 首先，先更改\\themes\\next\\source\\css\\_common\\components\\sidebar\\sidebar.styl，把第三行的right改成left,如下：123.sidebar &#123; position: fixed; left: 0; 保存之后，打开\\themes\\next\\source\\js\\src\\motion.js，把101行和167行的paddingRight全改成paddingLeft,同时找到类似如下的代码，并替换成如下代码:123456789101112131415161718192021var sidebarToggleLine1st = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-first', status: &#123; arrow: &#123;width: '50%', rotateZ: '45deg', top: '2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '45deg', top: '5px', left: 0&#125; &#125;&#125;);var sidebarToggleLine2nd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-middle', status: &#123; arrow: &#123;width: '90%'&#125;, close: &#123;opacity: 0&#125; &#125;&#125;);var sidebarToggleLine3rd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-last', status: &#123; arrow: &#123;width: '50%', rotateZ: '-45deg', top: '-2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '-45deg', top: '-5px', left: 0&#125; &#125;&#125;); 保存完毕之后，hexo clean和hexo d -g。刷新一下页面，就大功告成了！ 参考资料https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html#hcm=1515719347596232 （这篇文章强烈推荐！）http://www.lmnsyunhao.cn/2017/03/29/hexo-next-themes-left-sidebar/http://mashirosorata.vicp.io/HEXO-NEXT主题个性化配置.html","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://yoursite.com/categories/博客搭建/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"},{"name":"Next","slug":"Next","permalink":"http://yoursite.com/tags/Next/"},{"name":"博客美化","slug":"博客美化","permalink":"http://yoursite.com/tags/博客美化/"}]},{"title":"Zabbix监控ActiveMQ队列数以及结合Grafana展示","slug":"Zabbix监控ActiveMQ队列数以及结合Grafana展示","date":"2018-01-11T13:43:01.000Z","updated":"2018-01-22T09:08:16.057Z","comments":true,"path":"2018/01/11/Zabbix监控ActiveMQ队列数以及结合Grafana展示/","link":"","permalink":"http://yoursite.com/2018/01/11/Zabbix监控ActiveMQ队列数以及结合Grafana展示/","excerpt":"","text":"在ZABBIX上监控MQ队列众所周知，Zabbix是可以自定义监控项的，那么就代表只要能获得到的数字都可以进入Zabbix的监控范围内。作为消息队列，Activemq里的“消息堆积数”是监控的重点项目之一。 获取消息堆积数并不是一个很难的事儿，浏览器里登陆MQ的web网页控制台，输入账号密码之后，在Queues的网页里就能看到如下的界面： 其中Pending Messages就是“等待消息”，Consumers是“消费者”，Enqueued是“入队”，Dequeued是“出队”。入队数=出队数+等待数。 现在我们要获取到图中的队列叫AggregateQueue里的那个23596，很简单，shell语句是： 1curl -s -u网站用户名:网站密码 http://网站外网IP地址:8161/admin/queues.jsp | grep -A 5 \"具体的队列名&lt;/a&gt;&lt;/td&gt;\"|awk -F '&lt;' '&#123;print $2&#125;'|sed 's/td&gt;//g'|head -2|tail -1 这里curl有一个-s的参数，不然会显示curl的状态。如图： 语句在此，写脚本就很easy了。不过我这里就直接监控具体数字了，没有写脚本，如果要写python脚本的话，我推荐各位移步：http://blog.51cto.com/sfzhang88/1316789 ，看一下这篇文章。 现在把这个监控项添加到具体的zabbix_agentd.conf里吧，具体添加过程可以参看 http://blog.51cto.com/chenx1242/1839829 ，由于是curl网站，那么直接把这个监控项加到Zabbix-server里就好，然后使用zabbix_get检查一下。有的zabbix 3.x里没有zabbix_get，安装zabbix_get方法：yum install zabbix-get.x86_64。 zabbix_get检查情况和具体的trigger情况如下： 配置Zabbix结合Grafana我使用的Grafana版本是4.3.2，下载地址：https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.3.2-1.x86_64.rpm ，下载完毕之后，直接yum install /路径/grafana-4.3.2-1.x86_64.rpm，由于Grafana使用的是AWS的云存储，可能在墙内的下载会比较吃力，有断开的情况就多试几次。话说Grafana的升级是比较频繁的，半年不到的时间升级了三次，现在最新版本已经是4.6.2。所以说这玩意，其实选择一个稳定的就好。 启动grafana的方法就是：systemctl start grafana-server.service，配置开机自启动的方法：chkconfig grafana-server on。然后在浏览器里输入grafana外网ip地址：3000就能看到grafana的界面，默认密码：admin/admin，grafana默认的日志存储路径是/var/log/grafana/。 Grafana与ZABBIX联系的插件下载方式：grafana-cli plugins install alexanderzobnin-zabbix-app，安装之后，重启一下grafana-server，在web界面就会看到插件已经成功安装，如图： 其他更多的插件下载可以在grafana的官方网站查看到：https://grafana.com/plugins ，用grafana-cli都能搞定，还是那话，墙里的同学速度要慢一点。 现在配置Zabbix作为Grafana的数据源，首选点击网站上面的红色漩涡标志，选择zabbix，点击Plugin Config，点击Enable，启动Zabbix插件。如图： 再次点击红色漩涡，这次选择Data Sources，点击Add data source，如果插件启动成功，那么在Type里是可以选择zabbix的，然后就是填各种东西，如图： 这里有一些要额外说明：1）url这个是zabbix的API地址http://ip/zabbix/api_jsonrpc.php，这个可以在zabbix服务端上可查找find / -name api_*.php；2）username和passwd是zabbix WEB界面的登录用户名和密码，有读的权限即可；3）alerting选择启动，min severity选择high； 然后点击save &amp; test，如果都正确的话，就会出现success，如图： 在Grafana展示趋势图点击左上方红色漩涡，Dashboards的地方点击+new，然后在小齿轮的地方选择Templating,如图： 在Templating里要建立4个模板，其中group的添加方法如下，如果Query正确的话，在点击Include All option的时候，就会有“组”显示出，而且和zabbix里完全一致： group添加完了，还有host、application、iteams，添加的大同小异，需要注意的是Query的不同：host的Query：$group.*application的Query: $group.$host.*iterm的Query:$group.$host.$application.* 以上四个template都搞定之后，应该是这个样子： 模板搞定了，下面就是图形展示，选择对应的hosts、application和items就自动有图像生成了！ 最后说一下页面自动刷新，点击右上角“Last 6 hours”, 在弹出的下拉框中，选择Time range下的Refreshing every选项，点击下拉框按钮，默认应该有“off”和“1m”两个选项。点击“1m” 然后Apply设置，即为每一分钟刷新一次数据的意思。设置成功后，在原来Last 6 hours的后面会出现Refresh every 1m的橙色文字！ 参考资料《实践MQ的小demo》http://www.jianshu.com/p/3a39c8dd4f29","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"grafana","slug":"grafana","permalink":"http://yoursite.com/tags/grafana/"}]},{"title":"在Python使用yaml的几个例子","slug":"在Python使用yaml的几个例子","date":"2018-01-11T02:11:17.000Z","updated":"2018-01-22T02:33:38.843Z","comments":true,"path":"2018/01/11/在Python使用yaml的几个例子/","link":"","permalink":"http://yoursite.com/2018/01/11/在Python使用yaml的几个例子/","excerpt":"","text":"python版本：2.7.5安装方法：pip install PyYaml “把变量写进yaml做配置文件，然后python脚本从yaml文件里面取到变量”的方法最近是在python编程里比较流行的配置项方法。yaml更加易读，而且通过缩进表示结构，这一点与python不谋而合。 Yaml有四个比较常用的用法，分别是load()、dump()、load_all()、dump_all()。这篇文章主要就是了解一下这四个方法。 首先我们先写一个很简单的test.py： 12345678910111213# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_str = \"\"\"name: Gakkiage: 29job: Actressrelationship: Wife\"\"\" aaa = yaml.load(yaml_str)print aaa 执行的话，看到的效果就是： 12[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 这个aaa的类型是一个字典（dict），如果要得到里面那个”Gakki”，那么就是aaa[‘name’]。通过load方法，一个字符串变成了一个字典。 现在把test.py换成如下： 123456789101112# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_dict = &#123;\"name\": \"Gakki\", \"age\": 29, \"job\": \"Actress\", \"relationship\": \"Wife\" &#125;aaa = yaml.dump(yaml_dict, default_flow_style=False)print aaaprint (type(aaa)) 执行后的效果如下： 123456[root@paas-online-crs-001 chentest]# python test.py age: 29job: Actressname: Gakkirelationship: Wife&lt;type 'str'&gt; 可见，通过dump方法，把一个dict变成了一个字符串。 现在写一个配置文件，假如它叫test.yaml: 1234- Gakki- 29 - Actress- Wife 再来一个test.py，内容如下: 1234567# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yaml aaa = yaml.load(file('test.yaml', 'r'))print aaaprint (type(aaa)) 执行这个test.py： 123[root@paas-online-crs-001 chentest]# python test.py ['Gakki', 29, 'Actress', 'Wife']&lt;type 'list'&gt; #得到了一个列表 如果把那个test.yaml升级成字典和列表的混合结构，如下： 1234567- name: Chris age: 29 job: OM Engineer- name: Gakki age: 29 job: Actress relationship: Wife 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py [&#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;, &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125;]&lt;type 'list'&gt; 既然获得的结果是一个包含字典的列表，那么如果要获得“Gakki”就是aaa[1][‘name’] 如果想要复制和引用，那么要用&amp;和*，比如把test.yaml改成这样： 12name: &amp;name Gakkiwife: *name 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'name': 'Gakki', 'wife': 'Gakki'&#125;&lt;type 'dict'&gt; 在同一个yaml文件中，可以用 — 来分段，这样可以将多个文档写在一个文件中： 123456789--- name: Chris age: 29 job: OM Engineer--- name: Gakki age: 29 job: Actress relationship: Wife 再写一个新的test.py如下: 123456# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlys = yaml.load_all(file('gakki.yaml', 'r')) #load_all() 方法会生成一个迭代器，可以用for输出出来for y in ys: print y 执行这个py的效果： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;&#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 参考文档：https://huilansame.github.io/huilansame.github.io/archivers/recommond-case-file-type-yaml","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"编程","slug":"编程","permalink":"http://yoursite.com/tags/编程/"}]},{"title":"使用Zabbix去监控Redis","slug":"使用Zabbix去监控Redis","date":"2018-01-10T14:49:04.000Z","updated":"2018-01-22T02:32:59.824Z","comments":true,"path":"2018/01/10/使用Zabbix去监控Redis/","link":"","permalink":"http://yoursite.com/2018/01/10/使用Zabbix去监控Redis/","excerpt":"","text":"了解Redis的info要获得Redis的当前情况，使用info命令即可。具体用法：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info [参数] 。针对不同的参数就会看到具体的数字，如果没有带参数，那么就会把默认情况写出来，如果带上all参数，那么就会把所有情况都写出来。比如：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info server，就会看到redis关于server的一些数据，如下：可以看出，从server里可以查询到的是版本号、pid号、配置文件路径等等东西。 如果参数是client，记录了是客户端的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info clients# Clientsconnected_clients:64 #已连接客户端的数量（不包括通过从属服务器连接的客户端）client_longest_output_list:0 #当前连接的客户端当中，最长的输出列表client_biggest_input_buf:0 #当前连接的客户端当中，最大输入缓存blocked_clients:0 #正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 如果参数是memory，记录的是内存的相关信息： 12345678910[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info memory# Memoryused_memory:2252984 #由 Redis 分配器分配的内存总量，以字节（byte）为单位used_memory_human:2.15M #上面的数字加上了单位used_memory_rss:9293824 #常驻集大小，即Redis已分配的内存总量。这个值和top、ps等命令的输出一致used_memory_peak:2607520 #Redis 的内存消耗峰值（以字节为单位）used_memory_peak_human:2.49M #上面的数字加上了单位used_memory_lua:33792 #Lua 引擎所使用的内存大小（以字节为单位）mem_fragmentation_ratio:4.13 #used_memory_rss 和 used_memory 之间的比率mem_allocator:jemalloc-3.2.0 #在编译时指定的，Redis所使用的内存分配器。可以是libc、jemalloc或者tcmalloc。 这里要注意！在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿（我这个机器就已经属于严重的级别了）。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。 如果参数是stats，那就是统计的相关信息： 12345678910111213141516[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info stats# Statstotal_connections_received:150383 #服务器已接受的连接请求数量total_commands_processed:500935 #服务器已执行的命令数量instantaneous_ops_per_sec:0 #服务器每秒钟执行的命令数量rejected_connections:0 #因为最大客户端数量限制而被拒绝的连接请求数量sync_full:0 sync_partial_ok:0 sync_partial_err:0 #查找数据库键成功的次数expired_keys:41 #因为过期而被自动删除的数据库键数量evicted_keys:0 #因为最大内存容量限制而被驱逐（evict）的键数量keyspace_hits:78121 #查找数据库键成功的次数keyspace_misses:56 #查找数据库键失败的次数pubsub_channels:0 #目前被订阅的频道数量pubsub_patterns:0 #目前被订阅的模式数量latest_fork_usec:878 #最近一次 fork() 操作耗费的微秒数 如果参数是CPU，那么就会返回CPU的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info cpu# CPUused_cpu_sys:63.95 #Redis服务器耗费的系统CPUused_cpu_user:129.54 #Redis服务器耗费的用户CPU used_cpu_sys_children:1.70 #子进程耗费的系统CPUused_cpu_user_children:1.03 #子进程耗费的用户CPU 如果参数是keyspace，那么就会返回数据库相关的统计信息： 123[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info keyspace# Keyspacedb0:keys=262,expires=183,avg_ttl=284091259423 #据库的键数量、数据库设置有过期时间的key的数量（这个值减少是正常的） 除了以上之外其他还有更多信息，请移步：http://redisdoc.com/server/info.html 。感谢前人栽树！！！ 使用zabbix监控redis用zabbix监控redis是一个很简单的事儿，只需要把需要监控的数据提取出来即可。而提取数据的方法就是利用info去得到对应的数值。 首先先来一个判断redis服务器连接的脚本： 1234567891011[root@func-redis-001 ~]# cat check_redis.sh#这个脚本是用来zabbix监控自建redis的#!/bin/bashPORT='6379'PASSWD=‘REDIS密码’ STATUS_redis=$(redis-cli -h '127.0.0.1' -p $PORT -a $PASSWD ping)if [ \"$STATUS_redis\" == 'PONG' ];then echo '1'else echo '0'fi 然后更改zabbix_agentd.conf,如下： 12UserParameter=redis_status[*],redis-cli -h '127.0.0.1' -p $1 info | grep -w $2 | awk -F':' '&#123;print $NF&#125;'UserParameter=redis_ping,sudo sh /root/check_redis.sh 修改/etc/sudoers文件如下： 1234## Allow root to run any commands anywhereroot ALL=(ALL) ALLzabbix ALL=(ALL) NOPASSWD:ALL #这个是新增Defaults:zabbix !requiretty #这个是新增 保存之后，重启zabbix-agent服务，由于我这个redis是通过zabbix-proxy监控的，所以在zabbix-proxy一端用zabbix_get来查看结果： 然后在zabbix-proxy的模板里面添加一些需要监控的item即可，有必要的话可以设置trigger+action用来报警，如图： 最后就是grafana搞一个炫酷的图表来，如图： 最后一点，关于redis的内存优化，各位可以来看看：https://cachecloud.github.io/2017/02/16/Redis%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/ ，写的很全面了。还有zabbix各种模板整理，有需要的同学也可以去下载：https://monitoringartist.github.io/zabbix-searcher/ 。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"通过nginx配置修改网页cookie属性","slug":"通过nginx配置修改网页cookie属性","date":"2018-01-10T07:48:08.000Z","updated":"2018-01-22T02:33:37.326Z","comments":true,"path":"2018/01/10/通过nginx配置修改网页cookie属性/","link":"","permalink":"http://yoursite.com/2018/01/10/通过nginx配置修改网页cookie属性/","excerpt":"","text":"需求与具体配置公司的电子商城在十九大等保安检时期被折腾出去，结果这几天又折腾回来了，据说还会是明年大数据研究院的主要开发项目。结果回来没几天被测试中心的人在cookie方面发现了几个问题，如下： cookie没有使用http-only； cookie没有携带secure属性； http头中需要配置“X-Frame-Options：SAMEORIGIN”； 以上这几点可以通过nginx的配置来轻松实现，具体方法就是在需要更改的网页server的配置里面添加下面几句话。如图： 123add_header Set-Cookie \"HttpOnly\";add_header Set-Cookie \"Secure\";add_header X-Frame-Options \"SAMEORIGIN\"; 然后保存配置文件，nginx -s reload平滑重启即可，通过chrome在目标网页里按下ctrl+shift+c，先选择好network，然后重新刷新一下界面，选择域名，对应域名下点击headers，就会看到cookie的配置情况，如图： 扩展内容看到配置已经生效。那么这几个配置主要是干什么的呢？其实主要都是防范XSS攻击（跨域脚本攻击）的。 Cookie的Secure属性，意味着保持Cookie通信只限于加密传输，指示浏览器仅仅在通过安全/加密连接才能使用该Cookie。如果一个Web服务器从一个非安全连接里设置了一个带有secure属性的Cookie，当Cookie被发送到客户端时，它仍然能通过中间人攻击来拦截。 Cookie的HttpOnly属性，指示浏览器不要在除HTTP（和HTTPS)请求之外暴露Cookie。一个有HttpOnly属性的Cookie，是不可以通过例如调用JavaScript(引用document.cookie)这种非HTTP方式来访问。因此，也不可能通过跨域脚本（一种非常普通的攻击技术）来偷走这种Cookie。 X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在frame, iframe或者object中展现的标记。网站可以使用此功能，来确保自己网站的内容没有被嵌到别人的网站中去，也从而避免了点击劫持 (clickjacking) 的攻击。它有三个可选择项： 123DENY：表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许；SAMEORIGIN：表示该页面可以在相同域名页面的 frame 中展示；ALLOW-FROM uri地址：表示该页面可以在指定来源的 frame 中展示； 如果设置为 DENY，不光在别人的网站 frame 嵌入时会无法加载，在同域名页面中同样会无法加载。另一方面，如果设置为 SAMEORIGIN，那么页面就可以在同域名页面的 frame 中嵌套。 这里还要额外注意一下！配置了Cookie的HttpOnly属性和Secure属性之后，如果测试中心的人使用的协议是http而不是https的话，会有“浏览器请求后端服务时header不会带上cookie参数”的现象，那是因为“由于secure属性的存在，导致浏览器在与服务器通信时不会使用该cookie”。这个时候就需要把secure=”true”这个配置去掉才可以达到正确测试的目的。 参考资料https://imququ.com/post/my-nginx-conf-for-security.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"django新增class的时候数据库格式出错","slug":"django新增class的时候数据库格式出错","date":"2018-01-10T07:33:06.000Z","updated":"2018-01-22T02:27:44.606Z","comments":true,"path":"2018/01/10/django新增class的时候数据库格式出错/","link":"","permalink":"http://yoursite.com/2018/01/10/django新增class的时候数据库格式出错/","excerpt":"","text":"这几天开发频繁要求查看生产环境zookeeper的配置，于是就想在django里添加一个新的栏，以文本的形式随时更新zookeeper的情况。 于是我就登陆了django，在model.py里添加一个新的class，如下： 12345678#建立杭州测试ZK配置class HZfunczk(models.Model): hzfunczk_remark = models.CharField(verbose_name='杭州测试ZK配置',max_length=50000,blank=true) hzfunczk_signer = models.CharField(verbose_name='登记人',max_length=30,default='system') hzfunczk_signtime = models.DateField(auto_now_add=True) def __unicode__(self): return self.domain_name 然后在django的目录下执行python manage.py makemigrations，这一步没问题，但是在执行python manage.py migrate的时候，就出现了下面的错误： 我开始认为是charfield写错了，应该写Textfield，于是更改了一下，但是保存之后，再执行python manage.py migrate还是出错。其实这个错误主要原因就是因为我那个50000设置错了，因为字段hzfunczk_remark定义的长度50000超出了mysql的varchar的最大长度21845（在utf8编码情况下）。于是我就在model.py里把这个长度改成20000，保存之后，还是执行到python manage.py migrate这一步，依旧爆上面的错误。于是我就干脆把这个class先删除掉，没想到都删除光了，还是在make的时候会爆错。 这就很奇怪了，我已经删掉了为啥还有这样的事儿？于是就干脆进入到数据库去看，由于我现在只知道列名叫hzfunczk_remark，所以我要根据这个列名去查它所在的表，maria反馈如下： 12MariaDB [abccs]&gt; select TABLE_SCHEMA, TABLE_NAME from information_schema.columns where COLUMN_NAME = 'hzfunczk_remark'; Empty set (0.02 sec) 好尴尬呀，数据库里压根就没有列名为“hzfunczk_remark”的表。然后由于python manage.py migrate报错，现在无法启动django。怎么办？ 遇到这种状况，就去django里的migrations文件夹，这个文件夹里有很多的以时间命名的py文件，它们记录着数据库的每一步操作，不过这里面的py还没有真正执行到数据库里，我找到当时添加class那个时间段的py文件，里面是这样的： 先把里面CharField改成TextField，然后把50000改成小于21845的就行了。如果你性子比较烈，那就干脆把这个文件以及之后产生的所有文件都删除掉。重新的去make。 如果还是实在不行，还有一个万不得已的办法，几乎所有的数据库错误都可以用这个方法解决：将migrations文件夹下的文件除了init.py全部删掉，然后将数据库drop掉，重新建数据库。然后make和migrate，就可以使用一个新的数据库（但愿你永远用不到这个方法）。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"通道信息加密工具--Qtunnel","slug":"通道信息加密工具-Qtunnel","date":"2018-01-10T04:20:01.000Z","updated":"2018-01-22T02:33:26.540Z","comments":true,"path":"2018/01/10/通道信息加密工具-Qtunnel/","link":"","permalink":"http://yoursite.com/2018/01/10/通道信息加密工具-Qtunnel/","excerpt":"","text":"前言数据库做异地容灾是一个很常见的现象，既然信息要跨地域传递，要么就很土豪的打通机房之间的链路或者动用VPN，要不然就不可避免的走公网网络传输信息。既然选择了公网，那么数据库的语句就很容易被人监听到，所以把那些明文加密是必不可少的环节。 mysql支持tls/ssl加密方法对信息进行加密，这个方法的配置也很简单，就是两边各加上一个nginx，一个是正向代理一个是反向代理，配上ssl证书，然后就像配置网站https协议那样，在nginx.conf里开启ssl监听即可。 但是这种方法有一点小问题，就是在进行SSL握手之前，mysql会发送Server Greeting和Login Request数据包，然后才有可能使用SSL握手。这样步骤就多了一步鉴权，对访问性能有所影响。所以这个时候，我选择了另一个用于加密client和server之间链路通信的工具—-Qtunnel，因为它直接加密，速度更快。 Git的地址在这里：https://github.com/arstercz/qtunnel ，感谢arstercz大神的再加工！ 上面说过了Qtunnel是不需要认证的，默认加密方法是RC4，以字节流的方式加密明文的每一个字节，而且密钥长度最长支持256位，可以很好的抵御暴力搜索密钥的攻击，总而言之，Qtunnel是一个轻量且快速的加解密工具，而且还可以搭配atlas等数据库中间件使用。 下载与准备由于Qtunnel是用go语言写的，所以需要先安装golang，centos服务器的yum安装方法如下: 12rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install -y golang go语言安装完毕之后，我们就git clone https://github.com/arstercz/qtunnel.git ，获得qtunnel文件夹，文件夹内容如下： make，如果没有任何报错，那么就是安装成功了，使用./bin/qtunnel -h语句验证一番： 本次实验的计划是这样的：用A机器访问B机器的mysql，并且插入数据，在B机器上的3306端口抓包，查看数据是否是明文；然后再在A机器和B机器上都安装qtunnel并且启动，然后重新插入数据，在B机器上的端口抓包，查看数据是否被加密。流程图如下： 实验开始A机器和B机器都是使用阿里云虚拟服务器，版本都是centos 6.4，现在我们的加密实验正式开始。 首先A和B机器上都不启动qtunnel，然后我们在A机器上登陆B机器的数据库，如果之前没有授权，那么授权语句是： GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;A机器的IP地址&#39; IDENTIFIED BY &#39;密码&#39; WITH GRANT OPTION; 登陆mysql之后，我们随意的插一个语句，然后通过抓包发现无论这个语句还是数据库的反馈都是以明文的形式呈现，如图： 这种让数据裸奔的行为无疑于找死，那么这个时候我们就要配置一下qtunnel，来看一下它的加密效果。 在A服务器上，我们设定qtunnel是客户端，手动建立一个conf文件，比如vim /etc/conn.conf，内容如下： 123456[client1]faddr = 10.252.215.108:3309 #这里是qtunnel客户端的IPbaddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPcryptoMethod = rc4 #这里选用rc4的方式加密secret = 3301_test%Iad #rc4密钥，服务端的密码必须跟这个一致！clientmode = true #表示这端是客户端 然后使用./bin/qtunnel -conf=/etc/conn.conf -daemon -logto=syslog启动qtunnel，看一下进程和端口情况，如图： 在B服务器上，同样手动建立一个配置文件，假设也叫conn.conf，内容如下： 123456[server1]faddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPbaddr = 10.175.193.239:3306 #这里是数据库的地址，由于在同一台机器上，所以地址一样cryptoMethod = rc4 secret = 3301_test%Iad #rc4密钥，跟client密钥一致clientmode = false #表示这是服务器端 也用同样的语句启动qtunnel，查看3310这个端口已经被监听了： 现在，我们在A服务器上来重新连接B数据库，但是要注意！这个时候mysql里的-h不能再是B的IP地址了，而是A的地址！因为qtunnel现在已经打通了一个通道，访问qtunnel的3310端口就等于是访问B数据库的3306端口（有点类似atlas的意思）。 连上之后，我们随意插入一些语句，看一下qtunnel的能力: 可见这个时候，抓包显示都是加密的文字了，实验成功！ 总结与参考资料总结一下：qtunnel采用rc4加密，在算法强度和速度方面是很好的选择，不会引起slave太大的延迟，对管理员或开发而言数据都是透明的（如果在上面的实验启动了qtunnel之后，不监听3310端口，而是监听3306端口，得到的依旧是明文），只是在两端传输的过程中增加了加解密处理。核心的业务(比如用户和充值)在做异地架构的时候可以考虑该方式增强数据的安全性。 《mysql使用ssl简析》：https://hsulei.com/2017/10/19/mysql%E4%BD%BF%E7%94%A8ssl%E7%AE%80%E6%9E%90/《使用ssl加密mysql 5.6的官方文档》：https://dev.mysql.com/doc/refman/5.6/en/encrypted-connections.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"加密技术","slug":"加密技术","permalink":"http://yoursite.com/tags/加密技术/"},{"name":"Qtunnel","slug":"Qtunnel","permalink":"http://yoursite.com/tags/Qtunnel/"}]},{"title":"Zabbix3.0搭配微信企业号报警","slug":"Zabbix3-0搭配微信企业号报警","date":"2018-01-10T03:18:02.000Z","updated":"2018-01-22T02:28:56.199Z","comments":true,"path":"2018/01/10/Zabbix3-0搭配微信企业号报警/","link":"","permalink":"http://yoursite.com/2018/01/10/Zabbix3-0搭配微信企业号报警/","excerpt":"","text":"Zabbix搭配微信企业号报警是一个很流行的手段，这里说一下如何配置。 准备工作建立一个企业号以及具体应用的链接在此：http://chenx1242.blog.51cto.com/10430133/1954634，里面写的都很明白了。 现在打开微信企业号的官方网站https://work.weixin.qq.com，然后扫描一下微信二维码登录到企业号的控制台。 在控制台网页里，需要查找几个元素，分别是CorpID、应用AgentId、应用Secret还有用户账号。 首先，在控制台里选择“我的企业”，然后就可以看见CorpID，如图： 然后点击“企业应用”，如果没有应用，那么就新建立一个应用。比如我已经建立了一个应用叫“zabbix告警”，那么应用AgentId和应用Secret就在如图的位置： 有了上面的CropID和Secret，就可以去验证一下accesstoken，登录http://qydev.weixin.qq.com/debug ，后在填入对应的CropID和Secret，看一下返回结果是否是“HTTP/1.0 200 OK”，如图： 在这个“zabbix告警”的应用里可见范围里添加对应需要通知的人，然后在“通讯录”里，找到对应的人，记录他们的账号，如图： 材料已经俱备完毕，现在需要做的是更改zabbix-server配置。 首先，在zabbix-server.conf里添加一句AlertScriptsPath=/usr/lib/zabbix/alertscripts，这是为了说明一下脚本所在的路径。当然，这个路径你可以自己更改，然后重启一下zabbix-server。 编写脚本cd /usr/lib/zabbix/alertscripts，在这个目录下我们要新写一个微信脚本，比如脚本名称叫wechat.py。 这个python脚本是需要requests模块的，所以需要先安装这个模块，安装方法如下： 12pip install requestspip install --upgrade requests 而python脚本内容如下，感谢https://github.com/X-Mars/Zabbix-Alert-WeChat/的脚本： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/python2.7#_*_coding:utf-8 _*_#this script is used for alarm by WECHATimport requests,sys,jsonimport urllib3urllib3.disable_warnings()reload(sys)sys.setdefaultencoding('utf-8')def GetToken(Corpid,Secret): Url = \"https://qyapi.weixin.qq.com/cgi-bin/gettoken\" Data = &#123; \"corpid\":Corpid, \"corpsecret\":Secret &#125; r = requests.get(url=Url,params=Data,verify=False) Token = r.json()['access_token'] return Token def SendMessage(Token,User,Agentid,Subject,Content): Url = \"https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=%s\" % Token Data = &#123; \"touser\": User, # 企业号中的用户帐号，在zabbix用户Media中配置，如果配置不正常，将按部门发送。 #\"totag\": Tagid, # 企业号中的部门id，群发时使用。 \"msgtype\": \"text\", # 消息类型。 \"agentid\": Agentid, # 企业号中的应用id。 \"text\": &#123; \"content\": Subject + '\\n' + Content &#125;, \"safe\": \"0\" &#125; r = requests.post(url=Url,data=json.dumps(Data),verify=False) return r.text if __name__ == '__main__': User = sys.argv[1] # zabbix传过来的第一个参数 Subject = sys.argv[2] # zabbix传过来的第二个参数 Content = sys.argv[3] # zabbix传过来的第三个参数 Corpid = \"这里填写Corpid\" Secret = \"这里填写Secret\" Agentid = \"这里填写应用的agentid\" Token = GetToken(Corpid, Secret) Status = SendMessage(Token,User,Agentid,Subject,Content) print Status 脚本保存后，chown -R zabbix:zabbix wechat.py，然后小试一下，上面看到“Zabbix告警”这个微信应用里有一个用户账号叫ChenShuo，那么wechat.py执行语句是：python wechat.py ChenShuo 这个是标题 这里是正文！！ 然后看一下微信，如图： 正确出现了微信提示，可见这个脚本是OK的了。 配置zabbix现在我们要登录到zabbix网站，最上面的“Administration”里选择“Media types”，新建立一个Media type，如图： 保存之后，在“Administration”里选择“Users”，在Admin用户里点击“media”,把刚刚新增的“微信告警”这个media type添加进去，如图： 通知手段配置完毕，现在就是要在具体的Trigger上把微信告警这个新手段添加到active里。首先打开Configuration里的actions界面。此时假设现在有一个告警Trigger叫“模块发生了重启”，判断模块是否重启的依据就是pid值是否发生了变化。那么点击这个Trigger，在action里把“微信告警”添加到报警手段里，如图： 保存之后，整个的微信告警配置就完成了。为了验证配置是否生效，我冒死重启了一台生产环境的服务器，当然啦，好孩子千万不要效仿。 收到微信提示如图：不过考虑到微信告警可能会有所延迟，所以在这建议大家把告警阈值配置稍微早一点，避免“孩子死了奶来了”这种尴尬的情况。 参考资料http://www.yfshare.vip/2017/04/13/Zabbix%E4%B9%8B%E5%BE%AE%E4%BF%A1-Wechat-%E5%91%8A%E8%AD%A6/https://github.com/X-Mars/Zabbix-Alert-WeChat/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"自己动手搭建一个hexo博客demo","slug":"自己动手搭建一个hexo博客demo","date":"2018-01-10T02:54:51.000Z","updated":"2018-01-22T04:05:11.491Z","comments":true,"path":"2018/01/10/自己动手搭建一个hexo博客demo/","link":"","permalink":"http://yoursite.com/2018/01/10/自己动手搭建一个hexo博客demo/","excerpt":"","text":"曾几何时，自己动手做一个博客的想法愈加强烈，想在里面放一些更多除了技术之外的东西，比如烹饪的美食，比如PVP的视频，比如拍摄的照片，比如篮球足球的评论。在这种需求下，我从众多博客框架里面选择了hexo，原因就是“很多人都推荐hexo”….（囧）于是乎我在windows里搞一个，由于我在公司的网络是可以跨越长城的，所以搞github有一点天然的优势。而且github的博客不用花钱搞域名，他直接免费提供… 在搞github的时候墙裂推荐各位去用命令行，有linux的基本基础就可以很熟练的使用命令行搞github， 它的客户端真的不如命令行好用。 准备工作先去注册一个github，然后去https://git-scm.com 上下载一个最新的git windows的客户端，我下载的是2.15.1版本，如图： 下载完毕之后，就把这个exe文件安装，然后在“开始”里找到git再打开“Git Bash”，我的github账号是RorschachChan，电子邮件也已经配置过，所以现在就在这个bash窗口里写入如下语句： 12git config --global user.name \"RorschachChan\"git config --global user.email \"chenx1242@163.com\" 上面git config –global 参数，表示你这台机器上所有的Git仓库都会使用这个配置。 再去https://nodejs.org/en/download/ 上根据自己windows的情况，下载最新的nodejs，下载完了之后就一路next，然后需要退出重进一下git bash，在bash的命令行里输入node -v，看到版本号就是OK，同时输入node，$会变成&gt;，然后输入.exit就可以退出返回到bash。 然后就是安装hexo，hexo的安装比较简单，就是在git bash里输入npm install -g hexo-cli和npm install -g hexo，然后需要等待一会，如果出现了“npm ERR! ”不要怕，重新输入一次应该就会好了，安装完毕之后，输入$ hexo -v查看hexo的版本，如图： 然后建立一个github ssh密钥，在git bash里输入ssh-keygen -t rsa -C &quot;你的邮箱&quot;，然后告诉密钥生成的路径（下图黄框）以及会让你输入对应的口诀（红色箭头），这个口诀很重要，要妥善保存，如图： 这个密码会在你提交项目（hexo d）时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。这时候去C:\\Users\\33664\\.ssh的路径里就会看到一对钥匙，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 来到github的个人配置里，选择“SSH and GPG keys”，然后输入title和id_rsa.pub的内容，点击“add ssh key”。如图：准备工作的最后一步，就是建立一个文件夹，我的文件夹建立在E盘下，名字就叫hexo。 开始搭建博客首先在git bash里进入/e/hexo，然后输入hexo init，这个命令是初始化命令，再输入hexo -g来生成静态文件，执行之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github上你的用户名.github.io的仓库上去的。然后可以输入hexo s来本地启动hexo，这个时候跑到浏览器里输入localhost:4000就会看到hexo博客最初的一个样子，如图： 这个默认的主题比较难看，我们去https://github.com/iissnan/hexo-theme-next 下载最近一个比较火爆的主题next,并且把这个下载到hexo文件夹里的themes/next里，语句是：git clone https://github.com/iissnan/hexo-theme-next.git themes/next 然后打开hexo文件夹里的_config.xml，把原有的theme注释，换成新的next，注意，中间是有空格的！ 12#theme: landscapetheme: next 然后hexo clean和hexo g清除 Hexo 的缓存和重新生成静态文件，再次hexo s启动进程，来到浏览看一下发现博客的样子就变成下面的样子了：这个看上去就简单大方很多了吧。 把博客上传到github现在有人问了，这个博客看上去好像很美，但是有两个致命的缺陷：第一，内容都是在我的windows里，如果我这个电脑坏了/出差/换新硬盘，那么如何保证我以前文件？第二，我启动进程需要执行 hexo -s，如果我电脑关机了，岂不是博客无法打开？ 需要解决就要把磁盘上的内容传递到github库里了，同时github是常开进程的，这样既可以更新我们的内容又不会关闭博客进程，除非github这个网站黄了。 先去github网站去建立一个库（repository），这里我直接选择了公共读，如图： 然后在hexo文件夹里面，修改一下_config.xml的几个地方： 1234567891011121314# Sitetitle: 石锤淡啤酒 #这个是网站在标签页的标题subtitle: 生活就是等待戈多 #这个是副标题description: 这里记录的不只有代码，还有生活和思想！ #这里也可以写网站的关键词，也可以矫情的写点别的author: Chris Chan #这个作者会在网页最下面显示language: zh-Hans #这里表示简体中文timezone:# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:RorschachChan/RorschachChan.github.io.git #这里写的就是刚刚申请的库名 branch: master 建立完库以及修改保存了_config.xml之后，我们执行一句hexo d部署命令，在执行的时候需要输入当时你建立id_rsa时候的口诀，刚刚申请的那个口诀不会这么快就忘了吧。 返回到github的网站就看到hexo里所有的内容都上传到了github网站里了，如图: 在浏览器里输入“https://你的用户名.github.io”，就看到了博客界面： 同理，如果你的github用户名是test，建立的是test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 http://test.github.io 了，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。 至此，建立一个博客demo就到此结束了！ 参考资料https://baoyuzhang.github.io/2017/04/28/【Hexo搭建独立博客全纪录】（一）使用Git和Github/https://github.com/iissnan/hexo-theme-nexthttp://opiece.me/2015/04/09/hexo-guide/http://shenzekun.cn/hexo的next主题个性化配置教程.html 强烈推荐这篇文章，可以让你把next主题的博客做的更加漂亮！","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://yoursite.com/categories/博客搭建/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"},{"name":"博客搭建","slug":"博客搭建","permalink":"http://yoursite.com/tags/博客搭建/"}]},{"title":"Query String跟Arg的差异","slug":"Query-String跟arg的异同","date":"2018-01-09T12:47:40.000Z","updated":"2018-01-22T02:29:05.106Z","comments":true,"path":"2018/01/09/Query-String跟arg的异同/","link":"","permalink":"http://yoursite.com/2018/01/09/Query-String跟arg的异同/","excerpt":"","text":"前言与需求在https://rorschachchan.github.io/2018/01/09/记一次配置rewrite和return的经历/ 里记录了一次rewrite和return的故事，不过我当时在最后的return里是把域名给写死了：rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last;。 现在新的需求又来了，说域名不要写死，http://dvlshop.lechange.com/index.php/这部分要跟整个uri的state部分保持一致。 于是我这里再把整个uri贴出来，辣一下各位的眼睛：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 也就是说现在只需要变量state那点部分，那么这个时候就不能再使用$query_string了，要使用$arg。 $arg可以精确匹配变量，比如说我有一个参数（uri里？后面的那部分全叫参数）：&amp;p=你大爷&amp;q=你大娘，用$query_string和$arg就是获取所有，而使用$arg_p就是可以获取“你大爷”。 于是说动手就动手，把nginx.conf改成了：123456789101112131415161718location ~ .*\\.php.*&#123; include php_fcgi.conf; include pathinfo.conf; set $flag \"0\"; if ( $args ~ \"source_type=lc_app\" ) &#123; set $flag \"1\"; &#125; if ( $args ~ \"(.*)response_type(.*)\" )&#123; set $Flag \"$flag$flag\"; set $id $1; set $query $2; &#125; if ($Flag = \"11\")&#123; set $flag \"0\"; return 301 $arg_state$id+auto+$query; &#125;&#125; 但是通过日志查看，发现$arg_state得到的是/http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html,这就很囧了，我希望获取http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html（不要前面的反斜杠）或者是/product-79.html（不要中间的网站）。这可怎么办？ 答案是，原生的nginx是做不到这一点，因为nginx不参与业务层逻辑方面的业务。如果说要达到改写的目的，就要搭配lua或者把nginx换成openresty。于是乎就让开发修改一下传递的state来达到目的。 扩展与补充看到这个结果突然让我想起来一道面试题，说开发有一个模块，同时这个模块会给nginx提供几个状态码，比如状态码是111，那就是代表OK，状态码不是111，那就是代表不OK，现在想写一个语句，如果nginx获得的状态码不是111，返回一个404的页面，怎么写？ 没错，答案也是“原生nginx写不了”，原因跟上面的一样，应用模块状态码是业务层的，nginx是http层的，不在一层压根就无法交流。 在这里也顺道补充一下“在浏览器中输入一个URL后都发生了什么？”，以下是一个大概流程： 浏览器向DNS服务器查找输入URL对应的IP地址； DNS服务器返回网站的IP地址； 浏览器根据IP地址与目标web服务器建立TCP连接； 发送HTTP请求； 服务器处理请求； 返回响应结果； 关闭TCP连接； 浏览器解析HTML； 浏览器布局渲染；","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"},{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"}]},{"title":"记一次配置rewrite和return的经历","slug":"记一次配置rewrite和return的经历","date":"2018-01-09T08:39:10.000Z","updated":"2018-01-22T02:31:03.989Z","comments":true,"path":"2018/01/09/记一次配置rewrite和return的经历/","link":"","permalink":"http://yoursite.com/2018/01/09/记一次配置rewrite和return的经历/","excerpt":"","text":"前言与需求自动电商平台归属了大数据研究院之后，我又恢复了那个“把nginx当成爸爸”的日子。开发不断地提出了的要求，我一样一样的疲命应付，并且在应付后记录下来，就怕以后再遇到类似的问题。 这次的需求是一个跳转，满足某个条件之后把“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 ”改成“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27” 具体条件是: 先判断是否有source_type=lc_app； 再判断是否有response_type； 如果以上两个都满足，将“response_type”改成“+auto+”； 各位看官，我理解你们此时不想继续看下去的心情，其实我当初看着那么一大坨uri心里也直犯闹，但是没办法，“食君之禄，分君之忧”，我只能耐着性子一个一个的拆开，还别说，拆开的话就清晰许多了，如下：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 开始操作针对这次需求我的计划是这样的：把原地址看成”$1+ response_type +$2”这样的一个样式，确定$1和$2，然后rewrite成”$1+ +auto+ +$2”不就搞定了么？ 于是乎我就凭着我那二把刀的nginx技术开始动手。折腾了大约半个小时，拿出来这样一个配置： 123456789101112131415161718location ~ .*\\.php.* &#123; include php_fcgi.conf; include pathinfo.conf; set $flag \"0\"; if ( $request_uri ~ \"source_type=lc_app\" ) &#123; set $flag \"1\"; &#125; if ( $request_uri ~ \"(.*)response_type(.*)\" )&#123; set $Flag \"$flag$flag\"; set $id $1; set $query $2; &#125; if ($Flag = \"11\")&#123; #注意这个地方是11 set $flag \"0\"; rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last; #前面那一段是写死的 &#125; &#125; 但是很不幸，nginx -s reload之后的结果是“$1+$2+$1+ response_type +$2”的格式（地址太长太恶心了，我就不写了）。 然后在arstercz大神的指点下，把那句rewrite改成了return 301 http://dvlshop.lechange.com/index.php/wap/?$id$query;。就达到了效果。 原因确定后来追寻原因，原来是： rewrite后面接的$uri不需要$args，因为$args会被自动带过来。而return的则会丢失$args，需要手动补上$args。而我上面的$1,$2恰巧就是$args，所以用rewrite的话就会重复。举个例子，比如请求「http://localhost/?a=1」想被 301 到「https://localhost/?a=1?a=1」，要么 1234server &#123; listen 80; rewrite / https://$host$uri permanent;&#125; 要么就 1234server &#123; listen 80; return 301 https://$host$request_uri;&#125; 补充说明PS，这里补充一下uri、request_uri、document_uri之间的区别： $request_uri: /stat.php?id=1585378&amp;web_id=1585378 $uri: /stat.php (不带？后面) $document_uri: /stat.php （与uri完全相同）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"},{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"}]},{"title":"Linux运维工程师面试题第一套","slug":"Linux运维工程师面试题第一套","date":"2018-01-04T08:46:41.000Z","updated":"2018-01-22T02:28:13.351Z","comments":true,"path":"2018/01/04/Linux运维工程师面试题第一套/","link":"","permalink":"http://yoursite.com/2018/01/04/Linux运维工程师面试题第一套/","excerpt":"","text":"这套题的出处是http://blog.51cto.com/nolinux/1670406，看到了闲着没事周末就做一做，答案都是我自己在工作里得到的，不一定百分百准确，只是无聊的时候做做，现在拿出来跟各位分享一番。 1、请写出五种系统性能分析工具，并简述其作用和特点[我的答案] top、free、vmstat、iostat、perf等等等等，如果你想装逼，可以回答fio,blktrace，oprofile。具体的作用和特点这里不多说了，但是我着重要推荐vmstat，很实用很棒的一个命令。 2、请写出web服务器的调优要点[我的答案]以nginx为例，个人总结有如下几个要点：1）尽可能的少用http，因为http是有开销的；2）尽可能的使用CDN；3）添加Expire/Cache-Control头，这个头是缓存用的，可以缓存图片和flash那样不轻易更改的文件，减少访问时间；4）启动gzip压缩，这个没啥好说的了；5）尽可能少的重定向，能rewrite就不要return，我也知道return比rewrite好写，但是重定向是需要时间的，增加一次重定向就会多一次web需求；6）如果可以，把ajax也做缓存；7）减少dns查询，很多网页会有外站的广告，这些广告也是会启动dns查询的，所以如果不缺钱，减少这种广告；8）调好服务器里的TCP协议栈，这个无论是web服务器还是应用服务器都是必须的； 3、请写出你知道或使用过的nginx扩展模块（注意标注知道和使用）[我的答案] 随便说几个，这玩意到时候结合工作过的情况说说吧：Nginx负载均衡模块：nginx-upstream-fair非阻塞访问redis模块：redis2-nginx-module分布式图片实时动态压缩：ngx-fastdfs 4、请简述你了解的自动化配置管理工具特点和运行原理[我的答案]我用的最多的就是ansible和saltstack，这俩都是python的，对于我这个半路出家的更亲切。ansible基于SSH协议传输数据，不用装agent，配置比较简单，对windows支持惨不忍睹；saltstack使用消息队列zeroMQ传输数据，如果1000台以上的话它速度比ansible还要快,要安装agent，对windows支持同样惨不忍睹； 5、目前，有一个文件，内容如下： 172.16.100.1 172.16.100.2 172.16.100.3 172.16.100.4 请使用while和ssh命令，登录文件内的ip并执行hostname命令[我的答案]这个我还真没有什么思路，不过应该是跟“&lt;”输入重定向命令结合的一个脚本吧。PS,为啥不用ansible…哪怕pssh也可以啊！ 6、请使用awk命令将如下两份文件中名字相同的两行合并起来 A文件： 大广州 21岁 广州大 23岁 州广大 22岁 广州大 24岁 B文件： 广州大 男 大广州 男 州广大 男 广州大 男输出效果： 大广州 21岁 男[我的答案]awk ‘NR==FNR{a[$1]=$2}NR&gt;FNR{print $0,a[$1]}’ 第2个文件名 第1个文件名PS，做完这道题，我已经不认识“广”“州”这两个字了… 7、请使用绘图的方式简述TCP/IP三次握手和四次断开的交互过程[我的答案]这种图满大街都是了，我这个灵魂画师在这里就不污染各位的眼睛，不过这里推荐各位去看一篇文章：https://mp.weixin.qq.com/s?__biz=MjM5NzA1MTcyMA==&amp;mid=2651160450&amp;idx=2&amp;sn=1128438fa5287b6cee503880698642b2&amp;scene=21 对原理讲的浅显易懂。多说一句，网易招聘java的时候也问这个问题，不过他们问的是“为什么要三次握手？” 8、请根据你的理解，简述高可用服务体系的相关组件，并列举该组件的具体实现服务名字[我的答案] 我觉得这个题是要问一些架构上的东西，以我工作环境为例：统一配置:zookeeper、Consul、Etcd+Confd(这俩比较常见于动态管理nginx)前端展示:nginx消息队列:activemq、kafka读写分离中间件:atlas日志分析:elk 9、请根据你的理解，简述负载均衡的实现方式[我的答案]负载均衡主要分为两种，硬件（F5）和软件（NGINX、Haproxy、LVS），硬件效果比较牛逼，它是把4-7层的负载均衡功能做到一个硬件里面，但是价格昂贵最近用的越来越少了。软件的负载均衡又分两种，四层和七层：四层是在IP/TCP协议栈上把网络包的IP地址和端口进行修改，达到转发的目的；七层就是在应用层里把HTTP请求、URL等具体的应用数据发送到具体的服务器上。四层的效率比七层的高，四层一般安排在架构的前端，七层一般就是在具体服务器的前端。软件负载均衡比较常见的几个分配方式如下：轮询：访问请求依序分发给后端服务器；加权轮询：访问请求依序分发后端服务器，服务器权重越高被分发的几率也越大；最小连接数： 将访问请求分发给当前连接数最小的一台后端服务器，服务器权重越高被分发的几率也越大； 10、请根据你的理解，简述数据迁移工具和数据存储服务有哪些以及相关特点[我的答案]由于我公司主要都放在了阿里云，数据库用过的就这么几个:mysql、redis和elasticsearch。对于Storm和Hadoop这俩我还是初学者。mysql:关系型数据库elasticsearch:全文检索框架，这玩意逐渐向一个数据库靠拢了redis:键值储存数据库 mysql的数据迁移最常见的就是mysqldump，但是要注意使用不当会锁表，redis的数据迁移最稳妥的方法就是主从同步：在slave端启动redis，然后执行slaveof master机器IP地址 6379，然后使用info的时候查看master_link_status如果是up那就是OK了，再执行slaveof no one,提示OK就是OK了；Elasticsearch的数据迁移工具就是Elasticsearch-Exporter，不过我对它仅仅只是了解，用的并不多； 总结这套题不算难，方向是偏应用的，但是对云端服务的运维来说不算很友好，因为云厂商基本都把数据备份和数据迁移都做成自己的工具（比如阿里云的DTS），所以很多云服务的运维对这种东西了解不多。","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"},{"name":"职场","slug":"职场","permalink":"http://yoursite.com/tags/职场/"}]},{"title":"Nginx动态编译新的模块","slug":"Nginx动态编译新的模块","date":"2018-01-03T13:44:44.000Z","updated":"2018-01-22T04:05:41.652Z","comments":true,"path":"2018/01/03/Nginx动态编译新的模块/","link":"","permalink":"http://yoursite.com/2018/01/03/Nginx动态编译新的模块/","excerpt":"","text":"开始动手打算给电脑上的nginx添加一个当时没有编译安装的echo-nginx-module模块，这是一个第三方模块，要知道nginx要添加模块是需要重新编译的，这一点跟apache不同，apache是在配置文件里引用.so文件的。 首先先nginx -V，查看一下nginx已经编译的模块都有啥，如图： 于是我就git clone https://github.com/openresty/echo-nginx-module，但是发现竟然告诉我“git: command not found”。oh shit，原来这台nginx实验机器压根就没有装过git啊！而yum源里的软件基本上已经过时的太久了，就拿git来说吧，使用yum info git看到的版本是1.8.3.1。但是在https://github.com/git/git/releases 里可以看到，git的版本现在已经丧心病狂的到达了2.16的版本了。 那么我们先安装git!通过yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel和yum install gcc perl-ExtUtils-MakeMaker来安装依赖库。wget https://github.com/git/git/archive/v2.16.0-rc0.tar.gz来下载2.16的git保存到centos里。tar -xzvf v2.9.2.tar.gz -C /目标目录/，然后在目标目录里面执行make prefix=/usr/local/git all和make prefix=/usr/local/git install，编译过程可能会比较长，请耐心等待。 编译结束之后，echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/bashrc，把git添加到环境变量，再source /etc/bashrc让它实时生效，最后再一次看看git --version，大功告成！ 编译新模块git搞定了之后，重新git clone https://github.com/openresty/echo-nginx-module，然后在nginx的configure文件夹里面，把echo-nginx-module模块添加上。命令如下： ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/root/pcre-8.41 --with-http_v2_module --add-module=/root/echo-nginx-module-0.61,我这里还附赠了一个“http_v2_module”。 configure完毕之后，去make一下就可以了，不要轻易make install，不然就是重新安装了。原来的nginx.conf等配置都没了。 养成替换nginx二进制文件的好习惯，如下： cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak cp nginx编译目录/objs/nginx /usr/local/nginx/sbin/ 然后再打开看一下nginx -V","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"从vmstat命令里看服务器瓶颈","slug":"从vmstat命令里看服务器瓶颈","date":"2018-01-03T12:56:56.000Z","updated":"2018-01-22T02:29:31.147Z","comments":true,"path":"2018/01/03/从vmstat命令里看服务器瓶颈/","link":"","permalink":"http://yoursite.com/2018/01/03/从vmstat命令里看服务器瓶颈/","excerpt":"","text":"这几天重新翻看基础知识，看到了vmstat，我认为它是一个非常优秀的命令,因为它包括了top和free，甚至还包含了一些io的信息，可以说是运维人员常备命令之一。常用方法：vmstat (-a) 多少秒刷一次 刷多少次。 对上面这个图来一个简单的解释： r: 运行队列中进程数量，这个值长期大于1就要判断是否需要增加CPU。b: 等待IO的进程数量 swpd: 使用虚拟内存大小(如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能）free: 空闲物理内存大小buff: 用作缓冲的内存大小cache: 用作缓存的内存大小(如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小)inact: 非活跃内存大小（当使用-a选项时显示）active: 活跃的内存大小（当使用-a选项时显示） si: 每秒从交换区写到内存的大小，由磁盘调入内存so: 每秒写入交换区的内存大小，由内存调入磁盘注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。 bi: 每秒读取的块数bo: 每秒写入的块数注意：随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。 in: 每秒中断数，包括时钟中断。cs: 每秒上下文切换数。注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 us: 用户进程执行时间百分比(user time)注意： us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time)注意：sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 wa: IO等待时间百分比注意：wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 id: 空闲时间百分比 最后总结：如果r经常大于4 ，且id经常少于40，表示cpu的负荷很重。如果bi，bo长期不等于0，表示内存不足。 r（运行队列）展示了正在执行和等待CPU资源的任务个数。当这个值超过了CPU数目，就会出现CPU瓶颈了。 CPU 100%并不能说明什么，Linux总是试图要CPU尽可能的繁忙，使得任务的吞吐量最大化。唯一能够确定CPU瓶颈的还是r（运行队列）的值。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"}]},{"title":"关于阿里云CDN的两个故障解决","slug":"CDN网站一次打不开的问题","date":"2017-12-28T09:34:57.000Z","updated":"2018-01-22T02:27:42.100Z","comments":true,"path":"2017/12/28/CDN网站一次打不开的问题/","link":"","permalink":"http://yoursite.com/2017/12/28/CDN网站一次打不开的问题/","excerpt":"","text":"测试中心今天在测试时候发现了一个问题：官方的A网站做了域名跳转，跳转到阿里云CDN，但是在浏览器里输入A地址栏的时候，发现域名的确变成了CDN的域名，但是页面是403。 如图： 但是奇怪的是，再在浏览器点击一下回车，网页就神奇的打开了。 这个原因就是阿里云的CDN有一个“Refer防盗链”，需要在防盗链里面把A域名添加到白名单，这样的话就可以直接访问了。至于为什么第二次回车就可以访问，是因为那时候域名已经成CDN自己的域名了，当然可以访问。 但是这个防盗链也要注意！毕竟白/黑名单添加都是一个危险举动，一定三思后行。有可能你的css\\js是用cdn加速的，一旦加上了白名单，可能css就会变得很难看。 不就之后，商城也下来一个需求，说公司有两个多年不用的域名B和C，打算废物利用，两个都要达到直接“跳转官网”的目的。 于是我就到阿里云域名管理的那里搜索一下，发现目前官网域名后端绑定的是一个CDN，于是也把域名B和域名C做一个CNAME到这个域名，不过登陆浏览器发现域名B和域名C都反馈502。 于是我就到电子商城后端的nginx.conf里查看，确认server_name字段没有写错，然后把域名B和域名C的CNAME直接改成了CDN的域名，再通过了dig确认。但是等于浏览器还是发现502。 最后找了阿里云的人了解，原来阿里云规定“一个CDN只能绑定一个域名，因为节点上没有那两个域名的配置，所以只要不符合节点上有配置文件信息的，全部502”。所以B和C是无法访问的。要解决这个问题有两招，1）把域名B和域名C直接A记录绑定CDN后面的SLB上，但是代价就是访问速度不如CDN快；2）重新购买两个CDN，都绑定SLB，然后把这两个CDN分别绑定到域名B和域名C上，代价是多收一点流量费…","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"CDN","slug":"CDN","permalink":"http://yoursite.com/tags/CDN/"},{"name":"网站技术","slug":"网站技术","permalink":"http://yoursite.com/tags/网站技术/"}]},{"title":"screen的用法","slug":"screen的用法","date":"2017-12-21T07:59:44.000Z","updated":"2018-01-22T02:29:00.675Z","comments":true,"path":"2017/12/21/screen的用法/","link":"","permalink":"http://yoursite.com/2017/12/21/screen的用法/","excerpt":"","text":"很多时候在Linux要后台执行程序，都是使用“&amp;”，或者是nohup，不过这两个更多应用于临时的脚本。一个比较高科技的方法就是使用screen。 安装screen的方法很简单：yum install -y screen。 如果新建一个screen，就输入screen -S name，这样会新开一个窗口，然后执行命令。比如我要启动django，那么就输入python manage.py runserver 0.0.0.0:9000即可。 这个重开一个窗口，列出所有screen进程，就这样： [root@docker ~]# screen -ls There are screens on: 3029.xiedi (Attached) 如果想链接上之前那个django，执行命令screen -r 3029即可。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"其他软件","slug":"其他软件","permalink":"http://yoursite.com/tags/其他软件/"}]},{"title":"pictest","slug":"pictest","date":"2017-12-13T13:40:06.000Z","updated":"2018-01-03T07:06:26.282Z","comments":true,"path":"2017/12/13/pictest/","link":"","permalink":"http://yoursite.com/2017/12/13/pictest/","excerpt":"这是一个我用来测试图片上传的文章","text":"这是一个我用来测试图片上传的文章 啊！五环，你比四环多一环！啊！五环，你比六环少一环！终于有一天，你会修到七环","categories":[{"name":"用来保护视力的图片","slug":"用来保护视力的图片","permalink":"http://yoursite.com/categories/用来保护视力的图片/"}],"tags":[{"name":"美女","slug":"美女","permalink":"http://yoursite.com/tags/美女/"},{"name":"图片","slug":"图片","permalink":"http://yoursite.com/tags/图片/"}]},{"title":"这里记录的不只有代码，还有生活和思想！","slug":"这里记录的不只有代码，还有生活和思想！","date":"2017-12-13T06:17:22.000Z","updated":"2018-01-12T07:53:13.423Z","comments":true,"path":"2017/12/13/这里记录的不只有代码，还有生活和思想！/","link":"","permalink":"http://yoursite.com/2017/12/13/这里记录的不只有代码，还有生活和思想！/","excerpt":"","text":"var ap = new APlayer({ element: document.getElementById(\"aplayer0\"), narrow: false, autoplay: false, showlrc: 0, music: { title: \"一个人去旅行\", author: \"陈升\", url: \"http://p1x3hd2at.bkt.clouddn.com/一个人去旅行.mp3\", pic: \"http://p1x3hd2at.bkt.clouddn.com/五十米深蓝.jpg\", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 你说要一个人去旅行 但是归期却没有约定 亚得里亚海边风中的吉他声你说你带着苍白的回忆 却谢谢能与我相逢 我怕你在异乡夜里孤独醒来要拒绝两人单调的生活 想寻找自由 迷信了爱情 就迷失了我自己你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 一个人生活 你说要一个人去旅行 眼里藏着一朵乌云 知道你藏不住秘密 天空就会飘着雨你说你带着一本日记 却不想再拥有回忆 我怕你在异乡孤独的醒来要拒绝两人单调的生活 不想再随波逐流 迷信了孤独 就软弱的抛弃了我的等待 你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 让我孤独生活 你就这样 离开吧 抛弃我 孤独的旅人你就这样 离开我 抛弃我 让我孤独生活 我想要一个人去旅行 但愿归期会有约定 每个人都在问我 是否可以找到自由的你亚得里亚海边他乡的人和风中的吉他声 我怕你一个人在异乡孤独醒来我会带着你回来","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"音乐","slug":"音乐","permalink":"http://yoursite.com/tags/音乐/"},{"name":"感悟","slug":"感悟","permalink":"http://yoursite.com/tags/感悟/"}]}]}